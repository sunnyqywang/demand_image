{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from setup import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (45,50) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (11,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "hh = pd.read_csv(survey_dir+\"household.csv\")\n",
    "pr = pd.read_csv(survey_dir+\"person.csv\")\n",
    "pl = pd.read_csv(survey_dir+\"place.csv\")\n",
    "pt = pd.read_csv(survey_dir+\"place_transit.csv\")\n",
    "lc = pd.read_csv(survey_dir+\"location.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12391 Households 30683 People 128229 Places 99652 Trips\n"
     ]
    }
   ],
   "source": [
    "num_pl = len(pl)\n",
    "print(len(hh), \"Households\", len(pr), \"People\", len(pl), \"Places\", len(pl[pl.placeno!=1]), \"Trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 households with no income\n"
     ]
    }
   ],
   "source": [
    "# Income\n",
    "f_inc = (hh.hhinc >= 0) | (hh.hhinc2 >= -1)\n",
    "print(np.sum(f_inc==0), 'households with no income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 households with no trips\n"
     ]
    }
   ],
   "source": [
    "# Trip numbers\n",
    "f_hhtrips = (hh.hhtrips>0)\n",
    "print(np.sum(f_hhtrips==0), 'households with no trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh[f_inc & f_hhtrips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 people with no age\n"
     ]
    }
   ],
   "source": [
    "# Age\n",
    "f_age = (pr.aage >= -1)\n",
    "print(np.sum(f_age==0), 'people with no age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 people with no license info\n"
     ]
    }
   ],
   "source": [
    "# License\n",
    "f_lic = (pr.lic >= -1)\n",
    "print(np.sum(f_lic==0), 'people with no license info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 people with no education info\n"
     ]
    }
   ],
   "source": [
    "# Education\n",
    "f_edu = (pr.educ > 0)\n",
    "print(np.sum(f_edu==0), 'people with no education info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr[f_age & f_lic & f_edu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331 places with invalid modes (not available or air travel)\n"
     ]
    }
   ],
   "source": [
    "# Travel Mode\n",
    "f_mode = (pl['mode'] >= -1) & (pl['mode'] // 100 < 8)\n",
    "print(np.sum(f_mode==0), 'places with invalid modes (not available or air travel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pl[f_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1968 locations not in valid states\n",
      "989 places not in valid states\n"
     ]
    }
   ],
   "source": [
    "# Trip Location\n",
    "f_state_loc = (lc['state_fips'].isin([17,18,26,55]))\n",
    "# tight restrictions to speed up the image download process\n",
    "#f_state_loc = (lc['state_fips'].isin([17]))\n",
    "pl = pd.merge(lc[f_state_loc][['sampno','locno']], pl, on=['sampno','locno'])\n",
    "\n",
    "print(np.sum(f_state_loc==0), 'locations not in valid states')\n",
    "print(num_pl-len(pl), 'places not in valid states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc[f_state_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left with 12013 Households 30640 People 127240 Places 98899 Trips\n"
     ]
    }
   ],
   "source": [
    "print(\"Left with\", len(hh), \"Households\", len(pr), \"People\", len(pl), \"Places\", len(pl[pl.placeno!=1]), \"Trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn Places into Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_new = pl[['sampno', 'perno', 'placeGroup', 'locno', 'arrtime', 'deptime', 'travtime', 'mode']].sort_values(by=['sampno','perno','placeGroup']).reset_index(drop=True)\n",
    "pl_new['prev_placeGroup'] = pl_new['placeGroup'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.merge(pl_new, pl_new, left_on=['sampno', 'perno', 'placeGroup'], right_on=['sampno', 'perno', 'prev_placeGroup'], suffixes=('_1','_2'))\n",
    "tp = tp[['sampno', 'perno', 'placeGroup_1', 'placeGroup_2', 'locno_1', 'locno_2', 'deptime_1', 'arrtime_2', 'travtime_2', 'mode_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc[['sampno', 'locno', 'loctype', 'state', 'country', 'state_fips',\n",
    "       'county_fips', 'tract_fips', 'out_region', 'home', 'latitude',\n",
    "       'longitude']]\n",
    "tp = pd.merge(tp, lc, left_on=['sampno', 'locno_1'], right_on = ['sampno', 'locno'])\n",
    "tp = pd.merge(tp, lc, left_on=['sampno', 'locno_2'], right_on = ['sampno', 'locno'], suffixes=(\"_1\", \"_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.merge(tp, pr[['sampno','perno','wtperfin']], on=['sampno','perno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.to_csv(data_dir+\"trips.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp['tract_1'] = tp['state_fips_1']*1000000000+tp['county_fips_1']*1000000+tp['tract_fips_1']\n",
    "tp['tract_2'] = tp['state_fips_2']*1000000000+tp['county_fips_2']*1000000+tp['tract_fips_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sampno', 'perno', 'placeGroup_1', 'placeGroup_2', 'locno_1', 'locno_2',\n",
       "       'deptime_1', 'arrtime_2', 'travtime_2', 'mode_2', 'locno_1',\n",
       "       'loctype_1', 'state_1', 'country_1', 'state_fips_1', 'county_fips_1',\n",
       "       'tract_fips_1', 'out_region_1', 'home_1', 'latitude_1', 'longitude_1',\n",
       "       'locno_2', 'loctype_2', 'state_2', 'country_2', 'state_fips_2',\n",
       "       'county_fips_2', 'tract_fips_2', 'out_region_2', 'home_2', 'latitude_2',\n",
       "       'longitude_2', 'wtperfin', 'tract_1', 'tract_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify Mode Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Active; 2: Auto; 3: Mobility Services; 4: Public Transit\n",
      "mode\n",
      "1    13.281503\n",
      "2    75.000827\n",
      "3     5.135885\n",
      "4     6.581785\n",
      "Name: wtperfin, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tp['mode'] = tp['mode_2']//100\n",
    "tp['mode'] = tp['mode'].map({1:1,2:2,3:3,4:3,5:4,6:3,7:3})\n",
    "print(\"1: Active; 2: Auto; 3: Mobility Services; 4: Public Transit\")\n",
    "print(tp.groupby('mode').sum()['wtperfin']/tp['wtperfin'].sum()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_mode = tp.groupby(['state_1', 'state_fips_1', 'county_fips_1', 'tract_fips_1', 'mode']).sum()['wtperfin'].reset_index()\n",
    "o_mode['key'] = 0\n",
    "o_mode_full = pd.merge(o_mode[['state_1', 'state_fips_1', 'county_fips_1', 'tract_fips_1','key']].drop_duplicates(), \n",
    "                       o_mode[['mode','key']].drop_duplicates())\n",
    "\n",
    "o_mode = o_mode.drop(\"key\",1)\n",
    "o_mode_full = o_mode_full.drop(\"key\",1)\n",
    "\n",
    "o_mode = pd.merge(o_mode_full, o_mode, on=['state_1', 'state_fips_1', 'county_fips_1', 'tract_fips_1','mode'], how='left').fillna(0)\n",
    "\n",
    "trip_generation = tp.groupby(['state_1', 'state_fips_1', 'county_fips_1',\n",
    "       'tract_fips_1']).sum()['wtperfin'].reset_index()\n",
    "\n",
    "o_mode = pd.merge(o_mode, trip_generation, on=['state_1', 'state_fips_1', 'county_fips_1', 'tract_fips_1'],\n",
    "                 suffixes=(\"_mode\",\"_all\"))\n",
    "\n",
    "o_mode.to_csv(data_dir+\"origin_trip_behavior.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_mode = tp.groupby(['state_2', 'state_fips_2', 'county_fips_2', 'tract_fips_2', 'mode']).sum()['wtperfin'].reset_index()\n",
    "o_mode['key'] = 0\n",
    "o_mode_full = pd.merge(o_mode[['state_2', 'state_fips_2', 'county_fips_2', 'tract_fips_2','key']].drop_duplicates(), \n",
    "                       o_mode[['mode','key']].drop_duplicates())\n",
    "\n",
    "o_mode = o_mode.drop(\"key\",1)\n",
    "o_mode_full = o_mode_full.drop(\"key\",1)\n",
    "\n",
    "o_mode = pd.merge(o_mode_full, o_mode, on=['state_2', 'state_fips_2', 'county_fips_2', 'tract_fips_2','mode'], how='left').fillna(0)\n",
    "\n",
    "trip_generation = tp.groupby(['state_2', 'state_fips_2', 'county_fips_2',\n",
    "       'tract_fips_2']).sum()['wtperfin'].reset_index()\n",
    "\n",
    "o_mode = pd.merge(o_mode, trip_generation, on=['state_2', 'state_fips_2', 'county_fips_2', 'tract_fips_2'],\n",
    "                 suffixes=(\"_mode\",\"_all\"))\n",
    "\n",
    "o_mode.to_csv(data_dir+\"destination_trip_behavior.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OD pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep trips in Illinois only\n",
    "tp = tp[(tp['state_fips_1']==17)&(tp['state_fips_2']==17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# OD pairs: 46151 \t # records: 96698 \t # trips: 25859022\n",
      "# OD pairs with more than 5 records: 2413 accounting for 32471 records and 7759413 trips\n"
     ]
    }
   ],
   "source": [
    "od_weighted = tp.groupby(['tract_1','tract_2'], as_index=False).sum()[['tract_1','tract_2','wtperfin']]\n",
    "od_count = tp.groupby(['tract_1','tract_2'], as_index=False).count()[['tract_1','tract_2','sampno']]\n",
    "od = pd.merge(od_weighted, od_count, on=['tract_1','tract_2'])\n",
    "\n",
    "print(\"# OD pairs: %d \\t # records: %d \\t # trips: %d\" %(len(od), od.sum()['sampno'], od.sum()['wtperfin']))\n",
    "print(\"# OD pairs with more than 5 records: %d accounting for %d records and %d trips\" %\\\n",
    "      (len(od[od['sampno']>5]), od[od['sampno']>5].sum()['sampno'], od[od['sampno']>5].sum()['wtperfin']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OD Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode = tp.groupby(['tract_1','tract_2','mode'], as_index=False).sum()[['tract_1','tract_2','mode','wtperfin']]\n",
    "\n",
    "od_mode['key'] = 0\n",
    "od['key'] = 0\n",
    "\n",
    "# Create a df with all combinations of od and mode\n",
    "od_mode_full = pd.merge(od[['tract_1','tract_2','key']].drop_duplicates(), od_mode[['mode','key']].drop_duplicates()).drop(\"key\", 1)\n",
    "od_mode = od_mode.drop(\"key\",1)\n",
    "od = od.drop(\"key\",1)\n",
    "od_mode_full[\"i\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode = pd.merge(od_mode_full, od_mode, on=['tract_1','tract_2','mode'], how='outer').fillna(0)\n",
    "od_mode = pd.merge(od_mode, od, on=['tract_1','tract_2'], suffixes=(\"_mode\",\"_od\"))\n",
    "od_mode['mode_share'] = od_mode['wtperfin_mode'] / od_mode['wtperfin_od']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode.to_csv(data_dir+\"od_mode.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter OD pairs\n",
    "- A lot of public transit trips are filltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od[od['sampno']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Census tracts in these OD pairs: 925\n"
     ]
    }
   ],
   "source": [
    "tracts = pd.concat([od['tract_1'], od['tract_2']]).drop_duplicates().tolist()\n",
    "print(\"# Census tracts in these OD pairs:\", len(tracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode = tp.groupby(['tract_1','tract_2','mode'], as_index=False).count()[['tract_1','tract_2','mode','wtperfin']]\n",
    "\n",
    "od_mode['key'] = 0\n",
    "od['key'] = 0\n",
    "# Use filtered OD (>5 trips)\n",
    "od_mode_full = pd.merge(od[['tract_1','tract_2','key']].drop_duplicates(), od_mode[['mode','key']].drop_duplicates()).drop(\"key\", 1)\n",
    "od_mode = od_mode.drop(\"key\",1)\n",
    "od = od.drop(\"key\",1)\n",
    "od_mode_full[\"i\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode = pd.merge(od_mode_full, od_mode, on=['tract_1','tract_2','mode'], how='outer').fillna(0)\n",
    "od_mode = pd.merge(od_mode, od, on=['tract_1','tract_2'], suffixes=(\"_mode\",\"_od\"))\n",
    "od_mode['mode_share'] = od_mode['wtperfin_mode'] / od_mode['wtperfin_od']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode.to_csv(data_dir+\"od_mode_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Census Tracts to Get Images\n",
    "tracts = pd.concat([od['tract_1'], od['tract_2']]).drop_duplicates().tolist()\n",
    "lc = pd.read_csv(survey_dir+\"location.csv\")\n",
    "lc['tract'] = lc['state_fips']*1000000000+lc['county_fips']*1000000+lc['tract_fips']\n",
    "\n",
    "lc = lc[['tract','state_fips','county_fips','tract_fips','latitude','longitude']].drop_duplicates()\n",
    "lc = lc[lc['tract'].isin(tracts)]\n",
    "\n",
    "lc['train_test'] = np.random.rand(len(lc)) < 0.1\n",
    "lc['train_test'] = lc['train_test'].astype(int)\n",
    "lc.to_csv(data_dir+\"census_tracts_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
