{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from setup import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (45,50) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (11,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "hh = pd.read_csv(survey_dir+\"household.csv\")\n",
    "pr = pd.read_csv(survey_dir+\"person.csv\")\n",
    "pl = pd.read_csv(survey_dir+\"place.csv\")\n",
    "pt = pd.read_csv(survey_dir+\"place_transit.csv\")\n",
    "lc = pd.read_csv(survey_dir+\"location.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12391 Households 30683 People 128229 Places 99652 Trips\n"
     ]
    }
   ],
   "source": [
    "num_pl = len(pl)\n",
    "print(len(hh), \"Households\", len(pr), \"People\", len(pl), \"Places\", len(pl[pl.placeno!=1]), \"Trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Invalid Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 households with no income\n"
     ]
    }
   ],
   "source": [
    "# Income\n",
    "f_inc = (hh.hhinc >= 0) | (hh.hhinc2 >= -1)\n",
    "print(np.sum(f_inc==0), 'households with no income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 households with no trips\n"
     ]
    }
   ],
   "source": [
    "# Trip numbers\n",
    "f_hhtrips = (hh.hhtrips>0)\n",
    "print(np.sum(f_hhtrips==0), 'households with no trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh[f_inc & f_hhtrips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4959 people with no age or younger than 12 years\n"
     ]
    }
   ],
   "source": [
    "# Age\n",
    "f_age = (pr.age >= 12)\n",
    "print(np.sum(f_age==0), 'people with no age or younger than 12 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 people with no license info\n"
     ]
    }
   ],
   "source": [
    "# License\n",
    "f_lic = (pr.lic >= -1)\n",
    "print(np.sum(f_lic==0), 'people with no license info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 people with no education info\n"
     ]
    }
   ],
   "source": [
    "# Education\n",
    "f_edu = (pr.educ > 0)\n",
    "print(np.sum(f_edu==0), 'people with no education info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr[f_age & f_lic & f_edu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331 places with invalid modes (not available or air travel)\n"
     ]
    }
   ],
   "source": [
    "# Travel Mode\n",
    "f_mode = (pl['mode'] >= -1) & (pl['mode'] // 100 < 8)\n",
    "print(np.sum(f_mode==0), 'places with invalid modes (not available or air travel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity Duration\n",
    "f_actdur = pl['actdur'] < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pl[f_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4945 locations not in valid states\n",
      "2415 places not in valid states\n"
     ]
    }
   ],
   "source": [
    "# Trip Location\n",
    "f_state_loc = (lc['out_region']==0)\n",
    "\n",
    "pl = pd.merge(lc[f_state_loc][['sampno','locno']], pl, on=['sampno','locno'])\n",
    "\n",
    "print(np.sum(f_state_loc==0), 'locations not in valid states')\n",
    "print(num_pl-len(pl), 'places not in valid states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc[f_state_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left with 12013 Households 25698 People 125814 Places 97691 Trips\n"
     ]
    }
   ],
   "source": [
    "print(\"Left with\", len(hh), \"Households\", len(pr), \"People\", len(pl), \"Places\", len(pl[pl.placeno!=1]), \"Trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INCOME\n",
    "hh['hh_inc_0_30'] = (hh.hhinc.isin([1,2,3]))|(hh.hhinc2 == 1) # 13%\n",
    "hh['hh_inc_30_60'] = (hh.hhinc.isin([4,5,6]))|(hh.hhinc2 == 2) # 18% \n",
    "hh['hh_inc_60_100'] = (hh.hhinc.isin([7,8]))|(hh.hhinc2 == 3) # 26%\n",
    "hh['hh_inc_100_150'] = (hh.hhinc.isin([9]))|(hh.hhinc2 == 5) # 23%\n",
    "hh['hh_inc_150'] = (hh.hhinc == 10)|(hh.hhinc2 == 5) # 19%\n",
    "\n",
    "# there are no 0s in household size \n",
    "hh.hhsize = hh.hhsize * (hh.hhsize > 0)\n",
    "hh.hhveh = hh.hhveh * (hh.hhveh > 0)\n",
    "hh['avg_pr_veh'] = hh.hhveh / hh.hhsize\n",
    "\n",
    "# home ownership (with and without mortgage) (65%)\n",
    "hh['home_own'] = hh.homeown.isin([0,1,2])\n",
    "# home type\n",
    "hh['home_house'] = hh.resty.isin([1,2])\n",
    "hh['home_condo'] = hh.resty == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh[['sampno','hh_inc_0_30','hh_inc_30_60','hh_inc_60_100','hh_inc_100_150','hh_inc_150',\n",
    "        'avg_pr_veh','home_own','home_house','home_condo']]\n",
    "for c in ['sampno','hh_inc_0_30','hh_inc_30_60','hh_inc_60_100','hh_inc_100_150','hh_inc_150',\n",
    "         'home_own','home_house','home_condo']:\n",
    "    hh[c] = hh[c].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh.to_csv(data_dir+\"household.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Features\n",
    "- percentage quoted in terms of # observations (unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGE\n",
    "pr['12_18yrs'] = (pr['age'] >= 12) & (pr['age'] < 18) # 8%\n",
    "pr['18_25yrs'] = (pr['age'] >= 18) & (pr['age'] < 25) # 8% \n",
    "pr['25_55yrs'] = (pr['age'] >= 25) & (pr['age'] < 55) # 46%\n",
    "pr['55+yrs'] = (pr['age'] >= 55) # 21%\n",
    "pr['no_age'] = pr['age'] < 0\n",
    "\n",
    "### DISABILITY\n",
    "# 4% the rest is reported not disabled, young people (who do not need to answer), and people who do not wish to disclose\n",
    "pr['disability'] = pr['disab'] == 1\n",
    "\n",
    "### EDUCATION\n",
    "pr['educ_col'] = pr.educ == 5\n",
    "pr['educ_grad'] = pr.educ == 6\n",
    "\n",
    "### RACE\n",
    "# 78%\n",
    "pr['race_white'] = pr.race == 1 \n",
    "# 10%\n",
    "pr['race_black'] = pr.race == 2\n",
    "# 5%\n",
    "pr['race_asian'] = pr.race == 3\n",
    "\n",
    "### SEX\n",
    "pr['male'] = pr.sex == 1\n",
    "pr['female'] = pr.sex == 2\n",
    "\n",
    "### EMPLOYMENT\n",
    "# employed (58%)\n",
    "pr['emply'] = pr.emply_ask == 1\n",
    "# employer-subsidized parking (39%)\n",
    "pr['emply_park'] = (pr.emply_park > 0) & (pr.emply_park < 6)\n",
    "# employer-subsidized transit (12%)\n",
    "pr['emply_transit'] = (pr.emply_transit > 0) & (pr.emply_transit < 5)\n",
    "# employer provides vehicle (4%)\n",
    "pr['emply_veh'] = pr.pervh == 1\n",
    "# days WFH (if not, then 0) (>0: 10%)\n",
    "pr['emply_wfh'] = pr.tcdays * (pr.tcdays > 0)\n",
    "# ability to set or change work hours (25%)\n",
    "pr['emply_flex'] = pr.wkflex == 1\n",
    "# work hours\n",
    "pr['emply_hours'] = pr.wrkhrs * (pr.wrkhrs > 0)\n",
    "\n",
    "### TRAVEL BEHAVIOR\n",
    "# have license (71%)\n",
    "pr['license'] = pr.lic == 1\n",
    "# if skipped, then 0\n",
    "pr['person_trips'] = pr.pertrips * (pr.pertrips > 0)\n",
    "# ride bus more than 0 times in a typical week (56%)\n",
    "pr['person_transit'] = pr.ribus > 0\n",
    "# frequent bus rider (>=5 times a week) (10%)\n",
    "pr['person_freq_transit'] = pr.ribus == 4\n",
    "\n",
    "# 1: Active; 2: Auto; 3: Mobility Services; 4: Public Transit; 5: WFH\n",
    "# 57% (30,000 valid obervations)\n",
    "pr['work_mode'] = pr['wmode'].map({1:1,2:1,3:2,4:2,5:2,6:2,7:3,8:4,9:4,10:4,11:3,12:3,14:3,15:3,16:3,18:5})\n",
    "pr['work_mode'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr[['sampno','perno','wtperfin',\n",
    "         '12_18yrs','18_25yrs','25_55yrs','55+yrs','no_age',\n",
    "         'disability','educ_col','educ_grad','race_white','race_black','race_asian','male','female',\n",
    "         'emply_park','emply_transit','emply_veh','emply_wfh','emply_flex','emply_hours',\n",
    "         'license','person_trips','person_transit','person_freq_transit','work_mode']]\n",
    "for c in ['12_18yrs','18_25yrs','25_55yrs','55+yrs','no_age',\n",
    "         'disability','educ_col','educ_grad','race_white','race_black','race_asian','male','female',\n",
    "         'emply_park','emply_transit','emply_veh','emply_wfh','emply_flex',\n",
    "         'license','person_trips','person_transit','person_freq_transit','work_mode']:\n",
    "    pr[c] = pr[c].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.to_csv(data_dir+\"person.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Trip Features (Disaggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Turn Places into Trips\n",
    "# pl contains the information for the destination (as well as activity duration at destination, trip distance, etc.)\n",
    "pl['prev_placeGroup'] = pl['placeGroup'] - 1\n",
    "\n",
    "# create a new pl dataframe for information at the origin\n",
    "# only need to know where and when \n",
    "pl_new = pl[['sampno', 'perno', 'placeGroup', 'locno', 'deptime']].copy()\n",
    "pl_new = pl_new.sort_values(by=['sampno','perno','placeGroup']).reset_index(drop=True)\n",
    "\n",
    "tp = pd.merge(pl_new, pl, left_on=['sampno', 'perno', 'placeGroup'], right_on=['sampno', 'perno', 'prev_placeGroup'], suffixes=('_1','_2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add geospatial info from locations table\n",
    "lc = lc[['sampno', 'locno', 'loctype', 'state', 'country', 'state_fips',\n",
    "       'county_fips', 'tract_fips', 'home', 'latitude',\n",
    "       'longitude']]\n",
    "tp = pd.merge(tp, lc, left_on=['sampno', 'locno_1'], right_on = ['sampno', 'locno'])\n",
    "del tp['locno']\n",
    "tp = pd.merge(tp, lc, left_on=['sampno', 'locno_2'], right_on = ['sampno', 'locno'], suffixes=(\"_1\", \"_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out trips where time and distance reported do not make sense\n",
    "tp = tp[tp.time_distance_flag==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "tp['act_dur'] = tp.actdur\n",
    "\n",
    "tp['arr_hour'] = pd.to_datetime(tp['arrtime']).dt.hour\n",
    "tp['arr_min'] = pd.to_datetime(tp['arrtime']).dt.minute\n",
    "\n",
    "tp['dep_hour'] = pd.to_datetime(tp['deptime_1']).dt.hour\n",
    "tp['dep_min'] = pd.to_datetime(tp['deptime_1']).dt.minute\n",
    "\n",
    "tp['travel_time'] = tp['travtime']\n",
    "\n",
    "# excluding the respondent\n",
    "tp['companion'] = tp.hhparty + tp.nonhhcount\n",
    "tp['distance'] = tp.distance\n",
    "\n",
    "### TRIP PURPOSE\n",
    "# home2 is inferred by survey staff makes up by 1,2 primarily\n",
    "tp['from_home'] = tp.home_1\n",
    "tp['to_home'] = tp.home_2 #tpurp.isin([1,2]) # 35%\n",
    "\n",
    "tp['purp_work'] = tp.tpurp.isin([3,4,5,]) # 18%\n",
    "tp['purp_school'] = tp.tpurp.isin([6]) # 6%\n",
    "tp['purp_errand'] = tp.tpurp.isin([8,9,10,11,12,13,14,15,16]) # 19%\n",
    "tp['purp_recreation'] = tp.tpurp.isin([17,18,19,20,21,22,23,24,25,26,27]) # 21%\n",
    "\n",
    "tp['ontime_important'] = tp.trip_appt.isin([3,4,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = tp[['sampno', 'perno', 'placeGroup_1', 'placeGroup_2', 'locno_1', 'locno_2',\n",
    "         'loctype_1', 'state_1', 'country_1', 'state_fips_1',\n",
    "         'county_fips_1', 'tract_fips_1', 'latitude_1', 'longitude_1',\n",
    "         'loctype_2', 'state_2', 'country_2', 'state_fips_2',\n",
    "         'county_fips_2', 'tract_fips_2', 'latitude_2', 'longitude_2',\n",
    "         'dep_hour','dep_min','arr_hour','arr_min','travel_time', 'mode', \n",
    "         'companion','distance','from_home','to_home',\n",
    "         'purp_work','purp_school','purp_errand','purp_recreation',\n",
    "         'ontime_important']]\n",
    "for c in ['companion','from_home','to_home',\n",
    "         'purp_work','purp_school','purp_errand','purp_recreation',\n",
    "         'ontime_important']:\n",
    "    tp[c] = tp[c].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge trip with household and person information\n",
    "tp = pd.merge(tp, pr, on=['sampno','perno'])\n",
    "tp = pd.merge(tp, hh, on='sampno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp['tract_1'] = tp['state_fips_1'].astype(str)+\"_\"+tp['county_fips_1'].astype(str)+\"_\"+tp['tract_fips_1'].astype(str)\n",
    "tp['tract_2'] = tp['state_fips_2'].astype(str)+\"_\"+tp['county_fips_2'].astype(str)+\"_\"+tp['tract_fips_2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Active; 2: Auto; 3: Mobility Services; 4: Public Transit\n",
      "mode\n",
      "1    12.686272\n",
      "2    76.148262\n",
      "3     4.137105\n",
      "4     7.028362\n",
      "Name: wtperfin, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Simplify Mode Representation\n",
    "tp['mode'] = tp['mode']//100\n",
    "tp['mode'] = tp['mode'].map({1:1,2:2,3:3,4:3,5:4,6:3,7:3})\n",
    "print(\"1: Active; 2: Auto; 3: Mobility Services; 4: Public Transit\")\n",
    "print(tp.groupby('mode').sum()['wtperfin']/tp['wtperfin'].sum()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 84143 trip observations.\n",
      "Columns: ['sampno', 'perno', 'placeGroup_1', 'placeGroup_2', 'locno_1', 'locno_2', 'loctype_1', 'state_1', 'country_1', 'state_fips_1', 'county_fips_1', 'tract_fips_1', 'latitude_1', 'longitude_1', 'loctype_2', 'state_2', 'country_2', 'state_fips_2', 'county_fips_2', 'tract_fips_2', 'latitude_2', 'longitude_2', 'dep_hour', 'dep_min', 'arr_hour', 'arr_min', 'travel_time', 'mode', 'companion', 'distance', 'from_home', 'to_home', 'purp_work', 'purp_school', 'purp_errand', 'purp_recreation', 'ontime_important', 'wtperfin', '12_18yrs', '18_25yrs', '25_55yrs', '55+yrs', 'no_age', 'disability', 'educ_col', 'educ_grad', 'race_white', 'race_black', 'race_asian', 'male', 'female', 'emply_park', 'emply_transit', 'emply_veh', 'emply_wfh', 'emply_flex', 'emply_hours', 'license', 'person_trips', 'person_transit', 'person_freq_transit', 'work_mode', 'hh_inc_0_30', 'hh_inc_30_60', 'hh_inc_60_100', 'hh_inc_100_150', 'hh_inc_150', 'avg_pr_veh', 'home_own', 'home_house', 'home_condo', 'tract_1', 'tract_2']\n"
     ]
    }
   ],
   "source": [
    "print(\"Exported %d trip observations.\" % (len(tp)))\n",
    "print(\"Columns:\", list(tp.columns))\n",
    "tp.to_csv(data_dir+\"trips.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate\n",
    "\n",
    "### Mode choice by origin census tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_mode = tp.groupby(['state_fips_1', 'county_fips_1', 'tract_fips_1', 'mode']).agg({'wtperfin':sum, 'sampno':'count'}).reset_index()\n",
    "\n",
    "\n",
    "o_mode['key'] = 0\n",
    "o_mode_full = pd.merge(o_mode[['state_fips_1', 'county_fips_1', 'tract_fips_1','key']].drop_duplicates(), \n",
    "                       o_mode[['mode','key']].drop_duplicates())\n",
    "\n",
    "o_mode = o_mode.drop(\"key\",1)\n",
    "o_mode_full = o_mode_full.drop(\"key\",1)\n",
    "\n",
    "o_mode = pd.merge(o_mode_full, o_mode, on=['state_fips_1', 'county_fips_1', 'tract_fips_1','mode'], how='left').fillna(0)\n",
    "\n",
    "trip_generation = tp.groupby(['state_fips_1', 'county_fips_1',\n",
    "       'tract_fips_1']).agg({'wtperfin':sum, 'sampno':'count'}).reset_index()\n",
    "\n",
    "o_mode = pd.merge(o_mode, trip_generation, on=['state_fips_1', 'county_fips_1', 'tract_fips_1'],\n",
    "                 suffixes=(\"_mode\",\"_all\"))\n",
    "\n",
    "o_mode['geoid'] = o_mode['state_fips_1'].astype(str)+'_'+o_mode['county_fips_1'].astype(str)+'_'+o_mode['tract_fips_1'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_mode.to_csv(data_dir+\"origin_trip_behavior.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998 origin census tracts exported.\n"
     ]
    }
   ],
   "source": [
    "print(\"%d origin census tracts exported.\" % (len(o_mode)/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode choice by destination census tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mode = tp.groupby(['state_fips_2', 'county_fips_2', 'tract_fips_2', 'mode']).agg({'wtperfin':sum, 'sampno':'count'}).reset_index()\n",
    "d_mode['key'] = 0\n",
    "d_mode_full = pd.merge(d_mode[['state_fips_2', 'county_fips_2', 'tract_fips_2','key']].drop_duplicates(), \n",
    "                       d_mode[['mode','key']].drop_duplicates())\n",
    "\n",
    "d_mode = d_mode.drop(\"key\",1)\n",
    "d_mode_full = d_mode_full.drop(\"key\",1)\n",
    "\n",
    "d_mode = pd.merge(d_mode_full, d_mode, on=['state_fips_2', 'county_fips_2', 'tract_fips_2','mode'], how='left').fillna(0)\n",
    "\n",
    "trip_generation = tp.groupby(['state_fips_2', 'county_fips_2',\n",
    "       'tract_fips_2']).agg({'wtperfin':sum, 'sampno':'count'}).reset_index()\n",
    "\n",
    "d_mode = pd.merge(d_mode, trip_generation, on=['state_fips_2', 'county_fips_2', 'tract_fips_2'],\n",
    "                 suffixes=(\"_mode\",\"_all\"))\n",
    "d_mode['geoid'] = d_mode['state_fips_2'].astype(str)+'_'+d_mode['county_fips_2'].astype(str)+'_'+d_mode['tract_fips_2'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 destination census tracts exported.\n"
     ]
    }
   ],
   "source": [
    "d_mode.to_csv(data_dir+\"destination_trip_behavior.csv\", index=False)\n",
    "print(\"%d destination census tracts exported.\" % (len(d_mode)/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Choice by OD pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips are weighted to reflect representativeness of each sample.\n",
      "# OD pairs: 44253 \t # observations: 84143 \t # weighted trips: 22363279\n",
      "# OD pairs with >5 records: 1835 accounting for 23504 observations (5504411 weighted trips)\n"
     ]
    }
   ],
   "source": [
    "od_weighted = tp.groupby(['tract_1','tract_2'], as_index=False).sum()[['tract_1','tract_2','wtperfin']]\n",
    "od_count = tp.groupby(['tract_1','tract_2'], as_index=False).count()[['tract_1','tract_2','sampno']]\n",
    "od = pd.merge(od_weighted, od_count, on=['tract_1','tract_2'])\n",
    "\n",
    "print(\"Trips are weighted to reflect representativeness of each sample.\")\n",
    "print(\"# OD pairs: %d \\t # observations: %d \\t # weighted trips: %d\" %(len(od), od.sum()['sampno'], od.sum()['wtperfin']))\n",
    "print(\"# OD pairs with >5 records: %d accounting for %d observations (%d weighted trips)\" %\\\n",
    "      (len(od[od['sampno']>5]), od[od['sampno']>5].sum()['sampno'], od[od['sampno']>5].sum()['wtperfin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode = tp.groupby(['tract_1','tract_2','mode'], as_index=False).sum()[['tract_1','tract_2','mode','wtperfin']]\n",
    "\n",
    "od_mode['key'] = 0\n",
    "od['key'] = 0\n",
    "\n",
    "# Create a df with all combinations of od and mode\n",
    "od_mode_full = pd.merge(od[['tract_1','tract_2','key']].drop_duplicates(), od_mode[['mode','key']].drop_duplicates()).drop(\"key\", 1)\n",
    "od_mode = od_mode.drop(\"key\",1)\n",
    "od = od.drop(\"key\",1)\n",
    "\n",
    "od_mode = pd.merge(od_mode_full, od_mode, on=['tract_1','tract_2','mode'], how='outer').fillna(0)\n",
    "od_mode = pd.merge(od_mode, od, on=['tract_1','tract_2'], suffixes=(\"_mode\",\"_od\"))\n",
    "od_mode['mode_share'] = od_mode['wtperfin_mode'] / od_mode['wtperfin_od']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported full OD mode matrix with 44253 pairs of ODs.\n"
     ]
    }
   ],
   "source": [
    "print(\"Exported full OD mode matrix with %d pairs of ODs.\" % (len(od)))\n",
    "od_mode.to_csv(data_dir+\"od_mode.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter OD pairs to pairs with more than 5 observations\n",
    "- A lot of public transit trips are filltered. (possibly due to interstate train travel or commuter rail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od[od['sampno']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_mode = tp.groupby(['tract_1','tract_2','mode'], as_index=False).sum()[['tract_1','tract_2','mode','wtperfin']]\n",
    "\n",
    "od_mode['key'] = 0\n",
    "od['key'] = 0\n",
    "# Use filtered OD (>5 trips)\n",
    "od_mode_full = pd.merge(od[['tract_1','tract_2','key']].drop_duplicates(), od_mode[['mode','key']].drop_duplicates()).drop(\"key\", 1)\n",
    "od_mode = od_mode.drop(\"key\",1)\n",
    "od = od.drop(\"key\",1)\n",
    "\n",
    "od_mode = pd.merge(od_mode_full, od_mode, on=['tract_1','tract_2','mode'], how='outer').fillna(0)\n",
    "od_mode = pd.merge(od_mode, od, on=['tract_1','tract_2'], suffixes=(\"_mode\",\"_od\"))\n",
    "od_mode['mode_share'] = od_mode['wtperfin_mode'] / od_mode['wtperfin_od']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported filtered OD mode matrix with 1835 pairs of ODs.\n"
     ]
    }
   ],
   "source": [
    "print(\"Exported filtered OD mode matrix with %d pairs of ODs.\" % (len(od)))\n",
    "od_mode.to_csv(data_dir+\"od_mode_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split of Census Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Census Tracts to Get Images\n",
    "lc = pd.read_csv(survey_dir+\"location.csv\")\n",
    "lc['geoid'] = lc['state_fips'].astype(str)+\"_\"+lc['county_fips'].astype(str)+\"_\"+lc['tract_fips'].astype(str)\n",
    "\n",
    "lc = lc[['geoid','state_fips','county_fips','tract_fips','latitude','longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. By OD pairs (741 tracts used on models before 20220208)\n",
    "#tracts = pd.concat([od['tract_1'], od['tract_2']]).drop_duplicates().tolist()\n",
    "\n",
    "# 2. By Trip Origins (1337 tracts)\n",
    "# tracts = o_mode[o_mode['sampno_all']>=15]['geoid'].drop_duplicates().tolist()\n",
    "\n",
    "# 3. By Trip Origins (1571 tracts)\n",
    "tracts = o_mode[o_mode['sampno_all']>=10]['geoid'].drop_duplicates().tolist()\n",
    "\n",
    "lc = lc[lc['geoid'].isin(tracts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure the train/test set is consistent with previous runs\n",
    "backup = pd.read_csv(data_dir+\"census_tracts_filtered-1337.csv\")\n",
    "\n",
    "lc = pd.merge(lc, backup[['geoid','train_test']], on='geoid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign train/test status to newly added tracts\n",
    "lc['train_test'] = [int(np.random.rand() < 0.1) if np.isnan(x) else x for x in lc['train_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Census tracts in filtered OD pairs: 1571\n"
     ]
    }
   ],
   "source": [
    "lc.to_csv(data_dir+\"census_tracts_filtered.csv\", index=False)\n",
    "print(\"# Census tracts in filtered OD pairs:\", len(tracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
