{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents part 2 of the complementarity of image and demographic information: the ability of latent space extracted from Autoencoders to predict mode choice and trip generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from dataloader import SurveyDataset, load_aggregate_travel_behavior, load_demo\n",
    "from M1_util_train_test import load_model, test\n",
    "import linear_reg\n",
    "import mnl\n",
    "from setup import out_dir, data_dir, image_dir, model_dir, proj_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = '1571'\n",
    "\n",
    "model_type = 'SAE'\n",
    "sampling = 's'\n",
    "\n",
    "zoomlevel = 'zoom13'\n",
    "output_dim = 1\n",
    "model_run_date = '22021402'\n",
    "\n",
    "variable_names = ['active','auto','mas','pt', 'trpgen']\n",
    "\n",
    "demo_variables = ['tot_population','pct25_34yrs','pct35_50yrs','pctover65yrs',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pct_col_grad','avg_tt_to_work','inc_per_capita']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(proj_dir+\"latent_space/\"+model_type+\"_\"+zoomlevel+\"_\"+str(output_dim**2*2048)+\"_\"+\n",
    "                       model_run_date+\".pkl\", \"rb\") as f: \n",
    "    encoder_output = pkl.load(f)\n",
    "    im = pkl.load(f)\n",
    "    ct = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Embeddings\n",
    "unique_ct = list(set(ct))\n",
    "unique_ct.sort()\n",
    "ct = np.array(ct)\n",
    "aggregate_embeddings = []\n",
    "for i in unique_ct:\n",
    "    aggregate_embeddings.append(np.mean(encoder_output[ct == i], axis=0))\n",
    "aggregate_embeddings = np.array(aggregate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trip Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"origin_trip_behavior.csv\"\n",
    "df_pivot = load_aggregate_travel_behavior(file, data_version)\n",
    "\n",
    "train_test_index = df_pivot['train_test'].astype(bool).to_numpy()\n",
    "# train_test_index = np.random.rand(len(df_pivot)) < 0.2\n",
    "\n",
    "y = df_pivot[variable_names].to_numpy()\n",
    "y_train = y[~train_test_index,:4]\n",
    "y_test = y[train_test_index,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = aggregate_embeddings[~train_test_index, :]\n",
    "x_test = aggregate_embeddings[train_test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train = y[~train_test_index,1]\n",
    "auto_test = y[train_test_index,1]\n",
    "\n",
    "pt_train = y[~train_test_index,3]\n",
    "pt_test = y[train_test_index,3]\n",
    "\n",
    "active_train = y[~train_test_index,0]\n",
    "active_test = y[train_test_index,0]\n",
    "\n",
    "trpgen_train = y[~train_test_index,-1]\n",
    "trpgen_test = y[train_test_index,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression\n",
    "\n",
    "Highlight:\n",
    "\n",
    "Auto Lasso\n",
    "Parameter: 4.00e-06 Train R2: 0.6226 \t Test R: 0.6770 \t Nonzero coef: 81\n",
    "\n",
    "Auto Ridge\n",
    "Parameter: 2.00e-03 Train R2: 0.6554 \t Test R: 0.6694\n",
    "\n",
    "PT Lasso\n",
    "Parameter: 6.00e-06 Train R2: 0.4318 \t Test R: 0.4435 \t Nonzero coef: 22\n",
    "\n",
    "PT Ridge\n",
    "Parameter: 5.00e-03 Train R2: 0.5089 \t Test R: 0.4509\n",
    "\n",
    "Active Lasso\n",
    "Parameter: 3.00e-06 Train R2: 0.5354 \t Test R: 0.5541 \t Nonzero coef: 85\n",
    "\n",
    "Active Ridge\n",
    "Parameter: 3.00e-03 Train R2: 0.5592 \t Test R: 0.5524\n",
    "\n",
    "Trip Gen Lasso\n",
    "Parameter: 1.00e-03 Train R2: 0.0400 \t Test R: 0.0301 \t Nonzero coef: 13\n",
    "\n",
    "Trip Gen Ridge\n",
    "Parameter: 5.00e-02 Train R2: 0.0555 \t Test R: 0.0162"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Auto Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.9998 \t Test R2: -0.5443\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression without Regularization\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_train, auto_train)\n",
    "# with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#     f.write(\"%s,%s,%s,%.4f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], -1, \n",
    "#         lr.score(x_train, auto_train), lr.score(x_test, auto_test), 'lr', zoomlevel,\n",
    "#         np.sum(lr.coef_ != 0), len(lr.coef_)))\n",
    "print(\"Train R2: %.4f \\t Test R2: %.4f\" % (lr.score(x_train, auto_train), lr.score(x_test, auto_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.156e-02, tolerance: 7.704e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9984 \t Test R: -0.7392 \t Nonzero coef: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.783e+00, tolerance: 7.704e-03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-07 Train R2: 0.9454 \t Test R: 0.2914 \t Nonzero coef: 1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+00, tolerance: 7.704e-03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-06 Train R2: 0.7122 \t Test R: 0.6494 \t Nonzero coef: 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.945e-02, tolerance: 7.704e-03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-06 Train R2: 0.6604 \t Test R: 0.6727 \t Nonzero coef: 156\n",
      "Parameter: 3.00e-06 Train R2: 0.6376 \t Test R: 0.6763 \t Nonzero coef: 114\n",
      "Parameter: 4.00e-06 Train R2: 0.6226 \t Test R: 0.6770 \t Nonzero coef: 81\n",
      "Parameter: 5.00e-06 Train R2: 0.6134 \t Test R: 0.6752 \t Nonzero coef: 63\n",
      "Parameter: 6.00e-06 Train R2: 0.6055 \t Test R: 0.6717 \t Nonzero coef: 53\n",
      "Parameter: 7.00e-06 Train R2: 0.5982 \t Test R: 0.6666 \t Nonzero coef: 48\n",
      "Parameter: 8.00e-06 Train R2: 0.5917 \t Test R: 0.6608 \t Nonzero coef: 39\n",
      "Parameter: 1.00e-05 Train R2: 0.5826 \t Test R: 0.6534 \t Nonzero coef: 31\n",
      "Parameter: 2.00e-05 Train R2: 0.5549 \t Test R: 0.6273 \t Nonzero coef: 14\n",
      "Parameter: 5.00e-05 Train R2: 0.4927 \t Test R: 0.5396 \t Nonzero coef: 7\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for a in (1e-6)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, auto_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, auto_train), \n",
    "                                                                                  lasso.score(x_test, auto_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  \"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9959 \t Test R: -0.4623\n",
      "Parameter: 1.00e-04 Train R2: 0.7900 \t Test R: 0.6202\n",
      "Parameter: 1.00e-03 Train R2: 0.6796 \t Test R: 0.6655\n",
      "Parameter: 2.00e-03 Train R2: 0.6554 \t Test R: 0.6694\n",
      "Parameter: 3.00e-03 Train R2: 0.6421 \t Test R: 0.6693\n",
      "Parameter: 4.00e-03 Train R2: 0.6330 \t Test R: 0.6678\n",
      "Parameter: 5.00e-03 Train R2: 0.6260 \t Test R: 0.6659\n",
      "Parameter: 6.00e-03 Train R2: 0.6203 \t Test R: 0.6636\n",
      "Parameter: 7.00e-03 Train R2: 0.6155 \t Test R: 0.6612\n",
      "Parameter: 8.00e-03 Train R2: 0.6112 \t Test R: 0.6586\n",
      "Parameter: 1.00e-02 Train R2: 0.6039 \t Test R: 0.6534\n",
      "Parameter: 2.00e-02 Train R2: 0.5776 \t Test R: 0.6271\n",
      "Parameter: 5.00e-02 Train R2: 0.5246 \t Test R: 0.5617\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-3)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, auto_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, auto_train), \n",
    "                                                              ridge.score(x_test, auto_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  import sys\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e-02, tolerance: 1.373e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9960 \t Test R: -1.8425 \t Nonzero coef: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.159e-01, tolerance: 1.373e-03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-07 Train R2: 0.8526 \t Test R: 0.2409 \t Nonzero coef: 799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.311e-03, tolerance: 1.373e-03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-06 Train R2: 0.5404 \t Test R: 0.4324 \t Nonzero coef: 161\n",
      "Parameter: 2.00e-06 Train R2: 0.4969 \t Test R: 0.4397 \t Nonzero coef: 81\n",
      "Parameter: 3.00e-06 Train R2: 0.4728 \t Test R: 0.4403 \t Nonzero coef: 59\n",
      "Parameter: 4.00e-06 Train R2: 0.4532 \t Test R: 0.4408 \t Nonzero coef: 42\n",
      "Parameter: 5.00e-06 Train R2: 0.4409 \t Test R: 0.4423 \t Nonzero coef: 29\n",
      "Parameter: 6.00e-06 Train R2: 0.4318 \t Test R: 0.4435 \t Nonzero coef: 22\n",
      "Parameter: 7.00e-06 Train R2: 0.4260 \t Test R: 0.4408 \t Nonzero coef: 17\n",
      "Parameter: 8.00e-06 Train R2: 0.4215 \t Test R: 0.4387 \t Nonzero coef: 16\n",
      "Parameter: 1.00e-05 Train R2: 0.4121 \t Test R: 0.4336 \t Nonzero coef: 14\n",
      "Parameter: 2.00e-05 Train R2: 0.3690 \t Test R: 0.3912 \t Nonzero coef: 7\n",
      "Parameter: 5.00e-05 Train R2: 0.2584 \t Test R: 0.2642 \t Nonzero coef: 3\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for a in (1e-6)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, pt_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, pt_train), \n",
    "                                                                                  lasso.score(x_test, pt_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  \"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9838 \t Test R: -1.5064\n",
      "Parameter: 1.00e-04 Train R2: 0.7145 \t Test R: 0.3986\n",
      "Parameter: 1.00e-03 Train R2: 0.5733 \t Test R: 0.4392\n",
      "Parameter: 2.00e-03 Train R2: 0.5437 \t Test R: 0.4469\n",
      "Parameter: 3.00e-03 Train R2: 0.5278 \t Test R: 0.4495\n",
      "Parameter: 4.00e-03 Train R2: 0.5170 \t Test R: 0.4506\n",
      "Parameter: 5.00e-03 Train R2: 0.5089 \t Test R: 0.4509\n",
      "Parameter: 6.00e-03 Train R2: 0.5024 \t Test R: 0.4508\n",
      "Parameter: 7.00e-03 Train R2: 0.4970 \t Test R: 0.4505\n",
      "Parameter: 8.00e-03 Train R2: 0.4923 \t Test R: 0.4500\n",
      "Parameter: 1.00e-02 Train R2: 0.4846 \t Test R: 0.4488\n",
      "Parameter: 2.00e-02 Train R2: 0.4597 \t Test R: 0.4398\n",
      "Parameter: 5.00e-02 Train R2: 0.4185 \t Test R: 0.4089\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-3)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, pt_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, pt_train), \n",
    "                                                              ridge.score(x_test, pt_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.582e-02, tolerance: 3.791e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9976 \t Test R: -1.6841 \t Nonzero coef: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+00, tolerance: 3.791e-03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-07 Train R2: 0.9115 \t Test R: 0.1510 \t Nonzero coef: 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.146e-01, tolerance: 3.791e-03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-06 Train R2: 0.6169 \t Test R: 0.5213 \t Nonzero coef: 238\n",
      "Parameter: 2.00e-06 Train R2: 0.5626 \t Test R: 0.5487 \t Nonzero coef: 134\n",
      "Parameter: 3.00e-06 Train R2: 0.5354 \t Test R: 0.5541 \t Nonzero coef: 85\n",
      "Parameter: 4.00e-06 Train R2: 0.5183 \t Test R: 0.5513 \t Nonzero coef: 60\n",
      "Parameter: 5.00e-06 Train R2: 0.5059 \t Test R: 0.5517 \t Nonzero coef: 45\n",
      "Parameter: 6.00e-06 Train R2: 0.4972 \t Test R: 0.5472 \t Nonzero coef: 39\n",
      "Parameter: 7.00e-06 Train R2: 0.4887 \t Test R: 0.5425 \t Nonzero coef: 35\n",
      "Parameter: 8.00e-06 Train R2: 0.4815 \t Test R: 0.5367 \t Nonzero coef: 28\n",
      "Parameter: 1.00e-05 Train R2: 0.4714 \t Test R: 0.5276 \t Nonzero coef: 22\n",
      "Parameter: 2.00e-05 Train R2: 0.4385 \t Test R: 0.4899 \t Nonzero coef: 12\n",
      "Parameter: 5.00e-05 Train R2: 0.3489 \t Test R: 0.3816 \t Nonzero coef: 4\n"
     ]
    }
   ],
   "source": [
    "for a in (1e-6)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, active_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, active_train), \n",
    "                                                                                  lasso.score(x_test, active_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  \"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9969 \t Test R: -0.8904\n",
      "Parameter: 1.00e-04 Train R2: 0.7400 \t Test R: 0.5110\n",
      "Parameter: 1.00e-03 Train R2: 0.6048 \t Test R: 0.5468\n",
      "Parameter: 2.00e-03 Train R2: 0.5754 \t Test R: 0.5514\n",
      "Parameter: 3.00e-03 Train R2: 0.5592 \t Test R: 0.5524\n",
      "Parameter: 4.00e-03 Train R2: 0.5481 \t Test R: 0.5521\n",
      "Parameter: 5.00e-03 Train R2: 0.5396 \t Test R: 0.5509\n",
      "Parameter: 6.00e-03 Train R2: 0.5327 \t Test R: 0.5494\n",
      "Parameter: 7.00e-03 Train R2: 0.5268 \t Test R: 0.5476\n",
      "Parameter: 8.00e-03 Train R2: 0.5218 \t Test R: 0.5457\n",
      "Parameter: 1.00e-02 Train R2: 0.5132 \t Test R: 0.5414\n",
      "Parameter: 2.00e-02 Train R2: 0.4840 \t Test R: 0.5187\n",
      "Parameter: 5.00e-02 Train R2: 0.4311 \t Test R: 0.4605\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-3)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, active_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, active_train), \n",
    "                                                              ridge.score(x_test, active_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Trip Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+03, tolerance: 3.630e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9938 \t Test R: -3.8934 \t Nonzero coef: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.006e+04, tolerance: 3.630e+01\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-05 Train R2: 0.8816 \t Test R: -1.1713 \t Nonzero coef: 1176\n",
      "Parameter: 6.00e-04 Train R2: 0.0692 \t Test R: 0.0130 \t Nonzero coef: 38\n",
      "Parameter: 7.00e-04 Train R2: 0.0549 \t Test R: 0.0223 \t Nonzero coef: 25\n",
      "Parameter: 8.00e-04 Train R2: 0.0473 \t Test R: 0.0281 \t Nonzero coef: 18\n",
      "Parameter: 1.00e-03 Train R2: 0.0400 \t Test R: 0.0301 \t Nonzero coef: 13\n",
      "Parameter: 1.10e-03 Train R2: 0.0374 \t Test R: 0.0301 \t Nonzero coef: 11\n",
      "Parameter: 1.20e-03 Train R2: 0.0353 \t Test R: 0.0293 \t Nonzero coef: 10\n",
      "Parameter: 1.30e-03 Train R2: 0.0334 \t Test R: 0.0290 \t Nonzero coef: 9\n",
      "Parameter: 1.40e-03 Train R2: 0.0320 \t Test R: 0.0281 \t Nonzero coef: 8\n",
      "Parameter: 1.50e-03 Train R2: 0.0306 \t Test R: 0.0271 \t Nonzero coef: 8\n",
      "Parameter: 2.00e-03 Train R2: 0.0228 \t Test R: 0.0230 \t Nonzero coef: 5\n",
      "Parameter: 5.00e-03 Train R2: 0.0076 \t Test R: 0.0035 \t Nonzero coef: 2\n"
     ]
    }
   ],
   "source": [
    "for a in (1e-4)*np.array([0,0.1,6,7,8,10,11,12,13,14,15,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, trpgen_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, trpgen_train), \n",
    "                                                                                  lasso.score(x_test, trpgen_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  \"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.9954 \t Test R: -3.3639\n",
      "Parameter: 1.00e-03 Train R2: 0.2700 \t Test R: -0.1056\n",
      "Parameter: 1.00e-02 Train R2: 0.1170 \t Test R: -0.0025\n",
      "Parameter: 2.00e-02 Train R2: 0.0855 \t Test R: 0.0103\n",
      "Parameter: 3.00e-02 Train R2: 0.0707 \t Test R: 0.0142\n",
      "Parameter: 4.00e-02 Train R2: 0.0617 \t Test R: 0.0157\n",
      "Parameter: 5.00e-02 Train R2: 0.0555 \t Test R: 0.0162\n",
      "Parameter: 6.00e-02 Train R2: 0.0509 \t Test R: 0.0162\n",
      "Parameter: 7.00e-02 Train R2: 0.0474 \t Test R: 0.0161\n",
      "Parameter: 8.00e-02 Train R2: 0.0445 \t Test R: 0.0158\n",
      "Parameter: 1.00e-01 Train R2: 0.0401 \t Test R: 0.0152\n",
      "Parameter: 2.00e-01 Train R2: 0.0291 \t Test R: 0.0120\n",
      "Parameter: 5.00e-01 Train R2: 0.0184 \t Test R: 0.0069\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-2)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, trpgen_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, trpgen_train), \n",
    "                                                              ridge.score(x_test, trpgen_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear Regression (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pytorch_lr(w1_list, lr_list, x1, x2, y1, y2, reg_type='L2'):\n",
    "    \n",
    "    mseloss = nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    trainset = SurveyDataset(torch.tensor(x1,  dtype=torch.float), torch.tensor(y1, dtype=torch.float))\n",
    "    trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "\n",
    "    testset = SurveyDataset(torch.tensor(x2, dtype=torch.float), torch.tensor(y2, dtype=torch.float))\n",
    "    testloader = DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "    # decay rates for embedding\n",
    "#     w1_list = [0]\n",
    "    # decay rates for demo (There is no demo in this case)\n",
    "    w2_list = [0]\n",
    "    # lr_list = [0.005,0.01, 0.02]\n",
    "#     lr_list = [0.002]\n",
    "\n",
    "    dim_demo = 0\n",
    "    dim_embed = x1.shape[1]\n",
    "\n",
    "    for lr in lr_list:\n",
    "\n",
    "        for w1, w2 in itertools.product(w1_list, w2_list):\n",
    "\n",
    "            # model setup\n",
    "            model = linear_reg.LR(dim_embed=dim_embed, dim_demo=dim_demo)\n",
    "\n",
    "#             print(model)\n",
    "            embed_params = []\n",
    "            demo_params = []\n",
    "            other_params = []\n",
    "            for name, m in model.named_parameters():\n",
    "        #             print(name)\n",
    "                if 'embed' in name:\n",
    "                    embed_params.append(m)\n",
    "                elif 'demo' in name:\n",
    "                    demo_params.append(m)\n",
    "                else:\n",
    "                    other_params.append(m)\n",
    "\n",
    "#             optimizer = torch.optim.Adam([{'params':demo_params,'lr':lr}])\n",
    "            if reg_type == 'L2':\n",
    "                optimizer = torch.optim.Adam([{'params':embed_params,'weight_decay':w1,'lr':lr},\n",
    "                                          {'params':demo_params,'weight_decay':w2, 'lr':lr},\n",
    "                                          {'params':other_params,'weight_decay':0, 'lr':lr}])\n",
    "            else:\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#             print(optimizer)\n",
    "#             print(demo_params)\n",
    "            \n",
    "            # model training\n",
    "            ref1 = 0\n",
    "            ref2 = 0\n",
    "\n",
    "            for epoch in range(10000):\n",
    "\n",
    "                mse_ = 0\n",
    "\n",
    "                for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "                    # Compute prediction and loss\n",
    "                    pred = model(x_batch, None)\n",
    "                    pred = F.relu(pred).squeeze()\n",
    "\n",
    "                    mse = mseloss(pred, y_batch)\n",
    "                    mse_ += mse.item()\n",
    "\n",
    "                    if reg_type == 'L1':\n",
    "                        l1_reg = torch.tensor(0.)\n",
    "                        for p in embed_params:\n",
    "                            l1_reg += w1 * torch.norm(p,1)\n",
    "                        mse += l1_reg\n",
    "                        \n",
    "                    # Backpropagation\n",
    "                    optimizer.zero_grad()\n",
    "                    mse.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    model.embed.weight.data = (torch.abs(model.embed.weight)>1e-3) * model.embed.weight\n",
    "                        \n",
    "\n",
    "                train_r = r2_score(y_batch.numpy(), pred.detach().numpy())\n",
    "                train_mse = mse_/len(trainset)\n",
    "            \n",
    "#                 for i in embed_params:\n",
    "#                     print(torch.sum(i==0))\n",
    "#                     print(torch.min(torch.abs(i)))\n",
    "#                     break\n",
    "                        \n",
    "                if epoch % 50 == 0:\n",
    "                    print(f\"[epoch: {epoch:>3d}] Train MSE : {train_mse:.4f} R2 score: {train_r:.3f} \")\n",
    "                loss_ = train_mse\n",
    "\n",
    "                if epoch % 5 == 0:\n",
    "                    if epoch >=40:\n",
    "                        if (np.abs(loss_ - ref1)/ref1<0.0005) & (np.abs(loss_ - ref2)/ref2<0.0005):\n",
    "                            print(\"Early stopping at epoch\", epoch)\n",
    "                            print(ref2, ref1, loss_)\n",
    "                            break\n",
    "                        if (ref1 < loss_) & (ref1 < ref2):\n",
    "                            print(\"Diverging. stop.\")\n",
    "                            break\n",
    "                        if loss_ < best:\n",
    "                            best = loss_\n",
    "                            best_epoch = epoch\n",
    "                    else:\n",
    "                        best = loss_\n",
    "                        best_epoch = epoch\n",
    "\n",
    "                    ref2 = ref1\n",
    "                    ref1 = loss_\n",
    "\n",
    "                if epoch % 50 == 0:\n",
    "\n",
    "                    mse_ = 0 \n",
    "\n",
    "                    for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "                        pred = model(x_batch, None)\n",
    "                        pred = F.relu(pred).squeeze()\n",
    "\n",
    "                        mse = mseloss(pred, y_batch)\n",
    "                        mse_ += mse.item()\n",
    "                        \n",
    "#                     print(len(testset))\n",
    "\n",
    "                    test_mse = mse_/len(testset)\n",
    "                    test_r = r2_score(y_batch.numpy(),pred.detach().numpy())\n",
    "\n",
    "                    print(f\"[epoch: {epoch:>3d}] Test MSE {test_mse:.4f} R2 score: {test_r:.3f} \")\n",
    "            \n",
    "    for i in embed_params:\n",
    "        print(torch.sum(i==0))\n",
    "        print(torch.min(torch.abs(i)))\n",
    "        break\n",
    "        \n",
    "    return model\n",
    "\n",
    "    #         with open(out_dir+model_code+\"_regression_trpgen.csv\", \"a\") as f:\n",
    "    #             f.write(\"%s,%s,%s,%s,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f\\n\" % \\\n",
    "    #                 (model_run_date, model_type, zoomlevel, \"LR\", lr, w1, \n",
    "    #                   train_rmse, train_r, test_rmse, test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(905)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch:   0] Train MSE : 0.6379 R2 score: -10.708 \n",
      "[epoch:   0] Test MSE 0.6410 R2 score: -11.647 \n",
      "tensor(946)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(995)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1040)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1080)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1124)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1173)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1232)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1281)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1328)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1383)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1429)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch:  50] Train MSE : 0.3722 R2 score: -5.831 \n",
      "[epoch:  50] Test MSE 0.3782 R2 score: -6.462 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 100] Train MSE : 0.2309 R2 score: -3.238 \n",
      "[epoch: 100] Test MSE 0.2345 R2 score: -3.627 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 150] Train MSE : 0.1451 R2 score: -1.664 \n",
      "[epoch: 150] Test MSE 0.1467 R2 score: -1.894 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 200] Train MSE : 0.0976 R2 score: -0.791 \n",
      "[epoch: 200] Test MSE 0.0974 R2 score: -0.921 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 250] Train MSE : 0.0737 R2 score: -0.352 \n",
      "[epoch: 250] Test MSE 0.0721 R2 score: -0.422 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 300] Train MSE : 0.0628 R2 score: -0.153 \n",
      "[epoch: 300] Test MSE 0.0602 R2 score: -0.187 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 350] Train MSE : 0.0583 R2 score: -0.071 \n",
      "[epoch: 350] Test MSE 0.0550 R2 score: -0.084 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 400] Train MSE : 0.0566 R2 score: -0.039 \n",
      "[epoch: 400] Test MSE 0.0528 R2 score: -0.041 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 450] Train MSE : 0.0559 R2 score: -0.026 \n",
      "[epoch: 450] Test MSE 0.0518 R2 score: -0.022 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 500] Train MSE : 0.0556 R2 score: -0.020 \n",
      "[epoch: 500] Test MSE 0.0513 R2 score: -0.012 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 550] Train MSE : 0.0553 R2 score: -0.015 \n",
      "[epoch: 550] Test MSE 0.0510 R2 score: -0.006 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 600] Train MSE : 0.0551 R2 score: -0.011 \n",
      "[epoch: 600] Test MSE 0.0507 R2 score: -0.000 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 650] Train MSE : 0.0548 R2 score: -0.007 \n",
      "[epoch: 650] Test MSE 0.0505 R2 score: 0.004 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 700] Train MSE : 0.0546 R2 score: -0.002 \n",
      "[epoch: 700] Test MSE 0.0502 R2 score: 0.009 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 750] Train MSE : 0.0543 R2 score: 0.002 \n",
      "[epoch: 750] Test MSE 0.0500 R2 score: 0.014 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 800] Train MSE : 0.0541 R2 score: 0.007 \n",
      "[epoch: 800] Test MSE 0.0497 R2 score: 0.019 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 850] Train MSE : 0.0538 R2 score: 0.012 \n",
      "[epoch: 850] Test MSE 0.0495 R2 score: 0.024 \n",
      "tensor(1430)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1431)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1432)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 900] Train MSE : 0.0536 R2 score: 0.017 \n",
      "[epoch: 900] Test MSE 0.0492 R2 score: 0.029 \n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1433)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "[epoch: 950] Train MSE : 0.0533 R2 score: 0.021 \n",
      "[epoch: 950] Test MSE 0.0490 R2 score: 0.033 \n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1434)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor(1435)\n",
      "tensor(0., grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model_ls = pytorch_lr(w1_list=[3e-3], lr_list=[0.001], x1=x_train, x2=x_test, y1=auto_train, y2=auto_test, reg_type='L1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2048)\n"
     ]
    }
   ],
   "source": [
    "for i in model_ls.named_parameters():\n",
    "    print(torch.sum(torch.abs(i[1])>1e-5))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e3ef7fd786a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membed_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embed_params' is not defined"
     ]
    }
   ],
   "source": [
    "for i in embed_params:\n",
    "    print(torch.sum(i[1]==0))\n",
    "    print(torch.min(torch.abs(i[1])))\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   0] Train MSE : 0.6495 R2 score: -10.921 \n",
      "[epoch:   0] Test MSE 0.6646 R2 score: -12.113 \n",
      "[epoch:  50] Train MSE : 0.2005 R2 score: -2.681 \n",
      "[epoch:  50] Test MSE 0.2001 R2 score: -2.948 \n",
      "[epoch: 100] Train MSE : 0.0712 R2 score: -0.307 \n",
      "[epoch: 100] Test MSE 0.0687 R2 score: -0.356 \n",
      "[epoch: 150] Train MSE : 0.0568 R2 score: -0.042 \n",
      "[epoch: 150] Test MSE 0.0525 R2 score: -0.036 \n",
      "[epoch: 200] Train MSE : 0.0557 R2 score: -0.022 \n",
      "[epoch: 200] Test MSE 0.0509 R2 score: -0.005 \n",
      "[epoch: 250] Train MSE : 0.0551 R2 score: -0.011 \n",
      "[epoch: 250] Test MSE 0.0503 R2 score: 0.007 \n",
      "[epoch: 300] Train MSE : 0.0544 R2 score: 0.001 \n",
      "[epoch: 300] Test MSE 0.0497 R2 score: 0.019 \n",
      "[epoch: 350] Train MSE : 0.0537 R2 score: 0.014 \n",
      "[epoch: 350] Test MSE 0.0490 R2 score: 0.032 \n",
      "[epoch: 400] Train MSE : 0.0530 R2 score: 0.027 \n",
      "[epoch: 400] Test MSE 0.0484 R2 score: 0.046 \n",
      "[epoch: 450] Train MSE : 0.0523 R2 score: 0.041 \n",
      "[epoch: 450] Test MSE 0.0477 R2 score: 0.060 \n",
      "[epoch: 500] Train MSE : 0.0515 R2 score: 0.055 \n",
      "[epoch: 500] Test MSE 0.0469 R2 score: 0.074 \n",
      "[epoch: 550] Train MSE : 0.0507 R2 score: 0.069 \n",
      "[epoch: 550] Test MSE 0.0462 R2 score: 0.088 \n",
      "[epoch: 600] Train MSE : 0.0500 R2 score: 0.083 \n",
      "[epoch: 600] Test MSE 0.0455 R2 score: 0.102 \n",
      "[epoch: 650] Train MSE : 0.0492 R2 score: 0.097 \n",
      "[epoch: 650] Test MSE 0.0448 R2 score: 0.117 \n",
      "[epoch: 700] Train MSE : 0.0484 R2 score: 0.111 \n",
      "[epoch: 700] Test MSE 0.0440 R2 score: 0.131 \n",
      "[epoch: 750] Train MSE : 0.0476 R2 score: 0.125 \n",
      "[epoch: 750] Test MSE 0.0433 R2 score: 0.146 \n",
      "[epoch: 800] Train MSE : 0.0469 R2 score: 0.139 \n",
      "[epoch: 800] Test MSE 0.0426 R2 score: 0.160 \n",
      "[epoch: 850] Train MSE : 0.0461 R2 score: 0.153 \n",
      "[epoch: 850] Test MSE 0.0419 R2 score: 0.173 \n",
      "[epoch: 900] Train MSE : 0.0454 R2 score: 0.167 \n",
      "[epoch: 900] Test MSE 0.0412 R2 score: 0.187 \n",
      "[epoch: 950] Train MSE : 0.0447 R2 score: 0.180 \n",
      "[epoch: 950] Test MSE 0.0405 R2 score: 0.200 \n",
      "[epoch: 1000] Train MSE : 0.0440 R2 score: 0.193 \n",
      "[epoch: 1000] Test MSE 0.0399 R2 score: 0.213 \n",
      "[epoch: 1050] Train MSE : 0.0433 R2 score: 0.205 \n",
      "[epoch: 1050] Test MSE 0.0392 R2 score: 0.226 \n",
      "[epoch: 1100] Train MSE : 0.0427 R2 score: 0.217 \n",
      "[epoch: 1100] Test MSE 0.0386 R2 score: 0.238 \n",
      "[epoch: 1150] Train MSE : 0.0420 R2 score: 0.229 \n",
      "[epoch: 1150] Test MSE 0.0380 R2 score: 0.250 \n",
      "[epoch: 1200] Train MSE : 0.0414 R2 score: 0.240 \n",
      "[epoch: 1200] Test MSE 0.0374 R2 score: 0.261 \n",
      "[epoch: 1250] Train MSE : 0.0408 R2 score: 0.251 \n",
      "[epoch: 1250] Test MSE 0.0369 R2 score: 0.272 \n",
      "[epoch: 1300] Train MSE : 0.0402 R2 score: 0.262 \n",
      "[epoch: 1300] Test MSE 0.0363 R2 score: 0.283 \n",
      "[epoch: 1350] Train MSE : 0.0397 R2 score: 0.272 \n",
      "[epoch: 1350] Test MSE 0.0358 R2 score: 0.293 \n",
      "[epoch: 1400] Train MSE : 0.0391 R2 score: 0.282 \n",
      "[epoch: 1400] Test MSE 0.0353 R2 score: 0.303 \n",
      "[epoch: 1450] Train MSE : 0.0386 R2 score: 0.291 \n",
      "[epoch: 1450] Test MSE 0.0348 R2 score: 0.313 \n",
      "[epoch: 1500] Train MSE : 0.0381 R2 score: 0.300 \n",
      "[epoch: 1500] Test MSE 0.0344 R2 score: 0.322 \n",
      "[epoch: 1550] Train MSE : 0.0377 R2 score: 0.309 \n",
      "[epoch: 1550] Test MSE 0.0339 R2 score: 0.331 \n",
      "[epoch: 1600] Train MSE : 0.0372 R2 score: 0.317 \n",
      "[epoch: 1600] Test MSE 0.0335 R2 score: 0.339 \n",
      "[epoch: 1650] Train MSE : 0.0368 R2 score: 0.325 \n",
      "[epoch: 1650] Test MSE 0.0331 R2 score: 0.347 \n",
      "[epoch: 1700] Train MSE : 0.0363 R2 score: 0.333 \n",
      "[epoch: 1700] Test MSE 0.0327 R2 score: 0.355 \n",
      "[epoch: 1750] Train MSE : 0.0359 R2 score: 0.341 \n",
      "[epoch: 1750] Test MSE 0.0323 R2 score: 0.363 \n",
      "[epoch: 1800] Train MSE : 0.0355 R2 score: 0.348 \n",
      "[epoch: 1800] Test MSE 0.0319 R2 score: 0.370 \n",
      "[epoch: 1850] Train MSE : 0.0352 R2 score: 0.355 \n",
      "[epoch: 1850] Test MSE 0.0316 R2 score: 0.377 \n",
      "[epoch: 1900] Train MSE : 0.0348 R2 score: 0.361 \n",
      "[epoch: 1900] Test MSE 0.0312 R2 score: 0.384 \n",
      "[epoch: 1950] Train MSE : 0.0345 R2 score: 0.368 \n",
      "[epoch: 1950] Test MSE 0.0309 R2 score: 0.390 \n",
      "[epoch: 2000] Train MSE : 0.0341 R2 score: 0.374 \n",
      "[epoch: 2000] Test MSE 0.0306 R2 score: 0.397 \n",
      "[epoch: 2050] Train MSE : 0.0338 R2 score: 0.380 \n",
      "[epoch: 2050] Test MSE 0.0303 R2 score: 0.403 \n",
      "[epoch: 2100] Train MSE : 0.0335 R2 score: 0.386 \n",
      "[epoch: 2100] Test MSE 0.0300 R2 score: 0.409 \n",
      "[epoch: 2150] Train MSE : 0.0332 R2 score: 0.391 \n",
      "[epoch: 2150] Test MSE 0.0297 R2 score: 0.415 \n",
      "[epoch: 2200] Train MSE : 0.0329 R2 score: 0.397 \n",
      "[epoch: 2200] Test MSE 0.0294 R2 score: 0.420 \n",
      "[epoch: 2250] Train MSE : 0.0326 R2 score: 0.402 \n",
      "[epoch: 2250] Test MSE 0.0291 R2 score: 0.426 \n",
      "[epoch: 2300] Train MSE : 0.0323 R2 score: 0.407 \n",
      "[epoch: 2300] Test MSE 0.0288 R2 score: 0.431 \n",
      "[epoch: 2350] Train MSE : 0.0320 R2 score: 0.412 \n",
      "[epoch: 2350] Test MSE 0.0285 R2 score: 0.437 \n",
      "[epoch: 2400] Train MSE : 0.0317 R2 score: 0.417 \n",
      "[epoch: 2400] Test MSE 0.0283 R2 score: 0.442 \n",
      "[epoch: 2450] Train MSE : 0.0315 R2 score: 0.422 \n",
      "[epoch: 2450] Test MSE 0.0280 R2 score: 0.447 \n",
      "[epoch: 2500] Train MSE : 0.0312 R2 score: 0.427 \n",
      "[epoch: 2500] Test MSE 0.0278 R2 score: 0.452 \n",
      "[epoch: 2550] Train MSE : 0.0310 R2 score: 0.432 \n",
      "[epoch: 2550] Test MSE 0.0275 R2 score: 0.457 \n",
      "[epoch: 2600] Train MSE : 0.0307 R2 score: 0.436 \n",
      "[epoch: 2600] Test MSE 0.0273 R2 score: 0.462 \n",
      "[epoch: 2650] Train MSE : 0.0305 R2 score: 0.441 \n",
      "[epoch: 2650] Test MSE 0.0270 R2 score: 0.467 \n",
      "[epoch: 2700] Train MSE : 0.0302 R2 score: 0.445 \n",
      "[epoch: 2700] Test MSE 0.0268 R2 score: 0.472 \n",
      "[epoch: 2750] Train MSE : 0.0300 R2 score: 0.449 \n",
      "[epoch: 2750] Test MSE 0.0265 R2 score: 0.477 \n",
      "[epoch: 2800] Train MSE : 0.0298 R2 score: 0.453 \n",
      "[epoch: 2800] Test MSE 0.0263 R2 score: 0.481 \n",
      "[epoch: 2850] Train MSE : 0.0296 R2 score: 0.457 \n",
      "[epoch: 2850] Test MSE 0.0261 R2 score: 0.486 \n",
      "[epoch: 2900] Train MSE : 0.0293 R2 score: 0.461 \n",
      "[epoch: 2900] Test MSE 0.0258 R2 score: 0.490 \n",
      "[epoch: 2950] Train MSE : 0.0291 R2 score: 0.465 \n",
      "[epoch: 2950] Test MSE 0.0256 R2 score: 0.495 \n",
      "[epoch: 3000] Train MSE : 0.0289 R2 score: 0.469 \n",
      "[epoch: 3000] Test MSE 0.0254 R2 score: 0.499 \n",
      "[epoch: 3050] Train MSE : 0.0287 R2 score: 0.473 \n",
      "[epoch: 3050] Test MSE 0.0252 R2 score: 0.504 \n",
      "[epoch: 3100] Train MSE : 0.0285 R2 score: 0.477 \n",
      "[epoch: 3100] Test MSE 0.0249 R2 score: 0.508 \n",
      "[epoch: 3150] Train MSE : 0.0283 R2 score: 0.480 \n",
      "[epoch: 3150] Test MSE 0.0247 R2 score: 0.512 \n",
      "[epoch: 3200] Train MSE : 0.0281 R2 score: 0.484 \n",
      "[epoch: 3200] Test MSE 0.0245 R2 score: 0.517 \n",
      "[epoch: 3250] Train MSE : 0.0279 R2 score: 0.487 \n",
      "[epoch: 3250] Test MSE 0.0243 R2 score: 0.521 \n",
      "[epoch: 3300] Train MSE : 0.0277 R2 score: 0.491 \n",
      "[epoch: 3300] Test MSE 0.0241 R2 score: 0.525 \n",
      "[epoch: 3350] Train MSE : 0.0276 R2 score: 0.494 \n",
      "[epoch: 3350] Test MSE 0.0239 R2 score: 0.529 \n",
      "[epoch: 3400] Train MSE : 0.0274 R2 score: 0.497 \n",
      "[epoch: 3400] Test MSE 0.0237 R2 score: 0.533 \n",
      "[epoch: 3450] Train MSE : 0.0272 R2 score: 0.501 \n",
      "[epoch: 3450] Test MSE 0.0235 R2 score: 0.537 \n",
      "[epoch: 3500] Train MSE : 0.0270 R2 score: 0.504 \n",
      "[epoch: 3500] Test MSE 0.0233 R2 score: 0.541 \n",
      "[epoch: 3550] Train MSE : 0.0269 R2 score: 0.507 \n",
      "[epoch: 3550] Test MSE 0.0231 R2 score: 0.544 \n",
      "[epoch: 3600] Train MSE : 0.0267 R2 score: 0.510 \n",
      "[epoch: 3600] Test MSE 0.0229 R2 score: 0.548 \n",
      "[epoch: 3650] Train MSE : 0.0265 R2 score: 0.513 \n",
      "[epoch: 3650] Test MSE 0.0227 R2 score: 0.552 \n",
      "[epoch: 3700] Train MSE : 0.0264 R2 score: 0.516 \n",
      "[epoch: 3700] Test MSE 0.0225 R2 score: 0.555 \n",
      "[epoch: 3750] Train MSE : 0.0262 R2 score: 0.518 \n",
      "[epoch: 3750] Test MSE 0.0223 R2 score: 0.559 \n",
      "[epoch: 3800] Train MSE : 0.0261 R2 score: 0.521 \n",
      "[epoch: 3800] Test MSE 0.0222 R2 score: 0.563 \n",
      "[epoch: 3850] Train MSE : 0.0259 R2 score: 0.524 \n",
      "[epoch: 3850] Test MSE 0.0220 R2 score: 0.566 \n",
      "[epoch: 3900] Train MSE : 0.0258 R2 score: 0.526 \n",
      "[epoch: 3900] Test MSE 0.0218 R2 score: 0.569 \n",
      "[epoch: 3950] Train MSE : 0.0257 R2 score: 0.529 \n",
      "[epoch: 3950] Test MSE 0.0217 R2 score: 0.573 \n",
      "[epoch: 4000] Train MSE : 0.0255 R2 score: 0.531 \n",
      "[epoch: 4000] Test MSE 0.0215 R2 score: 0.576 \n",
      "[epoch: 4050] Train MSE : 0.0254 R2 score: 0.534 \n",
      "[epoch: 4050] Test MSE 0.0213 R2 score: 0.579 \n",
      "[epoch: 4100] Train MSE : 0.0253 R2 score: 0.536 \n",
      "[epoch: 4100] Test MSE 0.0212 R2 score: 0.582 \n",
      "[epoch: 4150] Train MSE : 0.0252 R2 score: 0.538 \n",
      "[epoch: 4150] Test MSE 0.0210 R2 score: 0.586 \n",
      "[epoch: 4200] Train MSE : 0.0250 R2 score: 0.541 \n",
      "[epoch: 4200] Test MSE 0.0208 R2 score: 0.589 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4250] Train MSE : 0.0249 R2 score: 0.543 \n",
      "[epoch: 4250] Test MSE 0.0207 R2 score: 0.592 \n",
      "[epoch: 4300] Train MSE : 0.0248 R2 score: 0.545 \n",
      "[epoch: 4300] Test MSE 0.0205 R2 score: 0.595 \n",
      "[epoch: 4350] Train MSE : 0.0247 R2 score: 0.547 \n",
      "[epoch: 4350] Test MSE 0.0204 R2 score: 0.597 \n",
      "[epoch: 4400] Train MSE : 0.0246 R2 score: 0.549 \n",
      "[epoch: 4400] Test MSE 0.0203 R2 score: 0.600 \n",
      "[epoch: 4450] Train MSE : 0.0245 R2 score: 0.551 \n",
      "[epoch: 4450] Test MSE 0.0201 R2 score: 0.603 \n",
      "[epoch: 4500] Train MSE : 0.0244 R2 score: 0.553 \n",
      "[epoch: 4500] Test MSE 0.0200 R2 score: 0.606 \n",
      "[epoch: 4550] Train MSE : 0.0243 R2 score: 0.555 \n",
      "[epoch: 4550] Test MSE 0.0199 R2 score: 0.608 \n",
      "[epoch: 4600] Train MSE : 0.0242 R2 score: 0.556 \n",
      "[epoch: 4600] Test MSE 0.0197 R2 score: 0.611 \n",
      "[epoch: 4650] Train MSE : 0.0241 R2 score: 0.558 \n",
      "[epoch: 4650] Test MSE 0.0196 R2 score: 0.613 \n",
      "[epoch: 4700] Train MSE : 0.0240 R2 score: 0.560 \n",
      "[epoch: 4700] Test MSE 0.0195 R2 score: 0.616 \n",
      "[epoch: 4750] Train MSE : 0.0239 R2 score: 0.561 \n",
      "[epoch: 4750] Test MSE 0.0193 R2 score: 0.618 \n",
      "[epoch: 4800] Train MSE : 0.0238 R2 score: 0.563 \n",
      "[epoch: 4800] Test MSE 0.0192 R2 score: 0.621 \n",
      "[epoch: 4850] Train MSE : 0.0237 R2 score: 0.564 \n",
      "[epoch: 4850] Test MSE 0.0191 R2 score: 0.623 \n",
      "[epoch: 4900] Train MSE : 0.0236 R2 score: 0.566 \n",
      "[epoch: 4900] Test MSE 0.0190 R2 score: 0.625 \n",
      "[epoch: 4950] Train MSE : 0.0236 R2 score: 0.567 \n",
      "[epoch: 4950] Test MSE 0.0189 R2 score: 0.627 \n",
      "[epoch: 5000] Train MSE : 0.0235 R2 score: 0.569 \n",
      "[epoch: 5000] Test MSE 0.0188 R2 score: 0.629 \n",
      "[epoch: 5050] Train MSE : 0.0234 R2 score: 0.570 \n",
      "[epoch: 5050] Test MSE 0.0187 R2 score: 0.631 \n",
      "[epoch: 5100] Train MSE : 0.0233 R2 score: 0.572 \n",
      "[epoch: 5100] Test MSE 0.0186 R2 score: 0.633 \n",
      "[epoch: 5150] Train MSE : 0.0233 R2 score: 0.573 \n",
      "[epoch: 5150] Test MSE 0.0185 R2 score: 0.635 \n",
      "[epoch: 5200] Train MSE : 0.0232 R2 score: 0.574 \n",
      "[epoch: 5200] Test MSE 0.0184 R2 score: 0.637 \n",
      "[epoch: 5250] Train MSE : 0.0231 R2 score: 0.575 \n",
      "[epoch: 5250] Test MSE 0.0183 R2 score: 0.639 \n",
      "[epoch: 5300] Train MSE : 0.0231 R2 score: 0.577 \n",
      "[epoch: 5300] Test MSE 0.0182 R2 score: 0.641 \n",
      "[epoch: 5350] Train MSE : 0.0230 R2 score: 0.578 \n",
      "[epoch: 5350] Test MSE 0.0181 R2 score: 0.642 \n",
      "[epoch: 5400] Train MSE : 0.0229 R2 score: 0.579 \n",
      "[epoch: 5400] Test MSE 0.0180 R2 score: 0.644 \n",
      "[epoch: 5450] Train MSE : 0.0229 R2 score: 0.580 \n",
      "[epoch: 5450] Test MSE 0.0180 R2 score: 0.646 \n",
      "[epoch: 5500] Train MSE : 0.0228 R2 score: 0.581 \n",
      "Early stopping at epoch 5500\n",
      "0.022843000743817406 0.022837281395724673 0.022831583630077572\n"
     ]
    }
   ],
   "source": [
    "model = pytorch_lr(w1_list=[3e-3], lr_list=[0.001], x1=x_train, x2=x_test, y1=auto_train, y2=auto_test, reg_type='L2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1541)\n",
      "tensor(0.0008, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(torch.sum(torch.abs(i[1])>0.1))\n",
    "    print(torch.min(torch.abs(i[1])))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   0] Train MSE : 0.0146 R2 score: -0.502 \n",
      "[epoch:   0] Test MSE 0.0141 R2 score: -0.513 \n",
      "[epoch:  50] Train MSE : 0.0077 R2 score: 0.209 \n",
      "[epoch:  50] Test MSE 0.0075 R2 score: 0.199 \n",
      "[epoch: 100] Train MSE : 0.0066 R2 score: 0.323 \n",
      "[epoch: 100] Test MSE 0.0064 R2 score: 0.311 \n",
      "[epoch: 150] Train MSE : 0.0060 R2 score: 0.377 \n",
      "[epoch: 150] Test MSE 0.0059 R2 score: 0.368 \n",
      "[epoch: 200] Train MSE : 0.0057 R2 score: 0.411 \n",
      "[epoch: 200] Test MSE 0.0056 R2 score: 0.404 \n",
      "[epoch: 250] Train MSE : 0.0055 R2 score: 0.431 \n",
      "[epoch: 250] Test MSE 0.0054 R2 score: 0.426 \n",
      "[epoch: 300] Train MSE : 0.0054 R2 score: 0.445 \n",
      "[epoch: 300] Test MSE 0.0052 R2 score: 0.440 \n",
      "[epoch: 350] Train MSE : 0.0053 R2 score: 0.455 \n",
      "[epoch: 350] Test MSE 0.0051 R2 score: 0.449 \n",
      "[epoch: 400] Train MSE : 0.0052 R2 score: 0.462 \n",
      "[epoch: 400] Test MSE 0.0051 R2 score: 0.455 \n",
      "[epoch: 450] Train MSE : 0.0052 R2 score: 0.469 \n",
      "[epoch: 450] Test MSE 0.0050 R2 score: 0.459 \n",
      "[epoch: 500] Train MSE : 0.0051 R2 score: 0.474 \n",
      "[epoch: 500] Test MSE 0.0050 R2 score: 0.462 \n",
      "[epoch: 550] Train MSE : 0.0051 R2 score: 0.479 \n",
      "[epoch: 550] Test MSE 0.0050 R2 score: 0.463 \n",
      "[epoch: 600] Train MSE : 0.0050 R2 score: 0.483 \n",
      "[epoch: 600] Test MSE 0.0050 R2 score: 0.465 \n",
      "[epoch: 650] Train MSE : 0.0050 R2 score: 0.487 \n",
      "[epoch: 650] Test MSE 0.0050 R2 score: 0.465 \n",
      "[epoch: 700] Train MSE : 0.0049 R2 score: 0.491 \n",
      "[epoch: 700] Test MSE 0.0050 R2 score: 0.465 \n",
      "[epoch: 750] Train MSE : 0.0049 R2 score: 0.494 \n",
      "[epoch: 750] Test MSE 0.0050 R2 score: 0.464 \n",
      "[epoch: 800] Train MSE : 0.0049 R2 score: 0.497 \n",
      "[epoch: 800] Test MSE 0.0050 R2 score: 0.464 \n",
      "[epoch: 850] Train MSE : 0.0049 R2 score: 0.500 \n",
      "[epoch: 850] Test MSE 0.0050 R2 score: 0.463 \n",
      "[epoch: 900] Train MSE : 0.0048 R2 score: 0.503 \n",
      "[epoch: 900] Test MSE 0.0050 R2 score: 0.463 \n",
      "[epoch: 950] Train MSE : 0.0048 R2 score: 0.505 \n",
      "[epoch: 950] Test MSE 0.0050 R2 score: 0.462 \n",
      "[epoch: 1000] Train MSE : 0.0048 R2 score: 0.508 \n",
      "[epoch: 1000] Test MSE 0.0050 R2 score: 0.462 \n",
      "[epoch: 1050] Train MSE : 0.0048 R2 score: 0.510 \n",
      "[epoch: 1050] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1100] Train MSE : 0.0047 R2 score: 0.512 \n",
      "[epoch: 1100] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1150] Train MSE : 0.0047 R2 score: 0.515 \n",
      "[epoch: 1150] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1200] Train MSE : 0.0047 R2 score: 0.517 \n",
      "[epoch: 1200] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1250] Train MSE : 0.0047 R2 score: 0.519 \n",
      "[epoch: 1250] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1300] Train MSE : 0.0047 R2 score: 0.520 \n",
      "[epoch: 1300] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1350] Train MSE : 0.0046 R2 score: 0.522 \n",
      "[epoch: 1350] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1400] Train MSE : 0.0046 R2 score: 0.524 \n",
      "[epoch: 1400] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1450] Train MSE : 0.0046 R2 score: 0.526 \n",
      "[epoch: 1450] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1500] Train MSE : 0.0046 R2 score: 0.527 \n",
      "[epoch: 1500] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1550] Train MSE : 0.0046 R2 score: 0.529 \n",
      "[epoch: 1550] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1600] Train MSE : 0.0046 R2 score: 0.530 \n",
      "[epoch: 1600] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1650] Train MSE : 0.0045 R2 score: 0.531 \n",
      "[epoch: 1650] Test MSE 0.0050 R2 score: 0.460 \n",
      "[epoch: 1700] Train MSE : 0.0045 R2 score: 0.533 \n",
      "[epoch: 1700] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1750] Train MSE : 0.0045 R2 score: 0.534 \n",
      "[epoch: 1750] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1800] Train MSE : 0.0045 R2 score: 0.535 \n",
      "[epoch: 1800] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1850] Train MSE : 0.0045 R2 score: 0.536 \n",
      "[epoch: 1850] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1900] Train MSE : 0.0045 R2 score: 0.537 \n",
      "[epoch: 1900] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 1950] Train MSE : 0.0045 R2 score: 0.538 \n",
      "[epoch: 1950] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2000] Train MSE : 0.0045 R2 score: 0.539 \n",
      "[epoch: 2000] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2050] Train MSE : 0.0045 R2 score: 0.540 \n",
      "[epoch: 2050] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2100] Train MSE : 0.0045 R2 score: 0.541 \n",
      "[epoch: 2100] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2150] Train MSE : 0.0044 R2 score: 0.542 \n",
      "[epoch: 2150] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2200] Train MSE : 0.0044 R2 score: 0.543 \n",
      "[epoch: 2200] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2250] Train MSE : 0.0044 R2 score: 0.543 \n",
      "[epoch: 2250] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2300] Train MSE : 0.0044 R2 score: 0.544 \n",
      "[epoch: 2300] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2350] Train MSE : 0.0044 R2 score: 0.544 \n",
      "[epoch: 2350] Test MSE 0.0050 R2 score: 0.461 \n",
      "[epoch: 2400] Train MSE : 0.0044 R2 score: 0.545 \n",
      "[epoch: 2400] Test MSE 0.0050 R2 score: 0.462 \n",
      "[epoch: 2450] Train MSE : 0.0044 R2 score: 0.545 \n",
      "[epoch: 2450] Test MSE 0.0050 R2 score: 0.462 \n",
      "[epoch: 2500] Train MSE : 0.0044 R2 score: 0.546 \n",
      "[epoch: 2500] Test MSE 0.0050 R2 score: 0.462 \n",
      "[epoch: 2550] Train MSE : 0.0044 R2 score: 0.546 \n",
      "[epoch: 2550] Test MSE 0.0050 R2 score: 0.462 \n",
      "[epoch: 2600] Train MSE : 0.0044 R2 score: 0.547 \n",
      "[epoch: 2600] Test MSE 0.0050 R2 score: 0.462 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-8b6e6ee24860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytorch_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-b08116603f5f>\u001b[0m in \u001b[0;36mpytorch_lr\u001b[0;34m(w1_list, lr_list, x1, x2, y1, y2)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mmse_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pytorch_lr(w1_list=[0.005], lr_list=[0.005], x1=x_train, x2=x_test, y1=pt_train, y2=pt_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   0] Train MSE : 0.0406 R2 score: -0.516 \n",
      "[epoch:   0] Test MSE 0.0375 R2 score: -0.524 \n",
      "[epoch:  50] Train MSE : 0.0231 R2 score: 0.139 \n",
      "[epoch:  50] Test MSE 0.0210 R2 score: 0.146 \n",
      "[epoch: 100] Train MSE : 0.0200 R2 score: 0.252 \n",
      "[epoch: 100] Test MSE 0.0182 R2 score: 0.261 \n",
      "[epoch: 150] Train MSE : 0.0182 R2 score: 0.321 \n",
      "[epoch: 150] Test MSE 0.0164 R2 score: 0.333 \n",
      "[epoch: 200] Train MSE : 0.0169 R2 score: 0.369 \n",
      "[epoch: 200] Test MSE 0.0151 R2 score: 0.385 \n",
      "[epoch: 250] Train MSE : 0.0160 R2 score: 0.403 \n",
      "[epoch: 250] Test MSE 0.0142 R2 score: 0.424 \n",
      "[epoch: 300] Train MSE : 0.0153 R2 score: 0.429 \n",
      "[epoch: 300] Test MSE 0.0134 R2 score: 0.454 \n",
      "[epoch: 350] Train MSE : 0.0148 R2 score: 0.447 \n",
      "[epoch: 350] Test MSE 0.0129 R2 score: 0.477 \n",
      "[epoch: 400] Train MSE : 0.0145 R2 score: 0.461 \n",
      "[epoch: 400] Test MSE 0.0124 R2 score: 0.495 \n",
      "[epoch: 450] Train MSE : 0.0142 R2 score: 0.472 \n",
      "[epoch: 450] Test MSE 0.0121 R2 score: 0.509 \n",
      "[epoch: 500] Train MSE : 0.0139 R2 score: 0.480 \n",
      "[epoch: 500] Test MSE 0.0118 R2 score: 0.521 \n",
      "[epoch: 550] Train MSE : 0.0138 R2 score: 0.487 \n",
      "[epoch: 550] Test MSE 0.0116 R2 score: 0.530 \n",
      "[epoch: 600] Train MSE : 0.0136 R2 score: 0.493 \n",
      "[epoch: 600] Test MSE 0.0114 R2 score: 0.538 \n",
      "[epoch: 650] Train MSE : 0.0134 R2 score: 0.499 \n",
      "[epoch: 650] Test MSE 0.0112 R2 score: 0.544 \n",
      "[epoch: 700] Train MSE : 0.0133 R2 score: 0.503 \n",
      "[epoch: 700] Test MSE 0.0111 R2 score: 0.549 \n",
      "[epoch: 750] Train MSE : 0.0132 R2 score: 0.508 \n",
      "[epoch: 750] Test MSE 0.0110 R2 score: 0.552 \n",
      "[epoch: 800] Train MSE : 0.0131 R2 score: 0.511 \n",
      "[epoch: 800] Test MSE 0.0109 R2 score: 0.555 \n",
      "[epoch: 850] Train MSE : 0.0130 R2 score: 0.515 \n",
      "[epoch: 850] Test MSE 0.0109 R2 score: 0.557 \n",
      "[epoch: 900] Train MSE : 0.0129 R2 score: 0.518 \n",
      "[epoch: 900] Test MSE 0.0109 R2 score: 0.559 \n",
      "[epoch: 950] Train MSE : 0.0129 R2 score: 0.521 \n",
      "[epoch: 950] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 1000] Train MSE : 0.0128 R2 score: 0.523 \n",
      "[epoch: 1000] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 1050] Train MSE : 0.0127 R2 score: 0.526 \n",
      "[epoch: 1050] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 1100] Train MSE : 0.0126 R2 score: 0.529 \n",
      "[epoch: 1100] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 1150] Train MSE : 0.0126 R2 score: 0.531 \n",
      "[epoch: 1150] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 1200] Train MSE : 0.0125 R2 score: 0.533 \n",
      "[epoch: 1200] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 1250] Train MSE : 0.0125 R2 score: 0.536 \n",
      "[epoch: 1250] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 1300] Train MSE : 0.0124 R2 score: 0.538 \n",
      "[epoch: 1300] Test MSE 0.0107 R2 score: 0.563 \n",
      "[epoch: 1350] Train MSE : 0.0123 R2 score: 0.540 \n",
      "[epoch: 1350] Test MSE 0.0107 R2 score: 0.563 \n",
      "[epoch: 1400] Train MSE : 0.0123 R2 score: 0.542 \n",
      "[epoch: 1400] Test MSE 0.0107 R2 score: 0.563 \n",
      "[epoch: 1450] Train MSE : 0.0122 R2 score: 0.544 \n",
      "[epoch: 1450] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 1500] Train MSE : 0.0122 R2 score: 0.546 \n",
      "[epoch: 1500] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 1550] Train MSE : 0.0121 R2 score: 0.548 \n",
      "[epoch: 1550] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 1600] Train MSE : 0.0121 R2 score: 0.549 \n",
      "[epoch: 1600] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 1650] Train MSE : 0.0120 R2 score: 0.551 \n",
      "[epoch: 1650] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 1700] Train MSE : 0.0120 R2 score: 0.553 \n",
      "[epoch: 1700] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 1750] Train MSE : 0.0119 R2 score: 0.554 \n",
      "[epoch: 1750] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 1800] Train MSE : 0.0119 R2 score: 0.556 \n",
      "[epoch: 1800] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 1850] Train MSE : 0.0119 R2 score: 0.558 \n",
      "[epoch: 1850] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 1900] Train MSE : 0.0118 R2 score: 0.559 \n",
      "[epoch: 1900] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 1950] Train MSE : 0.0118 R2 score: 0.561 \n",
      "[epoch: 1950] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 2000] Train MSE : 0.0117 R2 score: 0.562 \n",
      "[epoch: 2000] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 2050] Train MSE : 0.0117 R2 score: 0.563 \n",
      "[epoch: 2050] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2100] Train MSE : 0.0117 R2 score: 0.565 \n",
      "[epoch: 2100] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2150] Train MSE : 0.0116 R2 score: 0.566 \n",
      "[epoch: 2150] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2200] Train MSE : 0.0116 R2 score: 0.567 \n",
      "[epoch: 2200] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2250] Train MSE : 0.0116 R2 score: 0.568 \n",
      "[epoch: 2250] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2300] Train MSE : 0.0115 R2 score: 0.569 \n",
      "[epoch: 2300] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2350] Train MSE : 0.0115 R2 score: 0.571 \n",
      "[epoch: 2350] Test MSE 0.0108 R2 score: 0.559 \n",
      "[epoch: 2400] Train MSE : 0.0115 R2 score: 0.572 \n",
      "[epoch: 2400] Test MSE 0.0108 R2 score: 0.559 \n",
      "[epoch: 2450] Train MSE : 0.0115 R2 score: 0.573 \n",
      "[epoch: 2450] Test MSE 0.0108 R2 score: 0.559 \n",
      "[epoch: 2500] Train MSE : 0.0114 R2 score: 0.574 \n",
      "[epoch: 2500] Test MSE 0.0108 R2 score: 0.559 \n",
      "[epoch: 2550] Train MSE : 0.0114 R2 score: 0.575 \n",
      "[epoch: 2550] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2600] Train MSE : 0.0114 R2 score: 0.576 \n",
      "[epoch: 2600] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2650] Train MSE : 0.0113 R2 score: 0.577 \n",
      "[epoch: 2650] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2700] Train MSE : 0.0113 R2 score: 0.578 \n",
      "[epoch: 2700] Test MSE 0.0108 R2 score: 0.560 \n",
      "[epoch: 2750] Train MSE : 0.0113 R2 score: 0.578 \n",
      "[epoch: 2750] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 2800] Train MSE : 0.0113 R2 score: 0.579 \n",
      "[epoch: 2800] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 2850] Train MSE : 0.0113 R2 score: 0.580 \n",
      "[epoch: 2850] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 2900] Train MSE : 0.0112 R2 score: 0.581 \n",
      "[epoch: 2900] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 2950] Train MSE : 0.0112 R2 score: 0.582 \n",
      "[epoch: 2950] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 3000] Train MSE : 0.0112 R2 score: 0.582 \n",
      "[epoch: 3000] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 3050] Train MSE : 0.0112 R2 score: 0.583 \n",
      "[epoch: 3050] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 3100] Train MSE : 0.0112 R2 score: 0.584 \n",
      "[epoch: 3100] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 3150] Train MSE : 0.0111 R2 score: 0.585 \n",
      "[epoch: 3150] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3200] Train MSE : 0.0111 R2 score: 0.585 \n",
      "[epoch: 3200] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3250] Train MSE : 0.0111 R2 score: 0.586 \n",
      "[epoch: 3250] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3300] Train MSE : 0.0111 R2 score: 0.587 \n",
      "[epoch: 3300] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3350] Train MSE : 0.0111 R2 score: 0.587 \n",
      "[epoch: 3350] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3400] Train MSE : 0.0111 R2 score: 0.588 \n",
      "[epoch: 3400] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3450] Train MSE : 0.0110 R2 score: 0.588 \n",
      "[epoch: 3450] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3500] Train MSE : 0.0110 R2 score: 0.589 \n",
      "[epoch: 3500] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 3550] Train MSE : 0.0110 R2 score: 0.589 \n",
      "[epoch: 3550] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3600] Train MSE : 0.0110 R2 score: 0.590 \n",
      "[epoch: 3600] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3650] Train MSE : 0.0110 R2 score: 0.590 \n",
      "[epoch: 3650] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3700] Train MSE : 0.0110 R2 score: 0.591 \n",
      "[epoch: 3700] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3750] Train MSE : 0.0110 R2 score: 0.591 \n",
      "[epoch: 3750] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3800] Train MSE : 0.0110 R2 score: 0.591 \n",
      "[epoch: 3800] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3850] Train MSE : 0.0109 R2 score: 0.592 \n",
      "[epoch: 3850] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3900] Train MSE : 0.0109 R2 score: 0.592 \n",
      "[epoch: 3900] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 3950] Train MSE : 0.0109 R2 score: 0.593 \n",
      "[epoch: 3950] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 4000] Train MSE : 0.0109 R2 score: 0.593 \n",
      "[epoch: 4000] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 4050] Train MSE : 0.0109 R2 score: 0.593 \n",
      "[epoch: 4050] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 4100] Train MSE : 0.0109 R2 score: 0.593 \n",
      "[epoch: 4100] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 4150] Train MSE : 0.0109 R2 score: 0.594 \n",
      "[epoch: 4150] Test MSE 0.0108 R2 score: 0.562 \n",
      "[epoch: 4200] Train MSE : 0.0109 R2 score: 0.594 \n",
      "[epoch: 4200] Test MSE 0.0108 R2 score: 0.561 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4250] Train MSE : 0.0109 R2 score: 0.594 \n",
      "[epoch: 4250] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 4300] Train MSE : 0.0109 R2 score: 0.595 \n",
      "[epoch: 4300] Test MSE 0.0108 R2 score: 0.561 \n",
      "[epoch: 4350] Train MSE : 0.0109 R2 score: 0.595 \n",
      "[epoch: 4350] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 4400] Train MSE : 0.0109 R2 score: 0.595 \n",
      "[epoch: 4400] Test MSE 0.0108 R2 score: 0.563 \n",
      "[epoch: 4450] Train MSE : 0.0109 R2 score: 0.595 \n",
      "[epoch: 4450] Test MSE 0.0108 R2 score: 0.563 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-9d0261fa068d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytorch_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactive_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactive_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-b08116603f5f>\u001b[0m in \u001b[0;36mpytorch_lr\u001b[0;34m(w1_list, lr_list, x1, x2, y1, y2)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mmse_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pytorch_lr(w1_list=[0.003], lr_list=[0.005], x1=x_train, x2=x_test, y1=active_train, y2=active_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), out_dir+\"image_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MNL for Mode Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader and model definition\n",
    "\n",
    "trainset = SurveyDataset(torch.tensor(x_train,  dtype=torch.float), torch.tensor(y_train, dtype=torch.float))\n",
    "trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "\n",
    "testset = SurveyDataset(torch.tensor(x_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.float))\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "kldivloss = nn.KLDivLoss(reduction='sum')\n",
    "mseloss = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_train = np.sum(np.power(y_train - np.mean(y_train, axis=0), 2), axis=0)\n",
    "sst_test = np.sum(np.power(y_test - np.mean(y_test, axis=0), 2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mnl_torch(lr_list, wd_list):\n",
    "    \n",
    "    for (lr, wd) in itertools.product(lr_list, wd_list):\n",
    "        \n",
    "        print(f\"[lr: {lr:.3f}, wd: {wd:3.2e}]\")\n",
    "\n",
    "        # model setup\n",
    "        model = mnl.MNL(n_alts=4, n_features=x_train.shape[-1])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        # model training\n",
    "\n",
    "        ref1 = 0\n",
    "        ref2 = 0\n",
    "\n",
    "        for epoch in range(1000):\n",
    "\n",
    "            kl_ = 0\n",
    "            mse_ = 0\n",
    "            mse1_ = 0\n",
    "            mse2_ = 0\n",
    "            mse3_ = 0\n",
    "            mse4_ = 0\n",
    "\n",
    "            for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                util = model(x_batch)\n",
    "                probs = torch.log(nn.functional.softmax(util, dim=1))\n",
    "                kl = kldivloss(probs, y_batch)\n",
    "        #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                kl_ += kl.item()\n",
    "\n",
    "                mse = mseloss(torch.exp(probs), y_batch)\n",
    "        #         mse = mseloss(util, y_batch)\n",
    "                mse_ += mse.sum().item()\n",
    "                mse1_ += mse[:,0].sum().item()\n",
    "                mse2_ += mse[:,1].sum().item()\n",
    "                mse3_ += mse[:,2].sum().item()\n",
    "                mse4_ += mse[:,3].sum().item()\n",
    "                mse = mse.sum()\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                kl.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_kl = kl_/len(trainset)\n",
    "            train_mse = np.sqrt(mse_/len(trainset))\n",
    "            train_mse1 = np.sqrt(mse1_/len(trainset))\n",
    "            train_mse2 = np.sqrt(mse2_/len(trainset))\n",
    "            train_mse3 = np.sqrt(mse3_/len(trainset))\n",
    "            train_mse4 = np.sqrt(mse4_/len(trainset))\n",
    "\n",
    "            train_r1 = 1-mse1_/sst_train[0]\n",
    "            train_r2 = 1-mse2_/sst_train[1]\n",
    "            train_r3 = 1-mse3_/sst_train[2]\n",
    "            train_r4 = 1-mse4_/sst_train[3]\n",
    "\n",
    "            loss_ = train_kl\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "\n",
    "                kl_ = 0\n",
    "                mse_ = 0 \n",
    "                mse1_ = 0\n",
    "                mse2_ = 0\n",
    "                mse3_ = 0\n",
    "                mse4_ = 0\n",
    "\n",
    "                for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "                    \n",
    "                    util = model(x_batch)\n",
    "                    probs = torch.log(nn.functional.softmax(util,dim=1))\n",
    "                    kl = kldivloss(probs, y_batch)\n",
    "            #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                    kl_ += kl.item()\n",
    "\n",
    "                    mse = mseloss(torch.exp(probs), y_batch)\n",
    "            #         mse = mseloss(util, y_batch)\n",
    "                    mse_ += mse.sum().item()\n",
    "                    mse1_ += mse[:,0].sum().item()\n",
    "                    mse2_ += mse[:,1].sum().item()\n",
    "                    mse3_ += mse[:,2].sum().item()\n",
    "                    mse4_ += mse[:,3].sum().item()\n",
    "\n",
    "                test_kl = kl_/len(testset)\n",
    "                test_mse = np.sqrt(mse_/len(testset))\n",
    "                test_mse1 = np.sqrt(mse1_/len(testset))\n",
    "                test_mse2 = np.sqrt(mse2_/len(testset))\n",
    "                test_mse3 = np.sqrt(mse3_/len(testset))\n",
    "                test_mse4 = np.sqrt(mse4_/len(testset))\n",
    "\n",
    "                r1 = r2_score(y_batch.numpy()[:,0],torch.exp(probs).detach().numpy()[:,0])\n",
    "                r2 = r2_score(y_batch.numpy()[:,1],torch.exp(probs).detach().numpy()[:,1])\n",
    "                r3 = r2_score(y_batch.numpy()[:,2],torch.exp(probs).detach().numpy()[:,2])\n",
    "                r4 = r2_score(y_batch.numpy()[:,3],torch.exp(probs).detach().numpy()[:,3])\n",
    "\n",
    "                if epoch >= 40:\n",
    "                    if (np.abs(loss_ - ref1)/ref1<0.001) & (np.abs(loss_ - ref2)/ref2<0.001):\n",
    "                        print(\"Early stopping at epoch\", epoch)\n",
    "                        break\n",
    "                    if (ref1 < loss_) & (ref1 < ref2):\n",
    "                        print(\"Diverging. stop.\")\n",
    "                        break\n",
    "                    if loss_ < best:\n",
    "                        best = loss_\n",
    "                        best_epoch = epoch\n",
    "                        output = (train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                else:\n",
    "                    best = loss_\n",
    "                    best_epoch = epoch\n",
    "                    output = (train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                ref2 = ref1\n",
    "                ref1 = loss_\n",
    "\n",
    "#             if epoch % 20 == 0:\n",
    "\n",
    "#                 print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} RMSE {train_mse:.3f}\")\n",
    "#                    # {train_mse1:.3f} {train_mse2:.3f} {train_mse3:.3f} {train_mse4:.3f}\")\n",
    "#                 print(f\"\\t\\t\\t\\t\\t\\t Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "#                 print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} RMSE {np.sqrt(mse_/len(testset)):.3f}\")\n",
    "#                    #     {np.sqrt(mse1_/len(testset)):.3f} {np.sqrt(mse2_/len(testset)):.3f} {np.sqrt(mse3_/len(testset)):.3f} {np.sqrt(mse4_/len(testset)):.3f}\")\n",
    "#                 print(f\"\\t\\t\\t\\t\\t\\t Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "#                 print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "#                 print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "#         with open(out_dir+\"BA_mode_choice.csv\", \"a\") as f:\n",
    "#             f.write(\"%s,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f\\n\" % \n",
    "#                     ((\"MNL\",lr, wd)+output))\n",
    "    \n",
    "        print(f\"[epoch: {best_epoch:>3d}] Train KL loss: {output[0]:.3f} Train R2 score: {output[12]:.3f} {output[13]:.3f} {output[14]:.3f} {output[15]:.3f} \")\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Test KL loss: {output[6]:.3f} Test R2 score: {output[16]:.3f} {output[17]:.3f} {output[18]:.3f} {output[19]:.3f} \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 0.050, wd: 0.00e+00]\n",
      "Early stopping at epoch 890\n",
      "[epoch: 885] Train KL loss: 0.128 Train R2 score: 0.542 0.627 0.056 0.507 \n",
      "[epoch: 885] Test KL loss: 0.107 Test R2 score: 0.555 0.690 -0.131 0.479 \n",
      "\n",
      "[lr: 0.050, wd: 1.00e-07]\n",
      "Early stopping at epoch 895\n",
      "[epoch: 890] Train KL loss: 0.128 Train R2 score: 0.543 0.628 0.057 0.507 \n",
      "[epoch: 890] Test KL loss: 0.107 Test R2 score: 0.555 0.691 -0.132 0.479 \n",
      "\n",
      "[lr: 0.050, wd: 1.00e-06]\n",
      "Early stopping at epoch 895\n",
      "[epoch: 890] Train KL loss: 0.128 Train R2 score: 0.543 0.628 0.057 0.507 \n",
      "[epoch: 890] Test KL loss: 0.107 Test R2 score: 0.555 0.691 -0.132 0.479 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnl_torch(lr_list=[0.05], wd_list=[0, 1e-7, 1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 0.050, wd: 1.00e-05]\n",
      "Early stopping at epoch 895\n",
      "[epoch: 890] Train KL loss: 0.128 Train R2 score: 0.543 0.628 0.057 0.508 \n",
      "[epoch: 890] Test KL loss: 0.107 Test R2 score: 0.555 0.691 -0.132 0.479 \n",
      "\n",
      "[lr: 0.050, wd: 1.00e-04]\n",
      "Early stopping at epoch 850\n",
      "[epoch: 845] Train KL loss: 0.129 Train R2 score: 0.539 0.625 0.052 0.504 \n",
      "[epoch: 845] Test KL loss: 0.107 Test R2 score: 0.554 0.689 -0.122 0.478 \n",
      "\n",
      "[lr: 0.050, wd: 1.00e-03]\n",
      "Early stopping at epoch 700\n",
      "[epoch: 695] Train KL loss: 0.132 Train R2 score: 0.522 0.613 0.036 0.485 \n",
      "[epoch: 695] Test KL loss: 0.109 Test R2 score: 0.544 0.674 -0.089 0.468 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnl_torch(lr_list=[0.05], wd_list=[1e-5, 1e-4, 1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 0.0500, wd: 0.00e+00]\n",
      "[epoch:   0] Train KL loss: 0.845 Train R2 score: -0.647 -4.923 -11.745 -3.145 \n",
      "[epoch:   0] Test KL loss: 0.466 Test R2 score: -0.184 -2.139 -15.628 -1.287 \n",
      "[epoch:  20] Train KL loss: 0.239 Train R2 score: 0.043 0.068 -0.068 -0.103 \n",
      "[epoch:  20] Test KL loss: 0.213 Test R2 score: 0.023 0.081 -0.007 -0.094 \n",
      "[epoch:  40] Train KL loss: 0.209 Train R2 score: 0.129 0.160 -0.020 0.122 \n",
      "[epoch:  40] Test KL loss: 0.184 Test R2 score: 0.135 0.182 -0.002 0.131 \n",
      "[epoch:  60] Train KL loss: 0.193 Train R2 score: 0.200 0.259 -0.019 0.191 \n",
      "[epoch:  60] Test KL loss: 0.172 Test R2 score: 0.214 0.276 -0.119 0.193 \n",
      "[epoch:  80] Train KL loss: 0.181 Train R2 score: 0.259 0.334 -0.014 0.257 \n",
      "[epoch:  80] Test KL loss: 0.161 Test R2 score: 0.268 0.343 -0.084 0.246 \n",
      "[epoch: 100] Train KL loss: 0.173 Train R2 score: 0.298 0.382 -0.013 0.298 \n",
      "[epoch: 100] Test KL loss: 0.152 Test R2 score: 0.307 0.392 -0.068 0.280 \n",
      "[epoch: 120] Train KL loss: 0.167 Train R2 score: 0.333 0.421 -0.012 0.327 \n",
      "[epoch: 120] Test KL loss: 0.147 Test R2 score: 0.340 0.430 -0.071 0.305 \n",
      "[epoch: 140] Train KL loss: 0.162 Train R2 score: 0.361 0.452 -0.011 0.349 \n",
      "[epoch: 140] Test KL loss: 0.142 Test R2 score: 0.368 0.463 -0.072 0.325 \n",
      "[epoch: 160] Train KL loss: 0.158 Train R2 score: 0.385 0.478 -0.008 0.367 \n",
      "[epoch: 160] Test KL loss: 0.137 Test R2 score: 0.393 0.491 -0.073 0.342 \n",
      "[epoch: 180] Train KL loss: 0.154 Train R2 score: 0.406 0.499 -0.006 0.383 \n",
      "[epoch: 180] Test KL loss: 0.134 Test R2 score: 0.414 0.515 -0.072 0.357 \n",
      "[epoch: 200] Train KL loss: 0.151 Train R2 score: 0.422 0.517 -0.004 0.396 \n",
      "[epoch: 200] Test KL loss: 0.131 Test R2 score: 0.431 0.536 -0.071 0.371 \n",
      "[epoch: 220] Train KL loss: 0.149 Train R2 score: 0.436 0.531 -0.001 0.407 \n",
      "[epoch: 220] Test KL loss: 0.128 Test R2 score: 0.446 0.554 -0.070 0.383 \n",
      "[epoch: 240] Train KL loss: 0.147 Train R2 score: 0.448 0.543 0.001 0.417 \n",
      "[epoch: 240] Test KL loss: 0.126 Test R2 score: 0.459 0.570 -0.069 0.394 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2e57f32a0f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnl_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-a42315d9526d>\u001b[0m in \u001b[0;36mmnl_torch\u001b[0;34m(lr_list, wd_list)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mmse4_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/qingyi/demand_image/dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnl_torch(lr_list=[0.05], wd_list=[0, 1e-7, 1e-6,1e-5, 1e-4, 1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnl_torch(lr_list, wd_list):\n",
    "    \n",
    "    for (lr, wd) in itertools.product(lr_list, wd_list):\n",
    "        \n",
    "        print(f\"[lr: {lr:.4f}, wd: {wd:3.2e}]\")\n",
    "\n",
    "        # model setup\n",
    "        model = mnl.MNL(n_alts=4, n_features=x_train.shape[-1])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "#         print(optimizer)\n",
    "        # model training\n",
    "\n",
    "        ref1 = 0\n",
    "        ref2 = 0\n",
    "\n",
    "        for epoch in range(5000):\n",
    "\n",
    "            kl_ = 0\n",
    "            mse_ = 0\n",
    "            mse1_ = 0\n",
    "            mse2_ = 0\n",
    "            mse3_ = 0\n",
    "            mse4_ = 0\n",
    "\n",
    "            for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                util = model(x_batch)\n",
    "                probs = torch.log(nn.functional.softmax(util, dim=1))\n",
    "                kl = kldivloss(probs, y_batch)\n",
    "        #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                kl_ += kl.item()\n",
    "\n",
    "                mse = mseloss(torch.exp(probs), y_batch)\n",
    "        #         mse = mseloss(util, y_batch)\n",
    "                mse_ += mse.sum().item()\n",
    "                mse1_ += mse[:,0].sum().item()\n",
    "                mse2_ += mse[:,1].sum().item()\n",
    "                mse3_ += mse[:,2].sum().item()\n",
    "                mse4_ += mse[:,3].sum().item()\n",
    "                mse = mse.sum()\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                kl.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_kl = kl_/len(trainset)\n",
    "            train_mse = np.sqrt(mse_/len(trainset))\n",
    "            train_mse1 = np.sqrt(mse1_/len(trainset))\n",
    "            train_mse2 = np.sqrt(mse2_/len(trainset))\n",
    "            train_mse3 = np.sqrt(mse3_/len(trainset))\n",
    "            train_mse4 = np.sqrt(mse4_/len(trainset))\n",
    "\n",
    "            train_r1 = 1-mse1_/sst_train[0]\n",
    "            train_r2 = 1-mse2_/sst_train[1]\n",
    "            train_r3 = 1-mse3_/sst_train[2]\n",
    "            train_r4 = 1-mse4_/sst_train[3]\n",
    "\n",
    "            loss_ = train_kl\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "\n",
    "                kl_ = 0\n",
    "                mse_ = 0 \n",
    "                mse1_ = 0\n",
    "                mse2_ = 0\n",
    "                mse3_ = 0\n",
    "                mse4_ = 0\n",
    "\n",
    "                for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "                    \n",
    "                    util = model(x_batch)\n",
    "                    probs = torch.log(nn.functional.softmax(util,dim=1))\n",
    "                    kl = kldivloss(probs, y_batch)\n",
    "            #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                    kl_ += kl.item()\n",
    "\n",
    "                    mse = mseloss(torch.exp(probs), y_batch)\n",
    "            #         mse = mseloss(util, y_batch)\n",
    "                    mse_ += mse.sum().item()\n",
    "                    mse1_ += mse[:,0].sum().item()\n",
    "                    mse2_ += mse[:,1].sum().item()\n",
    "                    mse3_ += mse[:,2].sum().item()\n",
    "                    mse4_ += mse[:,3].sum().item()\n",
    "\n",
    "                test_kl = kl_/len(testset)\n",
    "                test_mse = np.sqrt(mse_/len(testset))\n",
    "                test_mse1 = np.sqrt(mse1_/len(testset))\n",
    "                test_mse2 = np.sqrt(mse2_/len(testset))\n",
    "                test_mse3 = np.sqrt(mse3_/len(testset))\n",
    "                test_mse4 = np.sqrt(mse4_/len(testset))\n",
    "\n",
    "                r1 = r2_score(y_batch.numpy()[:,0],torch.exp(probs).detach().numpy()[:,0])\n",
    "                r2 = r2_score(y_batch.numpy()[:,1],torch.exp(probs).detach().numpy()[:,1])\n",
    "                r3 = r2_score(y_batch.numpy()[:,2],torch.exp(probs).detach().numpy()[:,2])\n",
    "                r4 = r2_score(y_batch.numpy()[:,3],torch.exp(probs).detach().numpy()[:,3])\n",
    "\n",
    "                if epoch >= 40:\n",
    "                    if (np.abs(loss_ - ref1)/ref1<0.001) & (np.abs(loss_ - ref2)/ref2<0.001):\n",
    "                        print(\"Early stopping at epoch\", epoch)\n",
    "                        break\n",
    "                    if (ref1 < loss_) & (ref1 < ref2):\n",
    "                        print(\"Diverging. stop.\")\n",
    "                        break\n",
    "                    if loss_ < best:\n",
    "                        best = loss_\n",
    "                        best_epoch = epoch\n",
    "                        output = (train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                else:\n",
    "                    best = loss_\n",
    "                    best_epoch = epoch\n",
    "                    output = (train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                ref2 = ref1\n",
    "                ref1 = loss_\n",
    "\n",
    "            if epoch % 20 == 0:\n",
    "\n",
    "#                 print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} RMSE {train_mse:.3f}\")\n",
    "#                    # {train_mse1:.3f} {train_mse2:.3f} {train_mse3:.3f} {train_mse4:.3f}\")\n",
    "#                 print(f\"\\t\\t\\t\\t\\t\\t Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "#                 print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} RMSE {np.sqrt(mse_/len(testset)):.3f}\")\n",
    "#                    #     {np.sqrt(mse1_/len(testset)):.3f} {np.sqrt(mse2_/len(testset)):.3f} {np.sqrt(mse3_/len(testset)):.3f} {np.sqrt(mse4_/len(testset)):.3f}\")\n",
    "#                 print(f\"\\t\\t\\t\\t\\t\\t Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "                print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "                print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "#         with open(out_dir+\"BA_mode_choice.csv\", \"a\") as f:\n",
    "#             f.write(\"%s,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f\\n\" % \n",
    "#                     ((\"MNL\",lr, wd)+output))\n",
    "\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Train KL loss: {output[0]:.3f} Train R2 score: {output[12]:.3f} {output[13]:.3f} {output[14]:.3f} {output[15]:.3f} \")\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Test KL loss: {output[6]:.3f} Test R2 score: {output[16]:.3f} {output[17]:.3f} {output[18]:.3f} {output[19]:.3f} \")\n",
    "        print()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
