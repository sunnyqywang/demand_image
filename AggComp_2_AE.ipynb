{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents part 2 of the complementarity of image and demographic information: the ability of latent space extracted from Autoencoders to predict mode choice and trip generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from dataloader import SurveyDataset, load_aggregate_travel_behavior, load_demo\n",
    "from M1_util_train_test import load_model, test\n",
    "import linear_reg\n",
    "import mnl\n",
    "from setup import out_dir, data_dir, image_dir, model_dir, proj_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = '1571'\n",
    "\n",
    "model_type = 'AE'\n",
    "sampling = 's'\n",
    "\n",
    "zoomlevel = 'zoom15'\n",
    "output_dim = 3\n",
    "model_run_date = '2208'\n",
    "v2 = 1\n",
    "\n",
    "variable_names = ['active','auto','mas','pt', 'trpgen']\n",
    "\n",
    "demo_variables = ['tot_population','pct25_34yrs','pct35_50yrs','pctover65yrs',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pct_col_grad','avg_tt_to_work','inc_per_capita']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(proj_dir+\"latent_space/\"+model_type+\"_\"+zoomlevel+\"_\"+str(output_dim**2*2048)+\n",
    "                       \"_\"+str(v2)+\"_\"+model_run_date+\".pkl\", \"rb\") as f: \n",
    "    encoder_output = pkl.load(f)\n",
    "    im = pkl.load(f)\n",
    "    ct = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Embeddings\n",
    "unique_ct = list(set(ct))\n",
    "unique_ct.sort()\n",
    "ct = np.array(ct)\n",
    "aggregate_embeddings = []\n",
    "for i in unique_ct:\n",
    "    aggregate_embeddings.append(np.mean(encoder_output[ct == i], axis=0))\n",
    "aggregate_embeddings = np.array(aggregate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trip Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"origin_trip_behavior.csv\"\n",
    "df_pivot = load_aggregate_travel_behavior(file, data_version)\n",
    "\n",
    "train_test_index = df_pivot['train_test'].astype(bool).to_numpy()\n",
    "# train_test_index = np.random.rand(len(df_pivot)) < 0.2\n",
    "\n",
    "y = df_pivot[variable_names].to_numpy()\n",
    "y_train = y[~train_test_index,:4]\n",
    "y_test = y[train_test_index,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = aggregate_embeddings[~train_test_index, :]\n",
    "x_test = aggregate_embeddings[train_test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train = y[~train_test_index,1]\n",
    "auto_test = y[train_test_index,1]\n",
    "\n",
    "pt_train = y[~train_test_index,3]\n",
    "pt_test = y[train_test_index,3]\n",
    "\n",
    "active_train = y[~train_test_index,0]\n",
    "active_test = y[train_test_index,0]\n",
    "\n",
    "trpgen_train = y[~train_test_index,-1]\n",
    "trpgen_test = y[train_test_index,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Auto Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 1.0000 \t Test R2: 0.4236\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression without Regularization\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_train, auto_train)\n",
    "# with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#     f.write(\"%s,%s,%s,%.4f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], -1, \n",
    "#         lr.score(x_train, auto_train), lr.score(x_test, auto_test), 'lr', zoomlevel,\n",
    "#         np.sum(lr.coef_ != 0), len(lr.coef_)))\n",
    "print(\"Train R2: %.4f \\t Test R2: %.4f\" % (lr.score(x_train, auto_train), lr.score(x_test, auto_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-664430526f3d>:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: 0.2702 \t Nonzero coef: 18432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-05 Train R2: 0.9963 \t Test R: 0.2729 \t Nonzero coef: 3586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.320e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-05 Train R2: 0.9873 \t Test R: 0.3301 \t Nonzero coef: 2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.712e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-05 Train R2: 0.9595 \t Test R: 0.4343 \t Nonzero coef: 1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.805e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-05 Train R2: 0.9237 \t Test R: 0.4861 \t Nonzero coef: 1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 8.00e-05 Train R2: 0.8862 \t Test R: 0.5296 \t Nonzero coef: 1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.843e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-04 Train R2: 0.8492 \t Test R: 0.5658 \t Nonzero coef: 846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.742e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-04 Train R2: 0.7193 \t Test R: 0.6318 \t Nonzero coef: 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 3.00e-04 Train R2: 0.6512 \t Test R: 0.6293 \t Nonzero coef: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-04 Train R2: 0.6096 \t Test R: 0.6256 \t Nonzero coef: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.271e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-04 Train R2: 0.5818 \t Test R: 0.6194 \t Nonzero coef: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.612e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-04 Train R2: 0.5610 \t Test R: 0.6049 \t Nonzero coef: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.770e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 7.00e-04 Train R2: 0.5448 \t Test R: 0.5915 \t Nonzero coef: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.174e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 8.00e-04 Train R2: 0.5336 \t Test R: 0.5764 \t Nonzero coef: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.847e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 Train R2: 0.5184 \t Test R: 0.5539 \t Nonzero coef: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-03 Train R2: 0.4647 \t Test R: 0.5048 \t Nonzero coef: 21\n",
      "Parameter: 5.00e-03 Train R2: 0.3726 \t Test R: 0.3697 \t Nonzero coef: 11\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for a in (1e-4)*np.array([0,0.1,0.2,0.4,0.6,0.8,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, auto_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, auto_train), \n",
    "                                                                                  lasso.score(x_test, auto_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    with open(out_dir+\"SAE_A_LR.csv\", \"a\") as f:\n",
    "        f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (0,a,'auto',\n",
    "            lasso.score(x_train, auto_train), lasso.score(x_test, auto_test), 'lasso', \n",
    "            np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-3)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, auto_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, auto_train), \n",
    "                                                              ridge.score(x_test, auto_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-08df0451b31b>:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, pt_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -0.0445 \t Nonzero coef: 18432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.603e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-05 Train R2: 0.9830 \t Test R: 0.1063 \t Nonzero coef: 2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.778e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-05 Train R2: 0.9457 \t Test R: 0.2017 \t Nonzero coef: 1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.180e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-05 Train R2: 0.8490 \t Test R: 0.3262 \t Nonzero coef: 985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.740e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-05 Train R2: 0.7537 \t Test R: 0.3918 \t Nonzero coef: 680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.571e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 8.00e-05 Train R2: 0.6800 \t Test R: 0.4334 \t Nonzero coef: 460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.973e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-04 Train R2: 0.6250 \t Test R: 0.4445 \t Nonzero coef: 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.024e-02, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-04 Train R2: 0.4799 \t Test R: 0.4441 \t Nonzero coef: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 3.00e-04 Train R2: 0.4334 \t Test R: 0.4154 \t Nonzero coef: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.500e-01, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-04 Train R2: 0.4091 \t Test R: 0.3995 \t Nonzero coef: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.426e-02, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-04 Train R2: 0.3894 \t Test R: 0.3838 \t Nonzero coef: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e-02, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-04 Train R2: 0.3767 \t Test R: 0.3765 \t Nonzero coef: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e-03, tolerance: 1.373e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 7.00e-04 Train R2: 0.3665 \t Test R: 0.3661 \t Nonzero coef: 22\n",
      "Parameter: 8.00e-04 Train R2: 0.3574 \t Test R: 0.3573 \t Nonzero coef: 18\n",
      "Parameter: 1.00e-03 Train R2: 0.3468 \t Test R: 0.3471 \t Nonzero coef: 13\n",
      "Parameter: 2.00e-03 Train R2: 0.3022 \t Test R: 0.2850 \t Nonzero coef: 10\n",
      "Parameter: 5.00e-03 Train R2: 0.2089 \t Test R: 0.1831 \t Nonzero coef: 1\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for a in (1e-4)*np.array([0,0.1,0.2,0.4,0.6,0.8,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, pt_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, pt_train), \n",
    "                                                                                  lasso.score(x_test, pt_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    with open(out_dir+\"SAE_A_LR.csv\", \"a\") as f:\n",
    "        f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (0,a,'pt',\n",
    "            lasso.score(x_train, pt_train), lasso.score(x_test, pt_test), 'lasso', \n",
    "            np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-3)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, pt_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, pt_train), \n",
    "                                                              ridge.score(x_test, pt_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-4ae8c2bc955a>:3: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, active_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -0.1100 \t Nonzero coef: 18432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.603e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-05 Train R2: 0.9928 \t Test R: 0.1367 \t Nonzero coef: 3239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+00, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-05 Train R2: 0.9759 \t Test R: 0.2152 \t Nonzero coef: 2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.814e+00, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-05 Train R2: 0.9251 \t Test R: 0.2892 \t Nonzero coef: 1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+00, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-05 Train R2: 0.8663 \t Test R: 0.3498 \t Nonzero coef: 1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+00, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 8.00e-05 Train R2: 0.8101 \t Test R: 0.3993 \t Nonzero coef: 810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+00, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-04 Train R2: 0.7578 \t Test R: 0.4332 \t Nonzero coef: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.810e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-04 Train R2: 0.6021 \t Test R: 0.4954 \t Nonzero coef: 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.136e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 3.00e-04 Train R2: 0.5214 \t Test R: 0.4884 \t Nonzero coef: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.705e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-04 Train R2: 0.4765 \t Test R: 0.4822 \t Nonzero coef: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.941e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-04 Train R2: 0.4487 \t Test R: 0.4720 \t Nonzero coef: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.533e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-04 Train R2: 0.4340 \t Test R: 0.4593 \t Nonzero coef: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.922e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 7.00e-04 Train R2: 0.4242 \t Test R: 0.4497 \t Nonzero coef: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.932e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 8.00e-04 Train R2: 0.4153 \t Test R: 0.4446 \t Nonzero coef: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.425e-01, tolerance: 3.791e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 Train R2: 0.3966 \t Test R: 0.4321 \t Nonzero coef: 30\n",
      "Parameter: 2.00e-03 Train R2: 0.3294 \t Test R: 0.3565 \t Nonzero coef: 11\n",
      "Parameter: 5.00e-03 Train R2: 0.2307 \t Test R: 0.2172 \t Nonzero coef: 5\n"
     ]
    }
   ],
   "source": [
    "for a in (1e-4)*np.array([0,0.1,0.2,0.4,0.6,0.8,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, active_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, active_train), \n",
    "                                                                                  lasso.score(x_test, active_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    with open(out_dir+\"SAE_A_LR.csv\", \"a\") as f:\n",
    "        f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (0,a,'active',\n",
    "            lasso.score(x_train, active_train), lasso.score(x_test, active_test), 'lasso', \n",
    "            np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-3)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, active_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, active_train), \n",
    "                                                              ridge.score(x_test, active_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Trip Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in (1e-4)*np.array([0,0.1,6,7,8,10,11,12,13,14,15,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, trpgen_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, trpgen_train), \n",
    "                                                                                  lasso.score(x_test, trpgen_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-2)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, trpgen_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, trpgen_train), \n",
    "                                                              ridge.score(x_test, trpgen_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MNL for Mode Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader and model definition\n",
    "\n",
    "trainset = SurveyDataset(torch.tensor(x_train,  dtype=torch.float), torch.tensor(y_train, dtype=torch.float))\n",
    "trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "\n",
    "testset = SurveyDataset(torch.tensor(x_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.float))\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "kldivloss = nn.KLDivLoss(reduction='sum')\n",
    "mseloss = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_train = np.sum(np.power(y_train - np.mean(y_train, axis=0), 2), axis=0)\n",
    "sst_test = np.sum(np.power(y_test - np.mean(y_test, axis=0), 2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mnl_torch(lr_list, wd_list):\n",
    "    \n",
    "    for (lr, wd) in itertools.product(lr_list, wd_list):\n",
    "        \n",
    "        print(f\"[lr: {lr:.4f}, wd: {wd:3.2e}]\")\n",
    "\n",
    "        # model setup\n",
    "        model = mnl.MNL(n_alts=4, n_features=x_train.shape[-1])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "#         print(optimizer)\n",
    "        # model training\n",
    "\n",
    "        converged = 0\n",
    "        ref1 = 0\n",
    "        ref2 = 0\n",
    "\n",
    "        for epoch in range(5000):\n",
    "\n",
    "            kl_ = 0\n",
    "            mse_ = 0\n",
    "            mse1_ = 0\n",
    "            mse2_ = 0\n",
    "            mse3_ = 0\n",
    "            mse4_ = 0\n",
    "\n",
    "            for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                util = model(x_batch)\n",
    "                probs = torch.log(nn.functional.softmax(util, dim=1))\n",
    "                kl = kldivloss(probs, y_batch)\n",
    "        #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                kl_ += kl.item()\n",
    "\n",
    "                mse = mseloss(torch.exp(probs), y_batch)\n",
    "        #         mse = mseloss(util, y_batch)\n",
    "                mse_ += mse.sum().item()\n",
    "                mse1_ += mse[:,0].sum().item()\n",
    "                mse2_ += mse[:,1].sum().item()\n",
    "                mse3_ += mse[:,2].sum().item()\n",
    "                mse4_ += mse[:,3].sum().item()\n",
    "                mse = mse.sum()\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                kl.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_kl = kl_/len(trainset)\n",
    "            train_mse = np.sqrt(mse_/len(trainset))\n",
    "            train_mse1 = np.sqrt(mse1_/len(trainset))\n",
    "            train_mse2 = np.sqrt(mse2_/len(trainset))\n",
    "            train_mse3 = np.sqrt(mse3_/len(trainset))\n",
    "            train_mse4 = np.sqrt(mse4_/len(trainset))\n",
    "\n",
    "            train_r1 = 1-mse1_/sst_train[0]\n",
    "            train_r2 = 1-mse2_/sst_train[1]\n",
    "            train_r3 = 1-mse3_/sst_train[2]\n",
    "            train_r4 = 1-mse4_/sst_train[3]\n",
    "\n",
    "            loss_ = train_kl\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "\n",
    "                kl_ = 0\n",
    "                mse_ = 0 \n",
    "                mse1_ = 0\n",
    "                mse2_ = 0\n",
    "                mse3_ = 0\n",
    "                mse4_ = 0\n",
    "\n",
    "                for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "                    \n",
    "                    util = model(x_batch)\n",
    "                    probs = torch.log(nn.functional.softmax(util,dim=1))\n",
    "                    kl = kldivloss(probs, y_batch)\n",
    "            #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                    kl_ += kl.item()\n",
    "\n",
    "                    mse = mseloss(torch.exp(probs), y_batch)\n",
    "            #         mse = mseloss(util, y_batch)\n",
    "                    mse_ += mse.sum().item()\n",
    "                    mse1_ += mse[:,0].sum().item()\n",
    "                    mse2_ += mse[:,1].sum().item()\n",
    "                    mse3_ += mse[:,2].sum().item()\n",
    "                    mse4_ += mse[:,3].sum().item()\n",
    "\n",
    "                test_kl = kl_/len(testset)\n",
    "                test_mse = np.sqrt(mse_/len(testset))\n",
    "                test_mse1 = np.sqrt(mse1_/len(testset))\n",
    "                test_mse2 = np.sqrt(mse2_/len(testset))\n",
    "                test_mse3 = np.sqrt(mse3_/len(testset))\n",
    "                test_mse4 = np.sqrt(mse4_/len(testset))\n",
    "\n",
    "                r1 = r2_score(y_batch.numpy()[:,0],torch.exp(probs).detach().numpy()[:,0])\n",
    "                r2 = r2_score(y_batch.numpy()[:,1],torch.exp(probs).detach().numpy()[:,1])\n",
    "                r3 = r2_score(y_batch.numpy()[:,2],torch.exp(probs).detach().numpy()[:,2])\n",
    "                r4 = r2_score(y_batch.numpy()[:,3],torch.exp(probs).detach().numpy()[:,3])\n",
    "\n",
    "                if epoch >= 40:\n",
    "                    if (np.abs(loss_ - ref1)/ref1<0.001) & (np.abs(loss_ - ref2)/ref2<0.001):\n",
    "                        converged = 1\n",
    "                        print(\"Early stopping at epoch\", epoch)\n",
    "                        break\n",
    "                    if (ref1 < loss_) & (ref1 < ref2):\n",
    "                        print(\"Diverging. stop.\")\n",
    "                        break\n",
    "                    if loss_ < best:\n",
    "                        best = loss_\n",
    "                        best_epoch = epoch\n",
    "                        output = (best_epoch, train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                else:\n",
    "                    best = loss_\n",
    "                    best_epoch = epoch\n",
    "                    output = (best_epoch, train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                ref2 = ref1\n",
    "                ref1 = loss_\n",
    "\n",
    "            if epoch % 300 == 0:\n",
    "\n",
    "                print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} RMSE {train_mse:.3f}\")\n",
    "                   # {train_mse1:.3f} {train_mse2:.3f} {train_mse3:.3f} {train_mse4:.3f}\")\n",
    "                print(f\"\\t\\t\\t\\t\\t\\t Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "                print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} RMSE {np.sqrt(mse_/len(testset)):.3f}\")\n",
    "                   #     {np.sqrt(mse1_/len(testset)):.3f} {np.sqrt(mse2_/len(testset)):.3f} {np.sqrt(mse3_/len(testset)):.3f} {np.sqrt(mse4_/len(testset)):.3f}\")\n",
    "                print(f\"\\t\\t\\t\\t\\t\\t Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "                print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "                print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "        with open(out_dir+\"SAE_A_MNL.csv\", \"a\") as f:\n",
    "            f.write(\"%.1E,%.1E,%.1E,%d,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%d\\n\" % \n",
    "                    ((0,lr,wd)+output+(converged,)))\n",
    "\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Train KL loss: {output[1]:.3f} Train R2 score: {output[13]:.3f} {output[14]:.3f} {output[15]:.3f} {output[16]:.3f} \")\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Test KL loss: {output[7]:.3f} Test R2 score: {output[17]:.3f} {output[18]:.3f} {output[19]:.3f} {output[20]:.3f} \")\n",
    "        print()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 0.0001, wd: 1.00e-01]\n",
      "[epoch:   0] Train KL loss: 0.943 RMSE 0.711\n",
      "\t\t\t\t\t\t Train R2 score: -3.000 -5.447 -5.411 -1.381 \n",
      "[epoch:   0] Test KL loss: 0.239 RMSE 0.310\n",
      "\t\t\t\t\t\t Test R2 score: -0.071 -0.137 -0.319 -0.085 \n",
      "[epoch:   0] Train KL loss: 0.943 Train R2 score: -3.000 -5.447 -5.411 -1.381 \n",
      "[epoch:   0] Test KL loss: 0.239 Test R2 score: -0.071 -0.137 -0.319 -0.085 \n",
      "[epoch: 300] Train KL loss: 0.164 RMSE 0.242\n",
      "\t\t\t\t\t\t Train R2 score: 0.340 0.438 0.004 0.356 \n",
      "[epoch: 300] Test KL loss: 0.143 RMSE 0.227\n",
      "\t\t\t\t\t\t Test R2 score: 0.344 0.452 -0.066 0.341 \n",
      "[epoch: 300] Train KL loss: 0.164 Train R2 score: 0.340 0.438 0.004 0.356 \n",
      "[epoch: 300] Test KL loss: 0.143 Test R2 score: 0.344 0.452 -0.066 0.341 \n",
      "[epoch: 600] Train KL loss: 0.152 RMSE 0.227\n",
      "\t\t\t\t\t\t Train R2 score: 0.416 0.514 0.014 0.405 \n",
      "[epoch: 600] Test KL loss: 0.130 RMSE 0.209\n",
      "\t\t\t\t\t\t Test R2 score: 0.430 0.553 -0.076 0.406 \n",
      "[epoch: 600] Train KL loss: 0.152 Train R2 score: 0.416 0.514 0.014 0.405 \n",
      "[epoch: 600] Test KL loss: 0.130 Test R2 score: 0.430 0.553 -0.076 0.406 \n",
      "[epoch: 900] Train KL loss: 0.145 RMSE 0.219\n",
      "\t\t\t\t\t\t Train R2 score: 0.460 0.555 0.024 0.436 \n",
      "[epoch: 900] Test KL loss: 0.122 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.475 0.606 -0.080 0.445 \n",
      "[epoch: 900] Train KL loss: 0.145 Train R2 score: 0.460 0.555 0.024 0.436 \n",
      "[epoch: 900] Test KL loss: 0.122 Test R2 score: 0.475 0.606 -0.080 0.445 \n",
      "Early stopping at epoch 1070\n",
      "[epoch: 1065] Train KL loss: 0.142 Train R2 score: 0.475 0.569 0.031 0.448 \n",
      "[epoch: 1065] Test KL loss: 0.119 Test R2 score: 0.489 0.622 -0.082 0.457 \n",
      "\n",
      "[lr: 0.0001, wd: 1.00e+00]\n",
      "[epoch:   0] Train KL loss: 0.827 RMSE 0.676\n",
      "\t\t\t\t\t\t Train R2 score: 0.001 -4.538 -9.442 -8.142 \n",
      "[epoch:   0] Test KL loss: 0.256 RMSE 0.297\n",
      "\t\t\t\t\t\t Test R2 score: -0.181 0.064 -0.886 0.013 \n",
      "[epoch:   0] Train KL loss: 0.827 Train R2 score: 0.001 -4.538 -9.442 -8.142 \n",
      "[epoch:   0] Test KL loss: 0.256 Test R2 score: -0.181 0.064 -0.886 0.013 \n",
      "[epoch: 300] Train KL loss: 0.161 RMSE 0.238\n",
      "\t\t\t\t\t\t Train R2 score: 0.373 0.459 0.003 0.347 \n",
      "[epoch: 300] Test KL loss: 0.140 RMSE 0.223\n",
      "\t\t\t\t\t\t Test R2 score: 0.378 0.473 -0.059 0.334 \n",
      "[epoch: 300] Train KL loss: 0.161 Train R2 score: 0.373 0.459 0.003 0.347 \n",
      "[epoch: 300] Test KL loss: 0.140 Test R2 score: 0.378 0.473 -0.059 0.334 \n",
      "[epoch: 600] Train KL loss: 0.149 RMSE 0.223\n",
      "\t\t\t\t\t\t Train R2 score: 0.451 0.534 0.011 0.394 \n",
      "[epoch: 600] Test KL loss: 0.126 RMSE 0.205\n",
      "\t\t\t\t\t\t Test R2 score: 0.466 0.576 -0.066 0.392 \n",
      "[epoch: 600] Train KL loss: 0.149 Train R2 score: 0.451 0.534 0.011 0.394 \n",
      "[epoch: 600] Test KL loss: 0.126 Test R2 score: 0.466 0.576 -0.066 0.392 \n",
      "[epoch: 900] Train KL loss: 0.143 RMSE 0.216\n",
      "\t\t\t\t\t\t Train R2 score: 0.485 0.569 0.019 0.425 \n",
      "[epoch: 900] Test KL loss: 0.119 RMSE 0.196\n",
      "\t\t\t\t\t\t Test R2 score: 0.496 0.619 -0.073 0.433 \n",
      "[epoch: 900] Train KL loss: 0.143 Train R2 score: 0.485 0.569 0.019 0.425 \n",
      "[epoch: 900] Test KL loss: 0.119 Test R2 score: 0.496 0.619 -0.073 0.433 \n",
      "Early stopping at epoch 990\n",
      "[epoch: 985] Train KL loss: 0.142 Train R2 score: 0.492 0.575 0.022 0.432 \n",
      "[epoch: 985] Test KL loss: 0.118 Test R2 score: 0.500 0.625 -0.074 0.441 \n",
      "\n",
      "[lr: 0.0001, wd: 1.00e+01]\n",
      "[epoch:   0] Train KL loss: 1.140 RMSE 0.781\n",
      "\t\t\t\t\t\t Train R2 score: -1.000 -6.625 -3.324 -11.773 \n",
      "[epoch:   0] Test KL loss: 0.251 RMSE 0.313\n",
      "\t\t\t\t\t\t Test R2 score: -0.057 -0.103 -0.317 -0.524 \n",
      "[epoch:   0] Train KL loss: 1.140 Train R2 score: -1.000 -6.625 -3.324 -11.773 \n",
      "[epoch:   0] Test KL loss: 0.251 Test R2 score: -0.057 -0.103 -0.317 -0.524 \n",
      "[epoch: 300] Train KL loss: 0.164 RMSE 0.242\n",
      "\t\t\t\t\t\t Train R2 score: 0.340 0.434 0.003 0.345 \n",
      "[epoch: 300] Test KL loss: 0.144 RMSE 0.229\n",
      "\t\t\t\t\t\t Test R2 score: 0.339 0.442 -0.052 0.329 \n",
      "[epoch: 300] Train KL loss: 0.164 Train R2 score: 0.340 0.434 0.003 0.345 \n",
      "[epoch: 300] Test KL loss: 0.144 Test R2 score: 0.339 0.442 -0.052 0.329 \n",
      "[epoch: 600] Train KL loss: 0.152 RMSE 0.228\n",
      "\t\t\t\t\t\t Train R2 score: 0.418 0.512 0.012 0.392 \n",
      "[epoch: 600] Test KL loss: 0.130 RMSE 0.210\n",
      "\t\t\t\t\t\t Test R2 score: 0.430 0.548 -0.061 0.390 \n",
      "[epoch: 600] Train KL loss: 0.152 Train R2 score: 0.418 0.512 0.012 0.392 \n",
      "[epoch: 600] Test KL loss: 0.130 Test R2 score: 0.430 0.548 -0.061 0.390 \n",
      "[epoch: 900] Train KL loss: 0.145 RMSE 0.219\n",
      "\t\t\t\t\t\t Train R2 score: 0.461 0.553 0.022 0.422 \n",
      "[epoch: 900] Test KL loss: 0.122 RMSE 0.200\n",
      "\t\t\t\t\t\t Test R2 score: 0.476 0.603 -0.066 0.430 \n",
      "[epoch: 900] Train KL loss: 0.145 Train R2 score: 0.461 0.553 0.022 0.422 \n",
      "[epoch: 900] Test KL loss: 0.122 Test R2 score: 0.476 0.603 -0.066 0.430 \n",
      "Early stopping at epoch 1025\n",
      "[epoch: 1020] Train KL loss: 0.143 Train R2 score: 0.472 0.563 0.026 0.431 \n",
      "[epoch: 1020] Test KL loss: 0.120 Test R2 score: 0.485 0.615 -0.067 0.441 \n",
      "\n",
      "[lr: 0.0001, wd: 5.00e+01]\n",
      "[epoch:   0] Train KL loss: 1.375 RMSE 0.852\n",
      "\t\t\t\t\t\t Train R2 score: -0.095 -7.507 -53.730 -1.551 \n",
      "[epoch:   0] Test KL loss: 0.329 RMSE 0.358\n",
      "\t\t\t\t\t\t Test R2 score: -0.042 -0.318 -16.893 0.038 \n",
      "[epoch:   0] Train KL loss: 1.375 Train R2 score: -0.095 -7.507 -53.730 -1.551 \n",
      "[epoch:   0] Test KL loss: 0.329 Test R2 score: -0.042 -0.318 -16.893 0.038 \n",
      "Diverging. stop.\n",
      "[epoch:  35] Train KL loss: 0.207 Train R2 score: 0.156 0.202 -0.075 0.116 \n",
      "[epoch:  35] Test KL loss: 0.183 Test R2 score: 0.132 0.196 -0.064 0.140 \n",
      "\n",
      "[lr: 0.0001, wd: 1.00e+02]\n",
      "[epoch:   0] Train KL loss: 0.465 RMSE 0.493\n",
      "\t\t\t\t\t\t Train R2 score: -0.713 -2.015 -2.779 -0.889 \n",
      "[epoch:   0] Test KL loss: 0.255 RMSE 0.314\n",
      "\t\t\t\t\t\t Test R2 score: -0.104 -0.174 -0.049 -0.126 \n",
      "[epoch:   0] Train KL loss: 0.465 Train R2 score: -0.713 -2.015 -2.779 -0.889 \n",
      "[epoch:   0] Test KL loss: 0.255 Test R2 score: -0.104 -0.174 -0.049 -0.126 \n",
      "[epoch: 300] Train KL loss: 0.161 RMSE 0.239\n",
      "\t\t\t\t\t\t Train R2 score: 0.356 0.453 0.006 0.363 \n",
      "[epoch: 300] Test KL loss: 0.140 RMSE 0.224\n",
      "\t\t\t\t\t\t Test R2 score: 0.363 0.472 -0.064 0.351 \n",
      "[epoch: 300] Train KL loss: 0.161 Train R2 score: 0.356 0.453 0.006 0.363 \n",
      "[epoch: 300] Test KL loss: 0.140 Test R2 score: 0.363 0.472 -0.064 0.351 \n",
      "[epoch: 600] Train KL loss: 0.151 RMSE 0.226\n",
      "\t\t\t\t\t\t Train R2 score: 0.423 0.521 0.012 0.407 \n",
      "[epoch: 600] Test KL loss: 0.128 RMSE 0.208\n",
      "\t\t\t\t\t\t Test R2 score: 0.439 0.562 -0.066 0.411 \n",
      "[epoch: 600] Train KL loss: 0.151 Train R2 score: 0.423 0.521 0.012 0.407 \n",
      "[epoch: 600] Test KL loss: 0.128 Test R2 score: 0.439 0.562 -0.066 0.411 \n",
      "Early stopping at epoch 765\n",
      "[epoch: 760] Train KL loss: 0.148 Train R2 score: 0.443 0.539 0.015 0.419 \n",
      "[epoch: 760] Test KL loss: 0.125 Test R2 score: 0.459 0.585 -0.066 0.425 \n",
      "\n",
      "[lr: 0.0001, wd: 1.00e+03]\n",
      "[epoch:   0] Train KL loss: 1.137 RMSE 0.774\n",
      "\t\t\t\t\t\t Train R2 score: -0.400 -6.514 -24.147 -4.786 \n",
      "[epoch:   0] Test KL loss: 0.274 RMSE 0.315\n",
      "\t\t\t\t\t\t Test R2 score: -0.063 -0.051 -5.366 -0.098 \n",
      "[epoch:   0] Train KL loss: 1.137 Train R2 score: -0.400 -6.514 -24.147 -4.786 \n",
      "[epoch:   0] Test KL loss: 0.274 Test R2 score: -0.063 -0.051 -5.366 -0.098 \n",
      "[epoch: 300] Train KL loss: 0.168 RMSE 0.247\n",
      "\t\t\t\t\t\t Train R2 score: 0.316 0.408 -0.002 0.326 \n",
      "[epoch: 300] Test KL loss: 0.148 RMSE 0.234\n",
      "\t\t\t\t\t\t Test R2 score: 0.315 0.411 -0.056 0.314 \n",
      "[epoch: 300] Train KL loss: 0.168 Train R2 score: 0.316 0.408 -0.002 0.326 \n",
      "[epoch: 300] Test KL loss: 0.148 Test R2 score: 0.315 0.411 -0.056 0.314 \n",
      "Early stopping at epoch 430\n",
      "[epoch: 425] Train KL loss: 0.165 Train R2 score: 0.333 0.427 -0.001 0.338 \n",
      "[epoch: 425] Test KL loss: 0.145 Test R2 score: 0.335 0.437 -0.058 0.328 \n",
      "\n",
      "[lr: 0.0001, wd: 1.00e-01]\n",
      "[epoch:   0] Train KL loss: 0.622 RMSE 0.576\n",
      "\t\t\t\t\t\t Train R2 score: -0.215 -2.911 -15.715 -1.330 \n",
      "[epoch:   0] Test KL loss: 0.286 RMSE 0.314\n",
      "\t\t\t\t\t\t Test R2 score: -0.267 -0.104 -0.460 -0.027 \n",
      "[epoch:   0] Train KL loss: 0.622 Train R2 score: -0.215 -2.911 -15.715 -1.330 \n",
      "[epoch:   0] Test KL loss: 0.286 Test R2 score: -0.267 -0.104 -0.460 -0.027 \n",
      "[epoch: 300] Train KL loss: 0.160 RMSE 0.237\n",
      "\t\t\t\t\t\t Train R2 score: 0.369 0.465 0.001 0.368 \n",
      "[epoch: 300] Test KL loss: 0.138 RMSE 0.221\n",
      "\t\t\t\t\t\t Test R2 score: 0.377 0.490 -0.060 0.366 \n",
      "[epoch: 300] Train KL loss: 0.160 Train R2 score: 0.369 0.465 0.001 0.368 \n",
      "[epoch: 300] Test KL loss: 0.138 Test R2 score: 0.377 0.490 -0.060 0.366 \n",
      "[epoch: 600] Train KL loss: 0.148 RMSE 0.222\n",
      "\t\t\t\t\t\t Train R2 score: 0.444 0.541 0.008 0.419 \n",
      "[epoch: 600] Test KL loss: 0.124 RMSE 0.202\n",
      "\t\t\t\t\t\t Test R2 score: 0.460 0.590 -0.066 0.432 \n",
      "[epoch: 600] Train KL loss: 0.148 Train R2 score: 0.444 0.541 0.008 0.419 \n",
      "[epoch: 600] Test KL loss: 0.124 Test R2 score: 0.460 0.590 -0.066 0.432 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 900] Train KL loss: 0.142 RMSE 0.215\n",
      "\t\t\t\t\t\t Train R2 score: 0.480 0.573 0.016 0.447 \n",
      "[epoch: 900] Test KL loss: 0.118 RMSE 0.195\n",
      "\t\t\t\t\t\t Test R2 score: 0.491 0.628 -0.073 0.462 \n",
      "[epoch: 900] Train KL loss: 0.142 Train R2 score: 0.480 0.573 0.016 0.447 \n",
      "[epoch: 900] Test KL loss: 0.118 Test R2 score: 0.491 0.628 -0.073 0.462 \n",
      "Early stopping at epoch 975\n",
      "[epoch: 970] Train KL loss: 0.141 Train R2 score: 0.486 0.578 0.018 0.453 \n",
      "[epoch: 970] Test KL loss: 0.118 Test R2 score: 0.495 0.632 -0.073 0.467 \n",
      "\n",
      "[lr: 0.0001, wd: 1.00e+00]\n",
      "[epoch:   0] Train KL loss: 0.582 RMSE 0.556\n",
      "\t\t\t\t\t\t Train R2 score: -0.017 -2.704 -5.607 -4.607 \n",
      "[epoch:   0] Test KL loss: 0.283 RMSE 0.317\n",
      "\t\t\t\t\t\t Test R2 score: -0.274 -0.140 -0.063 -0.017 \n",
      "[epoch:   0] Train KL loss: 0.582 Train R2 score: -0.017 -2.704 -5.607 -4.607 \n",
      "[epoch:   0] Test KL loss: 0.283 Test R2 score: -0.274 -0.140 -0.063 -0.017 \n",
      "[epoch: 300] Train KL loss: 0.160 RMSE 0.237\n",
      "\t\t\t\t\t\t Train R2 score: 0.367 0.465 0.005 0.365 \n",
      "[epoch: 300] Test KL loss: 0.139 RMSE 0.222\n",
      "\t\t\t\t\t\t Test R2 score: 0.373 0.484 -0.055 0.349 \n",
      "[epoch: 300] Train KL loss: 0.160 Train R2 score: 0.367 0.465 0.005 0.365 \n",
      "[epoch: 300] Test KL loss: 0.139 Test R2 score: 0.373 0.484 -0.055 0.349 \n",
      "[epoch: 600] Train KL loss: 0.148 RMSE 0.222\n",
      "\t\t\t\t\t\t Train R2 score: 0.446 0.541 0.013 0.413 \n",
      "[epoch: 600] Test KL loss: 0.125 RMSE 0.203\n",
      "\t\t\t\t\t\t Test R2 score: 0.463 0.589 -0.065 0.413 \n",
      "[epoch: 600] Train KL loss: 0.148 Train R2 score: 0.446 0.541 0.013 0.413 \n",
      "[epoch: 600] Test KL loss: 0.125 Test R2 score: 0.463 0.589 -0.065 0.413 \n",
      "[epoch: 900] Train KL loss: 0.142 RMSE 0.215\n",
      "\t\t\t\t\t\t Train R2 score: 0.481 0.573 0.024 0.440 \n",
      "[epoch: 900] Test KL loss: 0.118 RMSE 0.195\n",
      "\t\t\t\t\t\t Test R2 score: 0.495 0.628 -0.070 0.446 \n",
      "[epoch: 900] Train KL loss: 0.142 Train R2 score: 0.481 0.573 0.024 0.440 \n",
      "[epoch: 900] Test KL loss: 0.118 Test R2 score: 0.495 0.628 -0.070 0.446 \n",
      "Early stopping at epoch 990\n",
      "[epoch: 985] Train KL loss: 0.141 Train R2 score: 0.488 0.579 0.027 0.446 \n",
      "[epoch: 985] Test KL loss: 0.117 Test R2 score: 0.499 0.633 -0.071 0.452 \n",
      "\n",
      "[lr: 0.0001, wd: 1.00e+01]\n",
      "[epoch:   0] Train KL loss: 0.867 RMSE 0.693\n",
      "\t\t\t\t\t\t Train R2 score: -0.111 -4.915 -23.842 -2.436 \n",
      "[epoch:   0] Test KL loss: 0.259 RMSE 0.308\n",
      "\t\t\t\t\t\t Test R2 score: -0.159 -0.049 -1.624 0.018 \n",
      "[epoch:   0] Train KL loss: 0.867 Train R2 score: -0.111 -4.915 -23.842 -2.436 \n",
      "[epoch:   0] Test KL loss: 0.259 Test R2 score: -0.159 -0.049 -1.624 0.018 \n",
      "[epoch: 300] Train KL loss: 0.162 RMSE 0.239\n",
      "\t\t\t\t\t\t Train R2 score: 0.357 0.452 0.002 0.356 \n",
      "[epoch: 300] Test KL loss: 0.141 RMSE 0.224\n",
      "\t\t\t\t\t\t Test R2 score: 0.362 0.467 -0.065 0.350 \n",
      "[epoch: 300] Train KL loss: 0.162 Train R2 score: 0.357 0.452 0.002 0.356 \n",
      "[epoch: 300] Test KL loss: 0.141 Test R2 score: 0.362 0.467 -0.065 0.350 \n",
      "[epoch: 600] Train KL loss: 0.149 RMSE 0.224\n",
      "\t\t\t\t\t\t Train R2 score: 0.435 0.529 0.009 0.408 \n",
      "[epoch: 600] Test KL loss: 0.126 RMSE 0.205\n",
      "\t\t\t\t\t\t Test R2 score: 0.451 0.574 -0.069 0.415 \n",
      "[epoch: 600] Train KL loss: 0.149 Train R2 score: 0.435 0.529 0.009 0.408 \n",
      "[epoch: 600] Test KL loss: 0.126 Test R2 score: 0.451 0.574 -0.069 0.415 \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[1e-3]);\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[1e-2]);\n",
    "\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[1e-1]);\n",
    "#     model = mnl_torch(lr_list=[1e-5], wd_list=[1e+0]);\n",
    "    mnl_torch(lr_list=[1e-4], wd_list=[0.1,1,10,50,100,1000]);\n",
    "#     mnl_torch(lr_list=[1e-5], wd_list=[1e+1]);\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[50]);\n",
    "\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[1e+2]);\n",
    "\n",
    "#     mnl_torch(lr_list=[5e-5], wd_list=[1e+3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 0.000, wd: 1.00e-01]\n",
      "[epoch:   0] Train KL loss: 0.920 RMSE 0.709\n",
      "\t\t\t\t\t\t Train R2 score: -1.233 -5.224 -22.002 -0.707 \n",
      "[epoch:   0] Test KL loss: 0.478 RMSE 0.364\n",
      "\t\t\t\t\t\t Test R2 score: -0.391 -0.619 -0.961 -0.398 \n",
      "[epoch:   0] Train KL loss: 0.920 Train R2 score: -1.233 -5.224 -22.002 -0.707 \n",
      "[epoch:   0] Test KL loss: 0.478 Test R2 score: -0.391 -0.619 -0.961 -0.398 \n",
      "[epoch: 100] Train KL loss: 0.154 RMSE 0.228\n",
      "\t\t\t\t\t\t Train R2 score: 0.413 0.508 0.001 0.398 \n",
      "[epoch: 100] Test KL loss: 0.146 RMSE 0.228\n",
      "\t\t\t\t\t\t Test R2 score: 0.358 0.442 -0.078 0.346 \n",
      "[epoch: 100] Train KL loss: 0.154 Train R2 score: 0.413 0.508 0.001 0.398 \n",
      "[epoch: 100] Test KL loss: 0.146 Test R2 score: 0.358 0.442 -0.078 0.346 \n",
      "[epoch: 200] Train KL loss: 0.144 RMSE 0.218\n",
      "\t\t\t\t\t\t Train R2 score: 0.465 0.557 0.020 0.449 \n",
      "[epoch: 200] Test KL loss: 0.136 RMSE 0.218\n",
      "\t\t\t\t\t\t Test R2 score: 0.410 0.493 -0.074 0.369 \n",
      "[epoch: 200] Train KL loss: 0.144 Train R2 score: 0.465 0.557 0.020 0.449 \n",
      "[epoch: 200] Test KL loss: 0.136 Test R2 score: 0.410 0.493 -0.074 0.369 \n",
      "[epoch: 300] Train KL loss: 0.136 RMSE 0.210\n",
      "\t\t\t\t\t\t Train R2 score: 0.507 0.595 0.039 0.490 \n",
      "[epoch: 300] Test KL loss: 0.131 RMSE 0.213\n",
      "\t\t\t\t\t\t Test R2 score: 0.442 0.524 -0.094 0.377 \n",
      "[epoch: 300] Train KL loss: 0.136 Train R2 score: 0.507 0.595 0.039 0.490 \n",
      "[epoch: 300] Test KL loss: 0.131 Test R2 score: 0.442 0.524 -0.094 0.377 \n",
      "[epoch: 400] Train KL loss: 0.129 RMSE 0.202\n",
      "\t\t\t\t\t\t Train R2 score: 0.543 0.626 0.057 0.527 \n",
      "[epoch: 400] Test KL loss: 0.127 RMSE 0.209\n",
      "\t\t\t\t\t\t Test R2 score: 0.465 0.545 -0.118 0.383 \n",
      "[epoch: 400] Train KL loss: 0.129 Train R2 score: 0.543 0.626 0.057 0.527 \n",
      "[epoch: 400] Test KL loss: 0.127 Test R2 score: 0.465 0.545 -0.118 0.383 \n",
      "[epoch: 500] Train KL loss: 0.123 RMSE 0.195\n",
      "\t\t\t\t\t\t Train R2 score: 0.574 0.653 0.076 0.560 \n",
      "[epoch: 500] Test KL loss: 0.125 RMSE 0.206\n",
      "\t\t\t\t\t\t Test R2 score: 0.482 0.560 -0.142 0.389 \n",
      "[epoch: 500] Train KL loss: 0.123 Train R2 score: 0.574 0.653 0.076 0.560 \n",
      "[epoch: 500] Test KL loss: 0.125 Test R2 score: 0.482 0.560 -0.142 0.389 \n",
      "[epoch: 600] Train KL loss: 0.118 RMSE 0.189\n",
      "\t\t\t\t\t\t Train R2 score: 0.601 0.677 0.095 0.591 \n",
      "[epoch: 600] Test KL loss: 0.123 RMSE 0.204\n",
      "\t\t\t\t\t\t Test R2 score: 0.495 0.571 -0.162 0.394 \n",
      "[epoch: 600] Train KL loss: 0.118 Train R2 score: 0.601 0.677 0.095 0.591 \n",
      "[epoch: 600] Test KL loss: 0.123 Test R2 score: 0.495 0.571 -0.162 0.394 \n",
      "[epoch: 700] Train KL loss: 0.114 RMSE 0.183\n",
      "\t\t\t\t\t\t Train R2 score: 0.625 0.697 0.115 0.620 \n",
      "[epoch: 700] Test KL loss: 0.122 RMSE 0.202\n",
      "\t\t\t\t\t\t Test R2 score: 0.505 0.579 -0.179 0.397 \n",
      "[epoch: 700] Train KL loss: 0.114 Train R2 score: 0.625 0.697 0.115 0.620 \n",
      "[epoch: 700] Test KL loss: 0.122 Test R2 score: 0.505 0.579 -0.179 0.397 \n",
      "[epoch: 800] Train KL loss: 0.109 RMSE 0.178\n",
      "\t\t\t\t\t\t Train R2 score: 0.647 0.716 0.136 0.646 \n",
      "[epoch: 800] Test KL loss: 0.121 RMSE 0.201\n",
      "\t\t\t\t\t\t Test R2 score: 0.514 0.585 -0.193 0.399 \n",
      "[epoch: 800] Train KL loss: 0.109 Train R2 score: 0.647 0.716 0.136 0.646 \n",
      "[epoch: 800] Test KL loss: 0.121 Test R2 score: 0.514 0.585 -0.193 0.399 \n",
      "[epoch: 900] Train KL loss: 0.105 RMSE 0.173\n",
      "\t\t\t\t\t\t Train R2 score: 0.667 0.732 0.157 0.670 \n",
      "[epoch: 900] Test KL loss: 0.121 RMSE 0.200\n",
      "\t\t\t\t\t\t Test R2 score: 0.520 0.589 -0.204 0.399 \n",
      "[epoch: 900] Train KL loss: 0.105 Train R2 score: 0.667 0.732 0.157 0.670 \n",
      "[epoch: 900] Test KL loss: 0.121 Test R2 score: 0.520 0.589 -0.204 0.399 \n",
      "[epoch: 1000] Train KL loss: 0.102 RMSE 0.168\n",
      "\t\t\t\t\t\t Train R2 score: 0.686 0.748 0.179 0.693 \n",
      "[epoch: 1000] Test KL loss: 0.120 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.525 0.592 -0.213 0.397 \n",
      "[epoch: 1000] Train KL loss: 0.102 Train R2 score: 0.686 0.748 0.179 0.693 \n",
      "[epoch: 1000] Test KL loss: 0.120 Test R2 score: 0.525 0.592 -0.213 0.397 \n",
      "[epoch: 1100] Train KL loss: 0.098 RMSE 0.164\n",
      "\t\t\t\t\t\t Train R2 score: 0.703 0.762 0.202 0.713 \n",
      "[epoch: 1100] Test KL loss: 0.120 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.529 0.595 -0.221 0.395 \n",
      "[epoch: 1100] Train KL loss: 0.098 Train R2 score: 0.703 0.762 0.202 0.713 \n",
      "[epoch: 1100] Test KL loss: 0.120 Test R2 score: 0.529 0.595 -0.221 0.395 \n",
      "[epoch: 1200] Train KL loss: 0.095 RMSE 0.159\n",
      "\t\t\t\t\t\t Train R2 score: 0.719 0.775 0.224 0.733 \n",
      "[epoch: 1200] Test KL loss: 0.120 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.532 0.596 -0.227 0.391 \n",
      "[epoch: 1200] Train KL loss: 0.095 Train R2 score: 0.719 0.775 0.224 0.733 \n",
      "[epoch: 1200] Test KL loss: 0.120 Test R2 score: 0.532 0.596 -0.227 0.391 \n",
      "[epoch: 1300] Train KL loss: 0.092 RMSE 0.155\n",
      "\t\t\t\t\t\t Train R2 score: 0.735 0.787 0.248 0.750 \n",
      "[epoch: 1300] Test KL loss: 0.120 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.534 0.596 -0.233 0.387 \n",
      "[epoch: 1300] Train KL loss: 0.092 Train R2 score: 0.735 0.787 0.248 0.750 \n",
      "[epoch: 1300] Test KL loss: 0.120 Test R2 score: 0.534 0.596 -0.233 0.387 \n",
      "[epoch: 1400] Train KL loss: 0.088 RMSE 0.151\n",
      "\t\t\t\t\t\t Train R2 score: 0.750 0.799 0.272 0.767 \n",
      "[epoch: 1400] Test KL loss: 0.120 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.535 0.596 -0.238 0.382 \n",
      "[epoch: 1400] Train KL loss: 0.088 Train R2 score: 0.750 0.799 0.272 0.767 \n",
      "[epoch: 1400] Test KL loss: 0.120 Test R2 score: 0.535 0.596 -0.238 0.382 \n",
      "[epoch: 1500] Train KL loss: 0.085 RMSE 0.147\n",
      "\t\t\t\t\t\t Train R2 score: 0.764 0.810 0.296 0.782 \n",
      "[epoch: 1500] Test KL loss: 0.121 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.535 0.596 -0.243 0.376 \n",
      "[epoch: 1500] Train KL loss: 0.085 Train R2 score: 0.764 0.810 0.296 0.782 \n",
      "[epoch: 1500] Test KL loss: 0.121 Test R2 score: 0.535 0.596 -0.243 0.376 \n",
      "[epoch: 1600] Train KL loss: 0.083 RMSE 0.142\n",
      "\t\t\t\t\t\t Train R2 score: 0.777 0.821 0.320 0.796 \n",
      "[epoch: 1600] Test KL loss: 0.121 RMSE 0.199\n",
      "\t\t\t\t\t\t Test R2 score: 0.534 0.594 -0.247 0.371 \n",
      "[epoch: 1600] Train KL loss: 0.083 Train R2 score: 0.777 0.821 0.320 0.796 \n",
      "[epoch: 1600] Test KL loss: 0.121 Test R2 score: 0.534 0.594 -0.247 0.371 \n",
      "Diverging. stop.\n",
      "[epoch: 1650] Train KL loss: 0.081 Train R2 score: 0.786 0.826 0.335 0.805 \n",
      "[epoch: 1650] Test KL loss: 0.120 Test R2 score: 0.541 0.604 -0.232 0.378 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnl_torch(lr_list=[0.0001], wd_list=[1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qingyi",
   "language": "python",
   "name": "qingyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
