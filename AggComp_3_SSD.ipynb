{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents part 2 of the complementarity of image and demographic information: the ability of latent space extracted from Autoencoders to predict mode choice and trip generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from dataloader import SurveyDataset, load_aggregate_travel_behavior, load_demo\n",
    "from M1_util_train_test import load_model, test\n",
    "import linear_reg\n",
    "import mnl\n",
    "from setup import out_dir, data_dir, image_dir, model_dir, proj_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = '1571'\n",
    "\n",
    "model_type = 'SSD'\n",
    "sampling = 's'\n",
    "\n",
    "zoomlevel = 'zoom15'\n",
    "output_dim = 3\n",
    "model_run_date = '2208'\n",
    "\n",
    "v2 = 1\n",
    "\n",
    "variable_names = ['active','auto','mas','pt', 'trpgen']\n",
    "\n",
    "demo_variables = ['tot_population','pct25_34yrs','pct35_50yrs','pctover65yrs',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pct_col_grad','avg_tt_to_work','inc_per_capita']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(proj_dir+\"latent_space/SSD_\"+zoomlevel+\"_\"+str(output_dim**2*2048)+\"_\"+str(v2)+\"_\"+\n",
    "                       str(model_run_date)+\".pkl\", \"rb\") as f:\n",
    "    encoder_output = pkl.load(f)\n",
    "    im = pkl.load(f)\n",
    "    ct = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Embeddings\n",
    "unique_ct = list(set(ct))\n",
    "unique_ct.sort()\n",
    "ct = np.array(ct)\n",
    "aggregate_embeddings = []\n",
    "for i in unique_ct:\n",
    "    aggregate_embeddings.append(np.mean(encoder_output[ct == i], axis=0))\n",
    "aggregate_embeddings = np.array(aggregate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trip Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"origin_trip_behavior.csv\"\n",
    "df_pivot = load_aggregate_travel_behavior(file, data_version)\n",
    "\n",
    "train_test_index = df_pivot['train_test'].astype(bool).to_numpy()\n",
    "# train_test_index = np.random.rand(len(df_pivot)) < 0.2\n",
    "\n",
    "y = df_pivot[variable_names].to_numpy()\n",
    "y_train = y[~train_test_index,:4]\n",
    "y_test = y[train_test_index,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = aggregate_embeddings[~train_test_index, :]\n",
    "x_test = aggregate_embeddings[train_test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train = y[~train_test_index,1]\n",
    "auto_test = y[train_test_index,1]\n",
    "\n",
    "pt_train = y[~train_test_index,3]\n",
    "pt_test = y[train_test_index,3]\n",
    "\n",
    "active_train = y[~train_test_index,0]\n",
    "active_test = y[train_test_index,0]\n",
    "\n",
    "trpgen_train = y[~train_test_index,-1]\n",
    "trpgen_test = y[train_test_index,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Auto Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.5889 \t Test R2: 0.6425\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression without Regularization\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_train, auto_train)\n",
    "print(\"Train R2: %.4f \\t Test R2: %.4f\" % (lr.score(x_train, auto_train), lr.score(x_test, auto_test)))\n",
    "with open(out_dir+\"AllModels_A_LR.csv\", \"a\") as f:\n",
    "    f.write(\"%s,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % ('SSD',0,'auto',\n",
    "        lasso.score(x_train, auto_train), lasso.score(x_test, auto_test), 'LR', \n",
    "        np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "for a in (1e-7)*np.array([0,0.1,0.2,0.4,0.6,0.8,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, auto_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, auto_train), \n",
    "                                                                                  lasso.score(x_test, auto_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    with open(out_dir+\"AllModels_A_LR.csv\", \"a\") as f:\n",
    "        f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (0,a,'auto',\n",
    "            lasso.score(x_train, auto_train), lasso.score(x_test, auto_test), 'lasso', \n",
    "            np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-4)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, auto_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, auto_train), \n",
    "                                                              ridge.score(x_test, auto_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.4686 \t Test R2: 0.5166\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression without Regularization\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_train, pt_train)\n",
    "with open(out_dir+\"AllModels_A_LR.csv\", \"a\") as f:\n",
    "    f.write(\"%s,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % ('SSD',0,'pt',\n",
    "        lr.score(x_train, pt_train), lr.score(x_test, pt_test), 'LR', \n",
    "        np.sum(lr.coef_ != 0), len(lr.coef_)))\n",
    "    \n",
    "print(\"Train R2: %.4f \\t Test R2: %.4f\" % (lr.score(x_train, pt_train), lr.score(x_test, pt_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "for a in (1e-6)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, pt_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, pt_train), \n",
    "                                                                                  lasso.score(x_test, pt_test), \n",
    "                                                                                np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    with open(out_dir+\"AllModels_A_LR.csv\", \"a\") as f:\n",
    "        f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "            lasso.score(x_train, pt_train), lasso.score(x_test, pt_test), 'lasso', \n",
    "            np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e0)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, pt_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, pt_train), \n",
    "                                                              ridge.score(x_test, pt_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.4744 \t Test R2: 0.5156\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression without Regularization\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_train, active_train)\n",
    "with open(out_dir+\"AllModels_A_LR.csv\", \"a\") as f:\n",
    "    f.write(\"%s,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % ('SSD',0,'active',\n",
    "        lr.score(x_train, active_train), lr.score(x_test, active_test), 'LR', \n",
    "        np.sum(lr.coef_ != 0), len(lr.coef_)))\n",
    "print(\"Train R2: %.4f \\t Test R2: %.4f\" % (lr.score(x_train, active_train), lr.score(x_test, active_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for a in (1e-5)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, active_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, active_train), \n",
    "                                                                                  lasso.score(x_test, active_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-2)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, active_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, active_train), \n",
    "                                                              ridge.score(x_test, active_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Trip Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in (1e-4)*np.array([0,0.1,6,7,8,10,11,12,13,14,15,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, trpgen_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, trpgen_train), \n",
    "                                                                                  lasso.score(x_test, trpgen_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e-2)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, trpgen_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, trpgen_train), \n",
    "                                                              ridge.score(x_test, trpgen_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MNL for Mode Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader and model definition\n",
    "\n",
    "trainset = SurveyDataset(torch.tensor(x_train,  dtype=torch.float), torch.tensor(y_train, dtype=torch.float))\n",
    "trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "\n",
    "testset = SurveyDataset(torch.tensor(x_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.float))\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "kldivloss = nn.KLDivLoss(reduction='sum')\n",
    "mseloss = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_train = np.sum(np.power(y_train - np.mean(y_train, axis=0), 2), axis=0)\n",
    "sst_test = np.sum(np.power(y_test - np.mean(y_test, axis=0), 2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mnl_torch(lr_list, wd_list):\n",
    "    \n",
    "    for (lr, wd) in itertools.product(lr_list, wd_list):\n",
    "        \n",
    "        print(f\"[lr: {lr:.3f}, wd: {wd:3.2e}]\")\n",
    "\n",
    "        # model setup\n",
    "        model = mnl.MNL(n_alts=4, n_features=x_train.shape[-1])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        # model training\n",
    "        converged = 0\n",
    "        ref1 = 0\n",
    "        ref2 = 0\n",
    "\n",
    "        for epoch in range(1000):\n",
    "\n",
    "            kl_ = 0\n",
    "            mse_ = 0\n",
    "            mse1_ = 0\n",
    "            mse2_ = 0\n",
    "            mse3_ = 0\n",
    "            mse4_ = 0\n",
    "\n",
    "            for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                util = model(x_batch)\n",
    "                probs = torch.log(nn.functional.softmax(util, dim=1))\n",
    "                kl = kldivloss(probs, y_batch)\n",
    "        #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                kl_ += kl.item()\n",
    "\n",
    "                mse = mseloss(torch.exp(probs), y_batch)\n",
    "        #         mse = mseloss(util, y_batch)\n",
    "                mse_ += mse.sum().item()\n",
    "                mse1_ += mse[:,0].sum().item()\n",
    "                mse2_ += mse[:,1].sum().item()\n",
    "                mse3_ += mse[:,2].sum().item()\n",
    "                mse4_ += mse[:,3].sum().item()\n",
    "                mse = mse.sum()\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                kl.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_kl = kl_/len(trainset)\n",
    "            train_mse = np.sqrt(mse_/len(trainset))\n",
    "            train_mse1 = np.sqrt(mse1_/len(trainset))\n",
    "            train_mse2 = np.sqrt(mse2_/len(trainset))\n",
    "            train_mse3 = np.sqrt(mse3_/len(trainset))\n",
    "            train_mse4 = np.sqrt(mse4_/len(trainset))\n",
    "\n",
    "            train_r1 = 1-mse1_/sst_train[0]\n",
    "            train_r2 = 1-mse2_/sst_train[1]\n",
    "            train_r3 = 1-mse3_/sst_train[2]\n",
    "            train_r4 = 1-mse4_/sst_train[3]\n",
    "\n",
    "            loss_ = train_kl\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "\n",
    "                kl_ = 0\n",
    "                mse_ = 0 \n",
    "                mse1_ = 0\n",
    "                mse2_ = 0\n",
    "                mse3_ = 0\n",
    "                mse4_ = 0\n",
    "\n",
    "                for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "                    \n",
    "                    util = model(x_batch)\n",
    "                    probs = torch.log(nn.functional.softmax(util,dim=1))\n",
    "                    kl = kldivloss(probs, y_batch)\n",
    "            #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                    kl_ += kl.item()\n",
    "\n",
    "                    mse = mseloss(torch.exp(probs), y_batch)\n",
    "            #         mse = mseloss(util, y_batch)\n",
    "                    mse_ += mse.sum().item()\n",
    "                    mse1_ += mse[:,0].sum().item()\n",
    "                    mse2_ += mse[:,1].sum().item()\n",
    "                    mse3_ += mse[:,2].sum().item()\n",
    "                    mse4_ += mse[:,3].sum().item()\n",
    "\n",
    "                test_kl = kl_/len(testset)\n",
    "                test_mse = np.sqrt(mse_/len(testset))\n",
    "                test_mse1 = np.sqrt(mse1_/len(testset))\n",
    "                test_mse2 = np.sqrt(mse2_/len(testset))\n",
    "                test_mse3 = np.sqrt(mse3_/len(testset))\n",
    "                test_mse4 = np.sqrt(mse4_/len(testset))\n",
    "\n",
    "                r1 = r2_score(y_batch.numpy()[:,0],torch.exp(probs).detach().numpy()[:,0])\n",
    "                r2 = r2_score(y_batch.numpy()[:,1],torch.exp(probs).detach().numpy()[:,1])\n",
    "                r3 = r2_score(y_batch.numpy()[:,2],torch.exp(probs).detach().numpy()[:,2])\n",
    "                r4 = r2_score(y_batch.numpy()[:,3],torch.exp(probs).detach().numpy()[:,3])\n",
    "\n",
    "                if epoch >= 40:\n",
    "                    if (np.abs(loss_ - ref1)/ref1<0.001) & (np.abs(loss_ - ref2)/ref2<0.001):\n",
    "                        print(\"Early stopping at epoch\", epoch)\n",
    "                        converged = 1\n",
    "                        break\n",
    "                    if (ref1 < loss_) & (ref1 < ref2):\n",
    "                        print(\"Diverging. stop.\")\n",
    "                        break\n",
    "                    if loss_ < best:\n",
    "                        best = loss_\n",
    "                        best_epoch = epoch\n",
    "                        output = (best_epoch, train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                else:\n",
    "                    best = loss_\n",
    "                    best_epoch = epoch\n",
    "                    output = (best_epoch, train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                ref2 = ref1\n",
    "                ref1 = loss_\n",
    "\n",
    "        if epoch % 300 == 0:\n",
    "\n",
    "                print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} RMSE {train_mse:.3f}\")\n",
    "                   # {train_mse1:.3f} {train_mse2:.3f} {train_mse3:.3f} {train_mse4:.3f}\")\n",
    "                print(f\"\\t\\t\\t\\t\\t\\t Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "                print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} RMSE {np.sqrt(mse_/len(testset)):.3f}\")\n",
    "                   #     {np.sqrt(mse1_/len(testset)):.3f} {np.sqrt(mse2_/len(testset)):.3f} {np.sqrt(mse3_/len(testset)):.3f} {np.sqrt(mse4_/len(testset)):.3f}\")\n",
    "                print(f\"\\t\\t\\t\\t\\t\\t Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "                print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "                print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "        with open(out_dir+\"AllModels_A_MNL.csv\", \"a\") as f:\n",
    "            f.write(\"%s,%.1E,%.1E,%d,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%d\\n\" % \n",
    "                    (('SSD',lr,wd)+output+(converged,)))\n",
    "\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Train KL loss: {output[1]:.3f} Train R2 score: {output[13]:.3f} {output[14]:.3f} {output[15]:.3f} {output[16]:.3f} \")\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Test KL loss: {output[7]:.3f} Test R2 score: {output[17]:.3f} {output[18]:.3f} {output[19]:.3f} {output[20]:.3f} \")\n",
    "        print()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 0.010, wd: 0.00e+00]\n",
      "Early stopping at epoch 795\n",
      "[epoch: 790] Train KL loss: 0.153 Train R2 score: 0.398 0.512 0.002 0.411 \n",
      "[epoch: 790] Test KL loss: 0.129 Test R2 score: 0.429 0.555 -0.094 0.456 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-07]\n",
      "Early stopping at epoch 785\n",
      "[epoch: 780] Train KL loss: 0.152 Train R2 score: 0.402 0.512 0.003 0.410 \n",
      "[epoch: 780] Test KL loss: 0.129 Test R2 score: 0.434 0.557 -0.093 0.454 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-06]\n",
      "Early stopping at epoch 710\n",
      "[epoch: 705] Train KL loss: 0.152 Train R2 score: 0.405 0.515 0.001 0.417 \n",
      "[epoch: 705] Test KL loss: 0.128 Test R2 score: 0.435 0.558 -0.097 0.462 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-05]\n",
      "Early stopping at epoch 900\n",
      "[epoch: 900] Train KL loss: 0.152 RMSE 0.228\n",
      "\t\t\t\t\t\t Train R2 score: 0.405 0.516 0.003 0.405 \n",
      "[epoch: 900] Test KL loss: 0.129 RMSE 0.207\n",
      "\t\t\t\t\t\t Test R2 score: 0.433 0.562 -0.088 0.447 \n",
      "[epoch: 900] Train KL loss: 0.152 Train R2 score: 0.405 0.516 0.003 0.405 \n",
      "[epoch: 900] Test KL loss: 0.129 Test R2 score: 0.433 0.562 -0.088 0.447 \n",
      "[epoch: 895] Train KL loss: 0.152 Train R2 score: 0.404 0.516 0.003 0.405 \n",
      "[epoch: 895] Test KL loss: 0.129 Test R2 score: 0.433 0.562 -0.088 0.446 \n",
      "\n",
      "[lr: 0.010, wd: 0.00e+00]\n",
      "Early stopping at epoch 580\n",
      "[epoch: 575] Train KL loss: 0.151 Train R2 score: 0.406 0.516 0.002 0.423 \n",
      "[epoch: 575] Test KL loss: 0.127 Test R2 score: 0.438 0.563 -0.095 0.476 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-07]\n",
      "Early stopping at epoch 680\n",
      "[epoch: 675] Train KL loss: 0.153 Train R2 score: 0.396 0.508 0.003 0.418 \n",
      "[epoch: 675] Test KL loss: 0.129 Test R2 score: 0.432 0.553 -0.095 0.464 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-06]\n",
      "Early stopping at epoch 750\n",
      "[epoch: 745] Train KL loss: 0.152 Train R2 score: 0.404 0.514 0.002 0.414 \n",
      "[epoch: 745] Test KL loss: 0.128 Test R2 score: 0.435 0.559 -0.100 0.463 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-05]\n",
      "Early stopping at epoch 715\n",
      "[epoch: 710] Train KL loss: 0.149 Train R2 score: 0.430 0.532 0.002 0.409 \n",
      "[epoch: 710] Test KL loss: 0.126 Test R2 score: 0.448 0.575 -0.085 0.451 \n",
      "\n",
      "[lr: 0.010, wd: 0.00e+00]\n",
      "Early stopping at epoch 840\n",
      "[epoch: 835] Train KL loss: 0.151 Train R2 score: 0.419 0.523 0.002 0.403 \n",
      "[epoch: 835] Test KL loss: 0.128 Test R2 score: 0.439 0.565 -0.088 0.446 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-07]\n",
      "Early stopping at epoch 920\n",
      "[epoch: 915] Train KL loss: 0.151 Train R2 score: 0.418 0.523 0.001 0.397 \n",
      "[epoch: 915] Test KL loss: 0.128 Test R2 score: 0.439 0.565 -0.087 0.433 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-06]\n",
      "Early stopping at epoch 680\n",
      "[epoch: 675] Train KL loss: 0.153 Train R2 score: 0.400 0.510 0.002 0.425 \n",
      "[epoch: 675] Test KL loss: 0.129 Test R2 score: 0.435 0.558 -0.090 0.478 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-05]\n",
      "Early stopping at epoch 615\n",
      "[epoch: 610] Train KL loss: 0.153 Train R2 score: 0.398 0.508 0.001 0.420 \n",
      "[epoch: 610] Test KL loss: 0.129 Test R2 score: 0.435 0.555 -0.091 0.469 \n",
      "\n",
      "[lr: 0.010, wd: 0.00e+00]\n",
      "Early stopping at epoch 860\n",
      "[epoch: 855] Train KL loss: 0.151 Train R2 score: 0.413 0.520 -0.000 0.406 \n",
      "[epoch: 855] Test KL loss: 0.128 Test R2 score: 0.437 0.560 -0.092 0.445 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-07]\n",
      "Early stopping at epoch 625\n",
      "[epoch: 620] Train KL loss: 0.151 Train R2 score: 0.406 0.516 -0.000 0.424 \n",
      "[epoch: 620] Test KL loss: 0.127 Test R2 score: 0.440 0.561 -0.106 0.473 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-06]\n",
      "Early stopping at epoch 750\n",
      "[epoch: 745] Train KL loss: 0.152 Train R2 score: 0.404 0.515 0.003 0.413 \n",
      "[epoch: 745] Test KL loss: 0.128 Test R2 score: 0.435 0.561 -0.092 0.456 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-05]\n",
      "Early stopping at epoch 765\n",
      "[epoch: 760] Train KL loss: 0.151 Train R2 score: 0.411 0.520 0.003 0.410 \n",
      "[epoch: 760] Test KL loss: 0.128 Test R2 score: 0.437 0.564 -0.087 0.454 \n",
      "\n",
      "[lr: 0.010, wd: 0.00e+00]\n",
      "Early stopping at epoch 770\n",
      "[epoch: 765] Train KL loss: 0.150 Train R2 score: 0.422 0.526 0.002 0.410 \n",
      "[epoch: 765] Test KL loss: 0.127 Test R2 score: 0.444 0.568 -0.089 0.448 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-07]\n",
      "Early stopping at epoch 750\n",
      "[epoch: 745] Train KL loss: 0.153 Train R2 score: 0.397 0.507 -0.000 0.420 \n",
      "[epoch: 745] Test KL loss: 0.130 Test R2 score: 0.431 0.549 -0.108 0.467 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-06]\n",
      "Early stopping at epoch 625\n",
      "[epoch: 620] Train KL loss: 0.153 Train R2 score: 0.397 0.511 0.002 0.422 \n",
      "[epoch: 620] Test KL loss: 0.129 Test R2 score: 0.431 0.556 -0.094 0.471 \n",
      "\n",
      "[lr: 0.010, wd: 1.00e-05]\n",
      "Early stopping at epoch 690\n",
      "[epoch: 685] Train KL loss: 0.153 Train R2 score: 0.400 0.510 0.001 0.415 \n",
      "[epoch: 685] Test KL loss: 0.129 Test R2 score: 0.435 0.556 -0.090 0.456 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    mnl_torch(lr_list=[0.01], wd_list=[0, 1e-7, 1e-6, 1e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qingyi",
   "language": "python",
   "name": "qingyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
