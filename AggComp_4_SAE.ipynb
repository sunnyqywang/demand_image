{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, GroupKFold\n",
    "import statsmodels.api as sm\n",
    "from exp_version import get_hp_from_version_code\n",
    "\n",
    "\n",
    "from dataloader import SurveyDataset, load_aggregate_travel_behavior, load_demo_v1\n",
    "from M1_util_train_test import load_model, test\n",
    "import linear_reg\n",
    "import mnl\n",
    "from setup import out_dir, data_dir, image_dir, model_dir, proj_dir\n",
    "\n",
    "plt.rcParams.update({\"font.size\":12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = '1571'\n",
    "\n",
    "model_type = 'AE'\n",
    "sampling = 's'\n",
    "\n",
    "zoomlevel = 'zoom15'\n",
    "\n",
    "variable_names = ['active','auto','mas','pt', 'trpgen']\n",
    "\n",
    "demo_variables = ['tot_population','pct25_34yrs','pct35_50yrs','pctover65yrs',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pct_col_grad','avg_tt_to_work','inc_per_capita']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(proj_dir+\"latent_space/2023-06-30T01-32-58_sae_3_0.9_ep88.pkl\", \"rb\") as f:\n",
    "    encoder_output = pkl.load(f)\n",
    "    im = pkl.load(f)\n",
    "    ct = pkl.load(f)\n",
    "    sup_true_list = pkl.load(f)\n",
    "    sup_list = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Embeddings\n",
    "unique_ct = list(set(ct))\n",
    "unique_ct.sort()\n",
    "ct = np.array(ct)\n",
    "aggregate_embeddings = []\n",
    "for i in unique_ct:\n",
    "#     aggregate_embeddings.append(np.mean(sup_list[ct == i], axis=0))\n",
    "    aggregate_embeddings.append(np.mean(encoder_output[ct == i], axis=0))\n",
    "aggregate_embeddings = np.array(aggregate_embeddings)\n",
    "\n",
    "x = aggregate_embeddings\n",
    "\n",
    "x = x.reshape(x.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trip Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"MyDailyTravel/origin_trip_behavior.csv\"\n",
    "df_pivot = load_aggregate_travel_behavior(file, data_version)\n",
    "y_ct = df_pivot['geoid'].to_list()\n",
    "y = df_pivot[variable_names].to_numpy()[:,:4]\n",
    "\n",
    "groups = df_pivot['train_test']\n",
    "group_split = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(x) != len(y):\n",
    "    x_mask = [True if c in y_ct else False for c in unique_ct]\n",
    "    x = x[x_mask,:]\n",
    "    unique_ct = list(np.array(unique_ct)[x_mask])\n",
    "    y_mask = [True if c in unique_ct else False for c in y_ct]\n",
    "    y = y[y_mask,:]\n",
    "    y_ct = list(np.array(y_ct)[y_mask])\n",
    "\n",
    "x = x[[y_ct.index(val) for val in unique_ct],:]\n",
    "unique_ct = list(np.array(unique_ct)[np.array([y_ct.index(val) for val in unique_ct])])\n",
    "for xc,yc in zip(unique_ct, y_ct):\n",
    "    assert xc == yc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Auto Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e-01, tolerance: 6.768e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.843e-01, tolerance: 6.596e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.616e-01, tolerance: 6.769e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.166e-01, tolerance: 7.111e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.579e-01, tolerance: 6.760e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 \t Train score: 0.7920 \t Cross val score: 0.6268 \t Nonzero coef: 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e-01, tolerance: 6.768e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.298e-02, tolerance: 6.596e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.831e-02, tolerance: 6.769e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e-01, tolerance: 7.111e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e-02, tolerance: 6.760e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-03 \t Train score: 0.7196 \t Cross val score: 0.6440 \t Nonzero coef: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.380e-03, tolerance: 6.768e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e-02, tolerance: 7.111e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e-02, tolerance: 6.760e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 3.00e-03 \t Train score: 0.6964 \t Cross val score: 0.6430 \t Nonzero coef: 76\n",
      "Parameter: 4.00e-03 \t Train score: 0.6842 \t Cross val score: 0.6429 \t Nonzero coef: 58\n",
      "Parameter: 5.00e-03 \t Train score: 0.6762 \t Cross val score: 0.6407 \t Nonzero coef: 51\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for a in (1e-3)*np.array([1,2,3,4,5]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    cross_results = cross_validate(lasso, x, y[:,y_index], cv=group_split, groups=groups, scoring='r2', return_train_score=True, return_estimator=True)\n",
    "    nz = 0\n",
    "    for m in cross_results['estimator']:\n",
    "        nz += sum(m.coef_ != 0)\n",
    "    nz /= 5\n",
    "    \n",
    "    print(\"Parameter: %.2e \\t Train score: %.4f \\t Cross val score: %.4f \\t Nonzero coef: %d\" % \n",
    "          (a, cross_results['train_score'].mean(), cross_results['test_score'].mean(), nz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_index=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e-02, tolerance: 1.168e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e-02, tolerance: 1.130e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.284e-02, tolerance: 1.210e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.786e-02, tolerance: 1.286e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e-03, tolerance: 1.281e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 \t Train score: 0.5976 \t Cross val score: 0.4791 \t Nonzero coef: 114\n",
      "Parameter: 2.00e-03 \t Train score: 0.5451 \t Cross val score: 0.4820 \t Nonzero coef: 47\n",
      "Parameter: 3.00e-03 \t Train score: 0.5248 \t Cross val score: 0.4786 \t Nonzero coef: 33\n",
      "Parameter: 4.00e-03 \t Train score: 0.5157 \t Cross val score: 0.4766 \t Nonzero coef: 27\n",
      "Parameter: 5.00e-03 \t Train score: 0.5090 \t Cross val score: 0.4745 \t Nonzero coef: 23\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for a in (1e-3)*np.array([1,2,3,4,5]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    cross_results = cross_validate(lasso, x, y[:,y_index], cv=group_split, groups=groups, scoring='r2', return_train_score=True, return_estimator=True)\n",
    "    nz = 0\n",
    "    for m in cross_results['estimator']:\n",
    "        nz += sum(m.coef_ != 0)\n",
    "    nz /= 5\n",
    "    \n",
    "    print(\"Parameter: %.2e \\t Train score: %.4f \\t Cross val score: %.4f \\t Nonzero coef: %d\" % \n",
    "          (a, cross_results['train_score'].mean(), cross_results['test_score'].mean(), nz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e-01, tolerance: 3.383e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.762e-01, tolerance: 3.240e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.474e-01, tolerance: 3.355e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e-01, tolerance: 3.441e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.626e-01, tolerance: 3.289e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 \t Train score: 0.6994 \t Cross val score: 0.5000 \t Nonzero coef: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e-02, tolerance: 3.383e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.941e-03, tolerance: 3.240e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e-02, tolerance: 3.355e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e-02, tolerance: 3.441e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e-02, tolerance: 3.289e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-03 \t Train score: 0.6089 \t Cross val score: 0.5244 \t Nonzero coef: 80\n",
      "Parameter: 3.00e-03 \t Train score: 0.5831 \t Cross val score: 0.5312 \t Nonzero coef: 51\n",
      "Parameter: 4.00e-03 \t Train score: 0.5711 \t Cross val score: 0.5307 \t Nonzero coef: 40\n",
      "Parameter: 5.00e-03 \t Train score: 0.5629 \t Cross val score: 0.5282 \t Nonzero coef: 33\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "for a in (1e-3)*np.array([1,2,3,4,5]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    cross_results = cross_validate(lasso, x, y[:,y_index], cv=group_split, groups=groups, scoring='r2', return_train_score=True, return_estimator=True)\n",
    "    nz = 0\n",
    "    for m in cross_results['estimator']:\n",
    "        nz += sum(m.coef_ != 0)\n",
    "    nz /= 5\n",
    "    \n",
    "    print(\"Parameter: %.2e \\t Train score: %.4f \\t Cross val score: %.4f \\t Nonzero coef: %d\" % \n",
    "          (a, cross_results['train_score'].mean(), cross_results['test_score'].mean(), nz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MNL for Mode Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {0:{}, 1:{}, 2:{}, 3:{}, 4:{}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 1.00e-05, wd: 1.00e+02]\n",
      "Early stopping at epoch 3370\n",
      "[epoch: 3360] Train KL loss: 0.088 Train R2 score: 0.764 0.792 0.190 0.687 \n",
      "[epoch: 3360] Test KL loss: 0.140 Test R2 score: 0.494 0.621 -0.052 0.408 \n",
      "\n",
      "[lr: 1.00e-05, wd: 1.00e+02]\n",
      "Early stopping at epoch 3380\n",
      "[epoch: 3370] Train KL loss: 0.082 Train R2 score: 0.783 0.816 0.322 0.704 \n",
      "[epoch: 3370] Test KL loss: 0.124 Test R2 score: 0.478 0.624 -0.056 0.451 \n",
      "\n",
      "[lr: 1.00e-05, wd: 1.00e+02]\n",
      "[epoch: 3980] Train KL loss: 0.086 Train R2 score: 0.761 0.803 0.262 0.707 \n",
      "[epoch: 3980] Test KL loss: 0.115 Test R2 score: 0.627 0.693 -0.131 0.454 \n",
      "\n",
      "[lr: 1.00e-05, wd: 1.00e+02]\n",
      "[epoch: 3990] Train KL loss: 0.075 Train R2 score: 0.808 0.839 0.319 0.767 \n",
      "[epoch: 3990] Test KL loss: 0.143 Test R2 score: 0.417 0.616 -0.066 0.481 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from util_aggregate_models import mnl_torch\n",
    "\n",
    "# dataloader and model definition\n",
    "\n",
    "lr_list = [1e-5]\n",
    "wd_list = [1e+2]\n",
    "\n",
    "for i in range(1,5):\n",
    "    \n",
    "    train_filter = groups != i\n",
    "    test_filter = groups == i\n",
    "    x_train = x[train_filter]\n",
    "    y_train = y[train_filter]\n",
    "    x_test = x[test_filter]\n",
    "    y_test = y[test_filter]\n",
    "    sst_train = np.sum(np.power(y_train - np.mean(y_train, axis=0), 2), axis=0)\n",
    "    sst_test = np.sum(np.power(y_test - np.mean(y_test, axis=0), 2), axis=0)\n",
    "    \n",
    "    trainset = SurveyDataset(torch.tensor(x_train,  dtype=torch.float), torch.tensor(y_train, dtype=torch.float))\n",
    "    trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "\n",
    "    testset = SurveyDataset(torch.tensor(x_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.float))\n",
    "    testloader = DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "    ret_dict = mnl_torch(trainloader, testloader, x_train.shape[-1], sst_train, sst_test, lr_list=lr_list, wd_list=wd_list,\n",
    "                        save_models=False)\n",
    "    \n",
    "    results[i].update(ret_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>train_kl_loss</th>\n",
       "      <th>test_kl_loss</th>\n",
       "      <th>train_r2_auto</th>\n",
       "      <th>train_r2_active</th>\n",
       "      <th>train_r2_pt</th>\n",
       "      <th>test_r2_auto</th>\n",
       "      <th>test_r2_active</th>\n",
       "      <th>test_r2_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.111378</td>\n",
       "      <td>0.127947</td>\n",
       "      <td>0.704159</td>\n",
       "      <td>0.627169</td>\n",
       "      <td>0.568777</td>\n",
       "      <td>0.642882</td>\n",
       "      <td>0.523653</td>\n",
       "      <td>0.475909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.123745</td>\n",
       "      <td>0.129049</td>\n",
       "      <td>0.658470</td>\n",
       "      <td>0.557780</td>\n",
       "      <td>0.516936</td>\n",
       "      <td>0.638284</td>\n",
       "      <td>0.529239</td>\n",
       "      <td>0.487337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.084392</td>\n",
       "      <td>0.130617</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>0.777548</td>\n",
       "      <td>0.708027</td>\n",
       "      <td>0.636118</td>\n",
       "      <td>0.499475</td>\n",
       "      <td>0.454408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.131610</td>\n",
       "      <td>0.803154</td>\n",
       "      <td>0.771443</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>0.633428</td>\n",
       "      <td>0.501606</td>\n",
       "      <td>0.439067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080918</td>\n",
       "      <td>0.132927</td>\n",
       "      <td>0.811473</td>\n",
       "      <td>0.785807</td>\n",
       "      <td>0.729977</td>\n",
       "      <td>0.632071</td>\n",
       "      <td>0.486227</td>\n",
       "      <td>0.442502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  weight_decay  train_kl_loss  test_kl_loss  train_r2_auto  \\\n",
       "1        0.00001        1000.0       0.111378      0.127947       0.704159   \n",
       "0        0.00001       10000.0       0.123745      0.129049       0.658470   \n",
       "2        0.00001         100.0       0.084392      0.130617       0.807652   \n",
       "3        0.00001          10.0       0.083860      0.131610       0.803154   \n",
       "4        0.00001           1.0       0.080918      0.132927       0.811473   \n",
       "\n",
       "   train_r2_active  train_r2_pt  test_r2_auto  test_r2_active  test_r2_pt  \n",
       "1         0.627169     0.568777      0.642882        0.523653    0.475909  \n",
       "0         0.557780     0.516936      0.638284        0.529239    0.487337  \n",
       "2         0.777548     0.708027      0.636118        0.499475    0.454408  \n",
       "3         0.771443     0.738307      0.633428        0.501606    0.439067  \n",
       "4         0.785807     0.729977      0.632071        0.486227    0.442502  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "\n",
    "lr_list = [1e-5]\n",
    "wd_list = [1e+4, 1e+3, 100, 10, 1]\n",
    "\n",
    "for (lr, wd) in itertools.product(lr_list, wd_list):\n",
    "\n",
    "    new = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        new2 = []\n",
    "        for k,v in results[i][(lr,wd)].items():\n",
    "            if k != 'train_loss' and k != 'test_loss':\n",
    "                new2.append(results[i][(lr,wd)][k]) \n",
    "        new.append(new2)\n",
    "        \n",
    "    new = np.array(new) \n",
    "    \n",
    "    df.append([lr] + [wd] + list(np.mean(new, axis=0)))\n",
    "\n",
    "\n",
    "pd.DataFrame(np.array(df), columns = ['learning_rate','weight_decay','train_kl_loss','test_kl_loss','train_r2_auto','train_r2_active','train_r2_pt',\n",
    "                                     'test_r2_auto','test_r2_active','test_r2_pt']).sort_values(by='test_kl_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-5\n",
    "wd = 10\n",
    "for i in range(5):\n",
    "        plt.plot(results[i][(lr, wd)]['train_loss'], c='black')\n",
    "        plt.plot(results[i][(lr, wd)]['test_loss'], c='red')\n",
    "plt.ylim([0,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>train_kl_loss</th>\n",
       "      <th>test_kl_loss</th>\n",
       "      <th>train_r2_auto</th>\n",
       "      <th>train_r2_active</th>\n",
       "      <th>train_r2_pt</th>\n",
       "      <th>test_r2_auto</th>\n",
       "      <th>test_r2_active</th>\n",
       "      <th>test_r2_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.109315</td>\n",
       "      <td>0.138404</td>\n",
       "      <td>0.712724</td>\n",
       "      <td>0.634471</td>\n",
       "      <td>0.593640</td>\n",
       "      <td>0.597671</td>\n",
       "      <td>0.488158</td>\n",
       "      <td>0.431714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.114054</td>\n",
       "      <td>0.141006</td>\n",
       "      <td>0.703157</td>\n",
       "      <td>0.622583</td>\n",
       "      <td>0.564238</td>\n",
       "      <td>0.624304</td>\n",
       "      <td>0.488380</td>\n",
       "      <td>0.423158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.120864</td>\n",
       "      <td>0.146180</td>\n",
       "      <td>0.685106</td>\n",
       "      <td>0.603797</td>\n",
       "      <td>0.546201</td>\n",
       "      <td>0.588821</td>\n",
       "      <td>0.472254</td>\n",
       "      <td>0.408024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.137119</td>\n",
       "      <td>0.146438</td>\n",
       "      <td>0.626710</td>\n",
       "      <td>0.498668</td>\n",
       "      <td>0.461746</td>\n",
       "      <td>0.585129</td>\n",
       "      <td>0.409555</td>\n",
       "      <td>0.374959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.149035</td>\n",
       "      <td>0.158456</td>\n",
       "      <td>0.590239</td>\n",
       "      <td>0.478582</td>\n",
       "      <td>0.242024</td>\n",
       "      <td>0.547520</td>\n",
       "      <td>0.362860</td>\n",
       "      <td>0.280133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.178673</td>\n",
       "      <td>0.187521</td>\n",
       "      <td>0.534564</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.092533</td>\n",
       "      <td>0.488444</td>\n",
       "      <td>0.388526</td>\n",
       "      <td>-0.523059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.150342</td>\n",
       "      <td>0.200315</td>\n",
       "      <td>0.615386</td>\n",
       "      <td>0.522976</td>\n",
       "      <td>0.361235</td>\n",
       "      <td>0.530836</td>\n",
       "      <td>0.220243</td>\n",
       "      <td>-0.263225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.168119</td>\n",
       "      <td>0.212490</td>\n",
       "      <td>0.563597</td>\n",
       "      <td>0.472240</td>\n",
       "      <td>0.124115</td>\n",
       "      <td>0.432032</td>\n",
       "      <td>0.269858</td>\n",
       "      <td>-0.764150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  weight_decay  train_kl_loss  test_kl_loss  train_r2_auto  \\\n",
       "1         0.0001        0.0100       0.109315      0.138404       0.712724   \n",
       "3         0.0001        0.0001       0.114054      0.141006       0.703157   \n",
       "2         0.0001        0.0010       0.120864      0.146180       0.685106   \n",
       "0         0.0001        0.1000       0.137119      0.146438       0.626710   \n",
       "6         0.0002        0.0010       0.149035      0.158456       0.590239   \n",
       "5         0.0002        0.0100       0.178673      0.187521       0.534564   \n",
       "7         0.0002        0.0001       0.150342      0.200315       0.615386   \n",
       "4         0.0002        0.1000       0.168119      0.212490       0.563597   \n",
       "\n",
       "   train_r2_active  train_r2_pt  test_r2_auto  test_r2_active  test_r2_pt  \n",
       "1         0.634471     0.593640      0.597671        0.488158    0.431714  \n",
       "3         0.622583     0.564238      0.624304        0.488380    0.423158  \n",
       "2         0.603797     0.546201      0.588821        0.472254    0.408024  \n",
       "0         0.498668     0.461746      0.585129        0.409555    0.374959  \n",
       "6         0.478582     0.242024      0.547520        0.362860    0.280133  \n",
       "5         0.170244     0.092533      0.488444        0.388526   -0.523059  \n",
       "7         0.522976     0.361235      0.530836        0.220243   -0.263225  \n",
       "4         0.472240     0.124115      0.432032        0.269858   -0.764150  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "\n",
    "for (lr, wd) in itertools.product(lr_list, wd_list):\n",
    "\n",
    "    new = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        new2 = []\n",
    "        for k,v in results[i][(lr,wd)].items():\n",
    "            new2.append(results[i][(lr,wd)][k]) \n",
    "        new.append(new2)\n",
    "        \n",
    "    new = np.array(new) \n",
    "    \n",
    "    df.append([lr] + [wd] + list(np.mean(new, axis=0)))\n",
    "\n",
    "\n",
    "pd.DataFrame(np.array(df), columns = ['learning_rate','weight_decay','train_kl_loss','test_kl_loss','train_r2_auto','train_r2_active','train_r2_pt',\n",
    "                                     'test_r2_auto','test_r2_active','test_r2_pt']).sort_values(by='test_kl_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qingyi",
   "language": "python",
   "name": "qingyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
