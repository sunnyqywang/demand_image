{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc2bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from setup import *\n",
    "from dataloader import SurveyDataset\n",
    "import mnl\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2f0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = '1571'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cedeaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.read_csv(data_dir+\"trips.csv\")\n",
    "n_alts = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9133c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.713060\n",
      "1    0.132001\n",
      "4    0.111893\n",
      "3    0.043046\n",
      "Name: mode, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(tp['mode'].value_counts()/len(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521995a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp['morning'] = (tp['dep_hour'] > 6) & (tp['dep_hour'] < 10)\n",
    "tp['afternoon'] = (tp['dep_hour'] > 15) & (tp['dep_hour'] < 19)\n",
    "tp['morning'] = tp['morning'].astype(int)\n",
    "tp['afternoon'] = tp['afternoon'].astype(int)\n",
    "\n",
    "def normalize_features(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = df[c]/df[c].max()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9301b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60edc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_filter = pd.read_csv(data_dir+\"census_tracts_filtered-\"+data_version+\".csv\")\n",
    "unique_ct = ct_filter['geoid'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e1aaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0aa0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_filter = []\n",
    "for t1, t2 in zip(tp['tract_1'], tp['tract_2']):\n",
    "    if sum(unique_ct == t1) == 1 and sum(unique_ct == t2) == 1:\n",
    "        trip_filter.append(True)\n",
    "    else:\n",
    "        trip_filter.append(False)\n",
    "trip_filter = np.array(trip_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0cbadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tp[['const','morning','afternoon','companion', 'distance', \n",
    "         'from_home', 'to_home', 'purp_work', 'purp_school', 'purp_errand', 'purp_recreation', \n",
    "         'ontime_important', '12_18yrs', '18_25yrs', '25_55yrs', '55+yrs', \n",
    "         'disability', 'educ_col', 'educ_grad', \n",
    "         'race_white', 'race_black', 'race_asian', \n",
    "         'male', 'female', \n",
    "         'emply_park', 'emply_transit', 'emply_veh', 'emply_wfh', 'emply_flex', 'emply_hours', \n",
    "         'license', 'person_trips', 'person_transit', 'person_freq_transit', \n",
    "         'hh_inc_0_30', 'hh_inc_30_60', 'hh_inc_60_100', 'hh_inc_100_150', 'hh_inc_150', \n",
    "         'avg_pr_veh', 'home_own', 'home_house', 'home_condo']].to_numpy()[trip_filter]\n",
    "\n",
    "y = tp['mode'].astype(int).to_numpy()[trip_filter] - 1\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ef1e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79929, 43)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "267ed279",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SurveyDataset(torch.tensor(x_train, dtype=torch.float), torch.tensor(y_train, dtype=torch.long))\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "testset = SurveyDataset(torch.tensor(x_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.long))\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b4c4444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   0] Train loss: 0.9441 accuracy: 0.673\n",
      "[epoch:   0] Test loss: 0.5756 accuracy: 0.789\n",
      "[epoch:   1] Train loss: 0.5413 accuracy: 0.808\n",
      "[epoch:   1] Test loss: 0.5104 accuracy: 0.824\n",
      "[epoch:   2] Train loss: 0.4991 accuracy: 0.825\n",
      "[epoch:   2] Test loss: 0.4840 accuracy: 0.829\n",
      "[epoch:   3] Train loss: 0.4802 accuracy: 0.833\n",
      "[epoch:   3] Test loss: 0.4717 accuracy: 0.833\n",
      "[epoch:   4] Train loss: 0.4710 accuracy: 0.835\n",
      "[epoch:   4] Test loss: 0.4656 accuracy: 0.835\n",
      "[epoch:   5] Train loss: 0.4653 accuracy: 0.838\n",
      "[epoch:   5] Test loss: 0.4632 accuracy: 0.836\n",
      "[epoch:   6] Train loss: 0.4622 accuracy: 0.840\n",
      "[epoch:   6] Test loss: 0.4601 accuracy: 0.839\n",
      "[epoch:   7] Train loss: 0.4605 accuracy: 0.841\n",
      "[epoch:   7] Test loss: 0.4594 accuracy: 0.841\n",
      "[epoch:   8] Train loss: 0.4589 accuracy: 0.842\n",
      "[epoch:   8] Test loss: 0.4577 accuracy: 0.841\n",
      "[epoch:   9] Train loss: 0.4579 accuracy: 0.843\n",
      "[epoch:   9] Test loss: 0.4568 accuracy: 0.842\n",
      "[epoch:  10] Train loss: 0.4577 accuracy: 0.844\n",
      "[epoch:  10] Test loss: 0.4562 accuracy: 0.841\n",
      "[epoch:  11] Train loss: 0.4570 accuracy: 0.844\n",
      "[epoch:  11] Test loss: 0.4557 accuracy: 0.843\n",
      "[epoch:  12] Train loss: 0.4568 accuracy: 0.844\n",
      "[epoch:  12] Test loss: 0.4556 accuracy: 0.845\n",
      "[epoch:  13] Train loss: 0.4564 accuracy: 0.845\n",
      "[epoch:  13] Test loss: 0.4560 accuracy: 0.844\n",
      "[epoch:  14] Train loss: 0.4564 accuracy: 0.845\n",
      "[epoch:  14] Test loss: 0.4558 accuracy: 0.842\n",
      "[epoch:  15] Train loss: 0.4569 accuracy: 0.845\n",
      "[epoch:  15] Test loss: 0.4553 accuracy: 0.844\n",
      "[epoch:  16] Train loss: 0.4560 accuracy: 0.845\n",
      "[epoch:  16] Test loss: 0.4554 accuracy: 0.844\n",
      "[epoch:  17] Train loss: 0.4563 accuracy: 0.845\n",
      "[epoch:  17] Test loss: 0.4551 accuracy: 0.844\n",
      "[epoch:  18] Train loss: 0.4565 accuracy: 0.845\n",
      "[epoch:  18] Test loss: 0.4552 accuracy: 0.844\n",
      "[epoch:  19] Train loss: 0.4562 accuracy: 0.845\n",
      "[epoch:  19] Test loss: 0.4572 accuracy: 0.842\n",
      "[epoch:  20] Train loss: 0.4560 accuracy: 0.845\n",
      "[epoch:  20] Test loss: 0.4571 accuracy: 0.847\n",
      "[epoch:  21] Train loss: 0.4562 accuracy: 0.845\n",
      "[epoch:  21] Test loss: 0.4564 accuracy: 0.844\n",
      "[epoch:  22] Train loss: 0.4559 accuracy: 0.846\n",
      "[epoch:  22] Test loss: 0.4547 accuracy: 0.845\n",
      "[epoch:  23] Train loss: 0.4557 accuracy: 0.845\n",
      "[epoch:  23] Test loss: 0.4547 accuracy: 0.845\n",
      "[epoch:  24] Train loss: 0.4558 accuracy: 0.845\n",
      "[epoch:  24] Test loss: 0.4555 accuracy: 0.846\n",
      "[epoch:  25] Train loss: 0.4557 accuracy: 0.846\n",
      "[epoch:  25] Test loss: 0.4548 accuracy: 0.844\n",
      "[epoch:  26] Train loss: 0.4558 accuracy: 0.846\n",
      "[epoch:  26] Test loss: 0.4556 accuracy: 0.847\n",
      "[epoch:  27] Train loss: 0.4557 accuracy: 0.845\n",
      "[epoch:  27] Test loss: 0.4550 accuracy: 0.846\n",
      "[epoch:  28] Train loss: 0.4558 accuracy: 0.846\n",
      "[epoch:  28] Test loss: 0.4578 accuracy: 0.846\n",
      "[epoch:  29] Train loss: 0.4557 accuracy: 0.846\n",
      "[epoch:  29] Test loss: 0.4553 accuracy: 0.844\n",
      "[epoch:  30] Train loss: 0.4559 accuracy: 0.845\n",
      "[epoch:  30] Test loss: 0.4578 accuracy: 0.843\n",
      "[epoch:  31] Train loss: 0.4561 accuracy: 0.845\n",
      "[epoch:  31] Test loss: 0.4571 accuracy: 0.844\n",
      "[epoch:  32] Train loss: 0.4555 accuracy: 0.846\n",
      "[epoch:  32] Test loss: 0.4547 accuracy: 0.845\n",
      "[epoch:  33] Train loss: 0.4559 accuracy: 0.845\n",
      "[epoch:  33] Test loss: 0.4570 accuracy: 0.845\n",
      "[epoch:  34] Train loss: 0.4556 accuracy: 0.846\n",
      "[epoch:  34] Test loss: 0.4546 accuracy: 0.844\n",
      "[epoch:  35] Train loss: 0.4559 accuracy: 0.845\n",
      "[epoch:  35] Test loss: 0.4558 accuracy: 0.847\n",
      "[epoch:  36] Train loss: 0.4554 accuracy: 0.846\n",
      "[epoch:  36] Test loss: 0.4546 accuracy: 0.845\n",
      "[epoch:  37] Train loss: 0.4558 accuracy: 0.845\n",
      "[epoch:  37] Test loss: 0.4544 accuracy: 0.845\n",
      "[epoch:  38] Train loss: 0.4554 accuracy: 0.846\n",
      "[epoch:  38] Test loss: 0.4558 accuracy: 0.844\n",
      "[epoch:  39] Train loss: 0.4555 accuracy: 0.846\n",
      "[epoch:  39] Test loss: 0.4562 accuracy: 0.847\n",
      "[epoch:  40] Train loss: 0.4556 accuracy: 0.846\n",
      "[epoch:  40] Test loss: 0.4540 accuracy: 0.846\n",
      "[epoch:  41] Train loss: 0.4559 accuracy: 0.846\n",
      "[epoch:  41] Test loss: 0.4545 accuracy: 0.845\n",
      "[epoch:  42] Train loss: 0.4554 accuracy: 0.846\n",
      "[epoch:  42] Test loss: 0.4548 accuracy: 0.844\n",
      "[epoch:  43] Train loss: 0.4560 accuracy: 0.845\n",
      "[epoch:  43] Test loss: 0.4552 accuracy: 0.846\n",
      "[epoch:  44] Train loss: 0.4554 accuracy: 0.846\n",
      "[epoch:  44] Test loss: 0.4543 accuracy: 0.846\n",
      "[epoch:  45] Train loss: 0.4558 accuracy: 0.846\n",
      "[epoch:  45] Test loss: 0.4568 accuracy: 0.844\n",
      "[epoch:  46] Train loss: 0.4558 accuracy: 0.846\n",
      "[epoch:  46] Test loss: 0.4632 accuracy: 0.842\n",
      "[epoch:  47] Train loss: 0.4556 accuracy: 0.846\n",
      "[epoch:  47] Test loss: 0.4548 accuracy: 0.845\n",
      "[epoch:  48] Train loss: 0.4555 accuracy: 0.846\n",
      "[epoch:  48] Test loss: 0.4544 accuracy: 0.845\n",
      "[epoch:  49] Train loss: 0.4557 accuracy: 0.846\n",
      "[epoch:  49] Test loss: 0.4544 accuracy: 0.844\n",
      "[epoch:  50] Train loss: 0.4557 accuracy: 0.846\n",
      "[epoch:  50] Test loss: 0.4551 accuracy: 0.845\n",
      "[epoch:  51] Train loss: 0.4558 accuracy: 0.846\n",
      "[epoch:  51] Test loss: 0.4563 accuracy: 0.846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-93c1532993f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = mnl.MNL(n_alts=n_alts, n_features=x.shape[-1])\n",
    "# model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=0)\n",
    "\n",
    "for epoch in range(300):\n",
    "    loss_ = 0\n",
    "    correct = 0\n",
    "    for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "        # Compute prediction and loss\n",
    "        util = model(x_batch)\n",
    "        loss = loss_fn(util, y_batch)\n",
    "        loss_ += loss.item()*len(y_batch)\n",
    "        \n",
    "        pred = torch.argmax(util, dim=1)\n",
    "        correct += torch.sum(pred == y_batch)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    if batch % 1 == 0:\n",
    "        print(f\"[epoch: {epoch:>3d}] Train loss: {loss_/len(trainset):.4f} accuracy: {correct/len(trainset):.3f}\")\n",
    "\n",
    "    correct = 0\n",
    "    loss_ = 0\n",
    "    for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "        util = model(x_batch)\n",
    "        loss = loss_fn(util, y_batch)\n",
    "        loss_ += loss.item()*len(y_batch)\n",
    "        pred = torch.argmax(util, dim=1)\n",
    "        correct += torch.sum(pred == y_batch)\n",
    "        \n",
    "    print(f\"[epoch: {epoch:>3d}] Test loss: {loss_/len(testset):.4f} accuracy: {correct/len(testset):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b058333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('beta.weight', Parameter containing:\n",
      "tensor([[ 0.6929, -0.0772,  0.2061, -0.2254, -1.0756, -0.0244,  0.0143,  0.2920,\n",
      "          0.1733, -0.0782,  0.3137, -0.2152, -0.0182,  0.4557,  0.4485,  0.7052,\n",
      "         -0.4744,  0.4495,  0.6261,  0.0923, -0.1780, -0.1531,  0.6451,  0.4286,\n",
      "         -0.3748,  0.3883, -0.2609, -0.1072,  0.0201,  0.0325, -0.2460, -0.0481,\n",
      "          0.1830, -0.2823,  0.3767,  0.2456,  0.3425,  0.3894,  0.4302, -0.8925,\n",
      "         -0.1659, -0.1228,  0.5170],\n",
      "        [-0.1174, -0.0136,  0.2340,  0.1317,  0.1220,  0.1956,  0.1850, -0.2740,\n",
      "         -0.6176,  0.4992,  0.0923, -0.0575, -0.3498, -0.6777, -0.0824, -0.0828,\n",
      "          0.0055, -0.3137, -0.2230,  0.0249,  0.0121,  0.0798, -0.1605, -0.1104,\n",
      "          0.5252, -0.6962,  0.0268, -0.1031, -0.1024,  0.0357,  1.0361,  0.0590,\n",
      "          0.0463, -1.3601, -0.2623,  0.0927, -0.0218, -0.0544, -0.0733,  0.6779,\n",
      "          0.2806,  0.3052, -0.3107],\n",
      "        [-0.0145, -0.2400, -0.5547,  0.1484,  0.1102, -0.3981, -0.3256, -0.3834,\n",
      "          0.2659, -0.9287, -0.2075, -0.0029,  1.2477,  0.2245, -0.0915, -0.2246,\n",
      "          0.4122,  0.0803, -0.0184,  0.0083,  0.0957,  0.3335, -0.1558,  0.0169,\n",
      "         -0.2528,  0.1268,  0.2673, -0.1649, -0.0073,  0.0549, -0.5725, -0.0211,\n",
      "          0.2068, -0.2225, -0.2088, -0.1138, -0.0348, -0.1124, -0.0957, -0.4366,\n",
      "         -0.2000, -0.3918, -0.1460],\n",
      "        [ 0.2834,  0.3940,  0.7527, -0.4965,  0.1667,  0.2256,  0.2877,  0.4330,\n",
      "          0.3362,  0.0145,  0.0159,  0.1783, -1.3467,  0.1577,  0.2500,  0.5489,\n",
      "          0.1118,  0.2266,  0.2705,  0.0186,  0.4101,  0.2925,  0.1440,  0.0555,\n",
      "         -0.6950,  0.7074, -0.3070,  0.0479,  0.1267,  0.0302, -0.7244, -0.1653,\n",
      "         -0.3816,  1.6923,  0.4498,  0.0513, -0.0038,  0.0501,  0.1356, -1.0098,\n",
      "         -0.2445, -0.2137,  0.3518]], requires_grad=True))\n",
      "('beta.bias', Parameter containing:\n",
      "tensor([ 0.8355, -0.3849, -0.1316,  0.2199], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5f4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
