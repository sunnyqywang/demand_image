{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from exp_version import get_hp_from_version_code\n",
    "\n",
    "\n",
    "from dataloader import SurveyDataset, load_aggregate_travel_behavior, load_demo\n",
    "from M1_util_train_test import load_model, test\n",
    "import linear_reg\n",
    "import mnl\n",
    "from setup import out_dir, data_dir, image_dir, model_dir, proj_dir\n",
    "\n",
    "plt.rcParams.update({\"font.size\":12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomlevel = 'zoom15'\n",
    "latent_dim = 100\n",
    "demo_dim = 7\n",
    "demo_cols = [0,1,2,3,4,8,9]\n",
    "demo_names = ['tot_population','pct25_34yrs','pct35_50yrs','pctover65yrs',\n",
    "             'pctwhite_alone','avg_tt_to_work','inc_per_capita']\n",
    "# demo_cols = [0,9]\n",
    "image_size = str(64)\n",
    "im_norm = '2'\n",
    "model_run_date = \"2210gan-7\"\n",
    "model_type = 'dcgan'\n",
    "loss_func = 'mse'\n",
    "model_class = 'gan'\n",
    "base_lr = '0.0002'\n",
    "weight_decay = '0'\n",
    "sampling = 'clustered'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(proj_dir+\"latent_space/cGAN_\"+zoomlevel+\"_\"+str(latent_dim+demo_dim)+\"_\"+model_run_date+\"_9.pkl\", \"rb\") as f: \n",
    "    \n",
    "    intermediate_layers_original_train = pkl.load(f)\n",
    "    intermediate_layers_generated_train = pkl.load(f)\n",
    "    intermediate_layers_original_test = pkl.load(f)\n",
    "    intermediate_layers_generated_test = pkl.load(f)\n",
    "    train_ct = pkl.load(f)\n",
    "    test_ct = pkl.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trip Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"origin_trip_behavior.csv\"\n",
    "df_pivot = load_aggregate_travel_behavior(file, data_version='1571')\n",
    "\n",
    "train_test_index = df_pivot['train_test'].astype(bool).to_numpy()\n",
    "variable_names = ['active','auto','mas','pt', 'trpgen']\n",
    "\n",
    "y = df_pivot[variable_names].to_numpy()\n",
    "y_train = y[~train_test_index,:4]\n",
    "y_test = y[train_test_index,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train = y[~train_test_index,1]\n",
    "auto_test = y[train_test_index,1]\n",
    "\n",
    "pt_train = y[~train_test_index,3]\n",
    "pt_test = y[train_test_index,3]\n",
    "\n",
    "active_train = y[~train_test_index,0]\n",
    "active_test = y[train_test_index,0]\n",
    "\n",
    "trpgen_train = y[~train_test_index,-1]\n",
    "trpgen_test = y[train_test_index,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_ct)\n",
    "num_test = len(test_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Auto Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-8a702679c8de>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -1.4997 \t Nonzero coef: 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-05 Train R2: 0.9222 \t Test R: -1.5619 \t Nonzero coef: 1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-04 Train R2: 0.7777 \t Test R: -1.1573 \t Nonzero coef: 849\n",
      "Parameter: 1.50e-04 Train R2: 0.6244 \t Test R: -0.7210 \t Nonzero coef: 643\n",
      "Parameter: 2.00e-04 Train R2: 0.4960 \t Test R: -0.4473 \t Nonzero coef: 510\n",
      "Parameter: 2.50e-04 Train R2: 0.3953 \t Test R: -0.2932 \t Nonzero coef: 378\n",
      "Parameter: 3.00e-04 Train R2: 0.3183 \t Test R: -0.2197 \t Nonzero coef: 296\n",
      "Parameter: 3.50e-04 Train R2: 0.2582 \t Test R: -0.1721 \t Nonzero coef: 213\n",
      "Parameter: 4.00e-04 Train R2: 0.2097 \t Test R: -0.1278 \t Nonzero coef: 182\n",
      "Parameter: 5.00e-04 Train R2: 0.1303 \t Test R: -0.0820 \t Nonzero coef: 108\n",
      "Parameter: 1.00e-03 Train R2: 0.0075 \t Test R: -0.0047 \t Nonzero coef: 3\n",
      "Layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-8a702679c8de>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -2.7378 \t Nonzero coef: 32768\n",
      "Parameter: 5.00e-04 Train R2: 0.4031 \t Test R: -0.3271 \t Nonzero coef: 408\n",
      "Parameter: 1.00e-03 Train R2: 0.1639 \t Test R: -0.0906 \t Nonzero coef: 132\n",
      "Parameter: 1.50e-03 Train R2: 0.0765 \t Test R: -0.0401 \t Nonzero coef: 54\n",
      "Parameter: 2.00e-03 Train R2: 0.0347 \t Test R: -0.0131 \t Nonzero coef: 20\n",
      "Parameter: 2.50e-03 Train R2: 0.0128 \t Test R: -0.0029 \t Nonzero coef: 7\n",
      "Parameter: 3.00e-03 Train R2: 0.0016 \t Test R: -0.0024 \t Nonzero coef: 1\n",
      "Parameter: 3.50e-03 Train R2: -0.0000 \t Test R: -0.0029 \t Nonzero coef: 0\n",
      "Parameter: 4.00e-03 Train R2: -0.0000 \t Test R: -0.0029 \t Nonzero coef: 0\n",
      "Parameter: 5.00e-03 Train R2: -0.0000 \t Test R: -0.0029 \t Nonzero coef: 0\n",
      "Parameter: 1.00e-02 Train R2: -0.0000 \t Test R: -0.0029 \t Nonzero coef: 0\n",
      "Layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-8a702679c8de>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -2.1607 \t Nonzero coef: 16384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.662e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-04 Train R2: 0.8540 \t Test R: -2.0741 \t Nonzero coef: 988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.793e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 Train R2: 0.6418 \t Test R: -1.3659 \t Nonzero coef: 704\n",
      "Parameter: 1.50e-03 Train R2: 0.4720 \t Test R: -0.9029 \t Nonzero coef: 494\n",
      "Parameter: 2.00e-03 Train R2: 0.3493 \t Test R: -0.6608 \t Nonzero coef: 339\n",
      "Parameter: 2.50e-03 Train R2: 0.2630 \t Test R: -0.4658 \t Nonzero coef: 247\n",
      "Parameter: 3.00e-03 Train R2: 0.1969 \t Test R: -0.3278 \t Nonzero coef: 178\n",
      "Parameter: 3.50e-03 Train R2: 0.1474 \t Test R: -0.2515 \t Nonzero coef: 136\n",
      "Parameter: 4.00e-03 Train R2: 0.1103 \t Test R: -0.2047 \t Nonzero coef: 103\n",
      "Parameter: 5.00e-03 Train R2: 0.0656 \t Test R: -0.1292 \t Nonzero coef: 54\n",
      "Parameter: 1.00e-02 Train R2: 0.0049 \t Test R: -0.0190 \t Nonzero coef: 7\n",
      "Layer 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-8a702679c8de>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -3.9027 \t Nonzero coef: 8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-04 Train R2: 0.8079 \t Test R: -2.7880 \t Nonzero coef: 925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 Train R2: 0.5875 \t Test R: -1.7799 \t Nonzero coef: 626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.50e-03 Train R2: 0.4363 \t Test R: -1.2233 \t Nonzero coef: 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.787e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-03 Train R2: 0.3292 \t Test R: -0.8528 \t Nonzero coef: 319\n",
      "Parameter: 2.50e-03 Train R2: 0.2541 \t Test R: -0.6105 \t Nonzero coef: 236\n",
      "Parameter: 3.00e-03 Train R2: 0.2019 \t Test R: -0.4477 \t Nonzero coef: 179\n",
      "Parameter: 3.50e-03 Train R2: 0.1624 \t Test R: -0.3385 \t Nonzero coef: 147\n",
      "Parameter: 4.00e-03 Train R2: 0.1313 \t Test R: -0.2521 \t Nonzero coef: 125\n",
      "Parameter: 5.00e-03 Train R2: 0.0839 \t Test R: -0.1283 \t Nonzero coef: 85\n",
      "Parameter: 1.00e-02 Train R2: 0.0138 \t Test R: -0.0078 \t Nonzero coef: 18\n",
      "Layer 4\n",
      "Parameter: 0.00e+00 Train R2: 0.0786 \t Test R: -0.2233 \t Nonzero coef: 107\n",
      "Parameter: 5.00e-04 Train R2: 0.0586 \t Test R: -0.1349 \t Nonzero coef: 58\n",
      "Parameter: 1.00e-03 Train R2: 0.0349 \t Test R: -0.0967 \t Nonzero coef: 32\n",
      "Parameter: 1.50e-03 Train R2: 0.0211 \t Test R: -0.0590 \t Nonzero coef: 22\n",
      "Parameter: 2.00e-03 Train R2: 0.0130 \t Test R: -0.0418 \t Nonzero coef: 8\n",
      "Parameter: 2.50e-03 Train R2: 0.0105 \t Test R: -0.0321 \t Nonzero coef: 6\n",
      "Parameter: 3.00e-03 Train R2: 0.0082 \t Test R: -0.0274 \t Nonzero coef: 6\n",
      "Parameter: 3.50e-03 Train R2: 0.0069 \t Test R: -0.0258 \t Nonzero coef: 4\n",
      "Parameter: 4.00e-03 Train R2: 0.0060 \t Test R: -0.0223 \t Nonzero coef: 4\n",
      "Parameter: 5.00e-03 Train R2: 0.0038 \t Test R: -0.0178 \t Nonzero coef: 4\n",
      "Parameter: 1.00e-02 Train R2: -0.0000 \t Test R: -0.0029 \t Nonzero coef: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-8a702679c8de>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e+01, tolerance: 7.704e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "for i,reg_base in zip(range(5), [5e-4, 5e-3, 5e-3, 5e-3, 5e-3]):\n",
    "    print(\"Layer\", i)\n",
    "    x_train = intermediate_layers_generated_train[i].reshape(num_train, -1)\n",
    "    x_test = intermediate_layers_generated_test[i].reshape(num_test, -1)\n",
    "\n",
    "    # Linear Regression without Regularization\n",
    "    # lr = linear_model.LinearRegression()\n",
    "    # lr.fit(x_train, auto_train)\n",
    "    # with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "    #     f.write(\"%s,%s,%s,%.4f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], -1, \n",
    "    #         lr.score(x_train, auto_train), lr.score(x_test, auto_test), 'lr', zoomlevel,\n",
    "    #         np.sum(lr.coef_ != 0), len(lr.coef_)))\n",
    "    # print(\"Train R2: %.4f \\t Test R2: %.4f\" % (lr.score(x_train, auto_train), lr.score(x_test, auto_test)))\n",
    "\n",
    "    # Lasso\n",
    "    for a in (reg_base)*np.array([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,1,2]):\n",
    "        lasso = linear_model.Lasso(alpha=a)\n",
    "        lasso.fit(x_train, auto_train)\n",
    "        print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % \\\n",
    "              (a, lasso.score(x_train, auto_train), lasso.score(x_test, auto_test), np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    #     with open(out_dir+\"SAE_A_LR.csv\", \"a\") as f:\n",
    "    #         f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (weight,a,'auto',\n",
    "    #             lasso.score(x_train, auto_train), lasso.score(x_test, auto_test), 'lasso', \n",
    "    #             np.sum(lasso.coef_ != 0), len(lasso.coef_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-c77a17228f10>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -1.2211 \t Nonzero coef: 65536\n",
      "Parameter: 1.00e-04 Train R2: 0.9564 \t Test R: -0.4703 \t Nonzero coef: 1186\n",
      "Parameter: 2.00e-04 Train R2: 0.8563 \t Test R: -0.3634 \t Nonzero coef: 940\n",
      "Parameter: 3.00e-04 Train R2: 0.7311 \t Test R: -0.2186 \t Nonzero coef: 769\n",
      "Parameter: 4.00e-04 Train R2: 0.5953 \t Test R: -0.1550 \t Nonzero coef: 617\n",
      "Parameter: 5.00e-04 Train R2: 0.4648 \t Test R: -0.1289 \t Nonzero coef: 461\n",
      "Parameter: 6.00e-04 Train R2: 0.3461 \t Test R: -0.1057 \t Nonzero coef: 321\n",
      "Parameter: 7.00e-04 Train R2: 0.2456 \t Test R: -0.0833 \t Nonzero coef: 217\n",
      "Parameter: 8.00e-04 Train R2: 0.1628 \t Test R: -0.0586 \t Nonzero coef: 145\n",
      "Parameter: 1.00e-03 Train R2: 0.0543 \t Test R: -0.0260 \t Nonzero coef: 60\n",
      "Parameter: 2.00e-03 Train R2: -0.0000 \t Test R: -0.0029 \t Nonzero coef: 0\n",
      "Layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-c77a17228f10>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -1.4282 \t Nonzero coef: 32768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.900e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-04 Train R2: 0.9852 \t Test R: -1.1510 \t Nonzero coef: 1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-04 Train R2: 0.9475 \t Test R: -0.9480 \t Nonzero coef: 1168\n",
      "Parameter: 3.00e-04 Train R2: 0.8960 \t Test R: -0.8153 \t Nonzero coef: 1034\n",
      "Parameter: 4.00e-04 Train R2: 0.8381 \t Test R: -0.7025 \t Nonzero coef: 920\n",
      "Parameter: 5.00e-04 Train R2: 0.7777 \t Test R: -0.5883 \t Nonzero coef: 822\n",
      "Parameter: 6.00e-04 Train R2: 0.7180 \t Test R: -0.5074 \t Nonzero coef: 723\n",
      "Parameter: 7.00e-04 Train R2: 0.6605 \t Test R: -0.4563 \t Nonzero coef: 659\n",
      "Parameter: 8.00e-04 Train R2: 0.6024 \t Test R: -0.4030 \t Nonzero coef: 590\n",
      "Parameter: 1.00e-03 Train R2: 0.4935 \t Test R: -0.3082 \t Nonzero coef: 485\n",
      "Parameter: 2.00e-03 Train R2: 0.1431 \t Test R: -0.0442 \t Nonzero coef: 128\n",
      "Layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-c77a17228f10>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -1.5510 \t Nonzero coef: 16384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.373e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-04 Train R2: 0.9983 \t Test R: -1.7577 \t Nonzero coef: 1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.647e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-04 Train R2: 0.9934 \t Test R: -1.7643 \t Nonzero coef: 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.264e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 3.00e-04 Train R2: 0.9858 \t Test R: -1.7144 \t Nonzero coef: 1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-04 Train R2: 0.9759 \t Test R: -1.6423 \t Nonzero coef: 1253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-04 Train R2: 0.9639 \t Test R: -1.5410 \t Nonzero coef: 1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.587e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-04 Train R2: 0.9501 \t Test R: -1.4953 \t Nonzero coef: 1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.720e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 7.00e-04 Train R2: 0.9349 \t Test R: -1.4608 \t Nonzero coef: 1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 8.00e-04 Train R2: 0.9185 \t Test R: -1.4112 \t Nonzero coef: 1076\n",
      "Parameter: 1.00e-03 Train R2: 0.8828 \t Test R: -1.2811 \t Nonzero coef: 1012\n",
      "Parameter: 2.00e-03 Train R2: 0.6854 \t Test R: -0.7409 \t Nonzero coef: 720\n",
      "Layer 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-c77a17228f10>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 1.0000 \t Test R: -2.9833 \t Nonzero coef: 8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-04 Train R2: 0.9964 \t Test R: -3.6156 \t Nonzero coef: 1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.290e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-04 Train R2: 0.9868 \t Test R: -3.3176 \t Nonzero coef: 1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 3.00e-04 Train R2: 0.9725 \t Test R: -3.0317 \t Nonzero coef: 1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 4.00e-04 Train R2: 0.9544 \t Test R: -2.8536 \t Nonzero coef: 1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.529e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 5.00e-04 Train R2: 0.9339 \t Test R: -2.6984 \t Nonzero coef: 1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.735e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 6.00e-04 Train R2: 0.9116 \t Test R: -2.5380 \t Nonzero coef: 1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.202e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 7.00e-04 Train R2: 0.8877 \t Test R: -2.3911 \t Nonzero coef: 1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.043e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 8.00e-04 Train R2: 0.8629 \t Test R: -2.1919 \t Nonzero coef: 1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 1.00e-03 Train R2: 0.8113 \t Test R: -1.7806 \t Nonzero coef: 927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.407e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "<ipython-input-15-c77a17228f10>:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, auto_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e+01, tolerance: 7.704e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.534e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e+00, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.584e-01, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.591e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 2.00e-03 Train R2: 0.5758 \t Test R: -0.9095 \t Nonzero coef: 571\n",
      "Layer 4\n",
      "Parameter: 0.00e+00 Train R2: 0.0766 \t Test R: -0.4194 \t Nonzero coef: 107\n",
      "Parameter: 1.00e-04 Train R2: 0.0759 \t Test R: -0.3696 \t Nonzero coef: 101\n",
      "Parameter: 2.00e-04 Train R2: 0.0740 \t Test R: -0.3234 \t Nonzero coef: 96\n",
      "Parameter: 3.00e-04 Train R2: 0.0716 \t Test R: -0.2847 \t Nonzero coef: 85\n",
      "Parameter: 4.00e-04 Train R2: 0.0682 \t Test R: -0.2602 \t Nonzero coef: 80\n",
      "Parameter: 5.00e-04 Train R2: 0.0646 \t Test R: -0.2372 \t Nonzero coef: 73\n",
      "Parameter: 6.00e-04 Train R2: 0.0607 \t Test R: -0.2172 \t Nonzero coef: 66\n",
      "Parameter: 7.00e-04 Train R2: 0.0567 \t Test R: -0.1951 \t Nonzero coef: 59\n",
      "Parameter: 8.00e-04 Train R2: 0.0529 \t Test R: -0.1759 \t Nonzero coef: 51\n",
      "Parameter: 1.00e-03 Train R2: 0.0462 \t Test R: -0.1429 \t Nonzero coef: 40\n",
      "Parameter: 2.00e-03 Train R2: 0.0200 \t Test R: -0.0551 \t Nonzero coef: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e-02, tolerance: 7.704e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "for i,reg_base in zip(range(5), [5e-4, 5e-3, 5e-3, 5e-3, 5e-3]):\n",
    "    print(\"Layer\", i)\n",
    "    x_train = intermediate_layers_original_train[i].reshape(num_train, -1)\n",
    "    x_test = intermediate_layers_original_test[i].reshape(num_test, -1)\n",
    "\n",
    "    # Linear Regression without Regularization\n",
    "    # lr = linear_model.LinearRegression()\n",
    "    # lr.fit(x_train, auto_train)\n",
    "    # with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "    #     f.write(\"%s,%s,%s,%.4f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], -1, \n",
    "    #         lr.score(x_train, auto_train), lr.score(x_test, auto_test), 'lr', zoomlevel,\n",
    "    #         np.sum(lr.coef_ != 0), len(lr.coef_)))\n",
    "    # print(\"Train R2: %.4f \\t Test R2: %.4f\" % (lr.score(x_train, auto_train), lr.score(x_test, auto_test)))\n",
    "\n",
    "    # Lasso\n",
    "    for a in (reg_base)*np.array([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,1,2]):\n",
    "        lasso = linear_model.Lasso(alpha=a)\n",
    "        lasso.fit(x_train, auto_train)\n",
    "        print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % \\\n",
    "              (a, lasso.score(x_train, auto_train), lasso.score(x_test, auto_test), np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    #     with open(out_dir+\"SAE_A_LR.csv\", \"a\") as f:\n",
    "    #         f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (weight,a,'auto',\n",
    "    #             lasso.score(x_train, auto_train), lasso.score(x_test, auto_test), 'lasso', \n",
    "    #             np.sum(lasso.coef_ != 0), len(lasso.coef_)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-7120b7093049>:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, pt_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.2512 \t Test R: 0.0327 \t Nonzero coef: 64\n",
      "Parameter: 1.00e-03 Train R2: 0.2016 \t Test R: 0.1087 \t Nonzero coef: 10\n",
      "Parameter: 2.00e-03 Train R2: 0.1796 \t Test R: 0.1045 \t Nonzero coef: 4\n",
      "Parameter: 4.00e-03 Train R2: 0.1727 \t Test R: 0.1089 \t Nonzero coef: 2\n",
      "Parameter: 6.00e-03 Train R2: 0.1635 \t Test R: 0.1116 \t Nonzero coef: 2\n",
      "Parameter: 8.00e-03 Train R2: 0.1506 \t Test R: 0.1058 \t Nonzero coef: 2\n",
      "Parameter: 1.00e-02 Train R2: 0.1340 \t Test R: 0.0917 \t Nonzero coef: 2\n",
      "Parameter: 2.00e-02 Train R2: 0.0997 \t Test R: 0.0749 \t Nonzero coef: 1\n",
      "Parameter: 3.00e-02 Train R2: 0.0449 \t Test R: 0.0360 \t Nonzero coef: 1\n",
      "Parameter: 4.00e-02 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n",
      "Parameter: 5.00e-02 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n",
      "Parameter: 6.00e-02 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n",
      "Parameter: 7.00e-02 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n",
      "Parameter: 8.00e-02 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n",
      "Parameter: 1.00e-01 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n",
      "Parameter: 2.00e-01 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n",
      "Parameter: 5.00e-01 Train R2: -0.0000 \t Test R: -0.0000 \t Nonzero coef: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.138e+00, tolerance: 1.373e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Layer\", i)\n",
    "    x_train = intermediate_layers_original_train[i].reshape(num_train, -1)\n",
    "    x_test = intermediate_layers_original_test[i].reshape(num_test, -1)\n",
    "\n",
    "    for a in (1e-3)*np.array([0,0.1,0.2,0.4,0.6,0.8,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "        lasso = linear_model.Lasso(alpha=a)\n",
    "        lasso.fit(x_train, pt_train)\n",
    "        print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, pt_train), \n",
    "                                                                                      lasso.score(x_test, pt_test), \n",
    "                                                                                      np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    #     with open(out_dir+\"SAE_A_LR.csv\", \"a\") as f:\n",
    "    #         f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (weight,a,'pt',\n",
    "    #             lasso.score(x_train, pt_train), lasso.score(x_test, pt_test), 'lasso', \n",
    "    #             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.2502 \t Test R: -0.0880 \t Nonzero coef: 64\n",
      "Parameter: 1.00e-03 Train R2: 0.2250 \t Test R: 0.0072 \t Nonzero coef: 18\n",
      "Parameter: 2.00e-03 Train R2: 0.2138 \t Test R: 0.0361 \t Nonzero coef: 7\n",
      "Parameter: 4.00e-03 Train R2: 0.2022 \t Test R: 0.0563 \t Nonzero coef: 5\n",
      "Parameter: 6.00e-03 Train R2: 0.1938 \t Test R: 0.0751 \t Nonzero coef: 3\n",
      "Parameter: 8.00e-03 Train R2: 0.1863 \t Test R: 0.0922 \t Nonzero coef: 3\n",
      "Parameter: 1.00e-02 Train R2: 0.1771 \t Test R: 0.1050 \t Nonzero coef: 2\n",
      "Parameter: 2.00e-02 Train R2: 0.1289 \t Test R: 0.1307 \t Nonzero coef: 1\n",
      "Parameter: 3.00e-02 Train R2: 0.1090 \t Test R: 0.1121 \t Nonzero coef: 1\n",
      "Parameter: 4.00e-02 Train R2: 0.0813 \t Test R: 0.0844 \t Nonzero coef: 1\n",
      "Parameter: 5.00e-02 Train R2: 0.0456 \t Test R: 0.0476 \t Nonzero coef: 1\n",
      "Parameter: 6.00e-02 Train R2: 0.0019 \t Test R: 0.0018 \t Nonzero coef: 1\n",
      "Parameter: 7.00e-02 Train R2: -0.0000 \t Test R: -0.0003 \t Nonzero coef: 0\n",
      "Parameter: 8.00e-02 Train R2: -0.0000 \t Test R: -0.0003 \t Nonzero coef: 0\n",
      "Parameter: 1.00e-01 Train R2: -0.0000 \t Test R: -0.0003 \t Nonzero coef: 0\n",
      "Parameter: 2.00e-01 Train R2: -0.0000 \t Test R: -0.0003 \t Nonzero coef: 0\n",
      "Parameter: 5.00e-01 Train R2: -0.0000 \t Test R: -0.0003 \t Nonzero coef: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-0aabbf89e3f7>:3: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, active_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+01, tolerance: 3.791e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Layer\", i)\n",
    "    x_train = intermediate_layers_original_train[i].reshape(num_train, -1)\n",
    "    x_test = intermediate_layers_original_test[i].reshape(num_test, -1)\n",
    "\n",
    "    for a in (1e-4)*np.array([0,0.1,0.2,0.4,0.6,0.8,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "        lasso = linear_model.Lasso(alpha=a)\n",
    "        lasso.fit(x_train, active_train)\n",
    "        print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, active_train), \n",
    "                                                                                      lasso.score(x_test, active_test), \n",
    "                                                                                      np.sum(lasso.coef_ != 0)))\n",
    "\n",
    "    #     with open(out_dir+\"SAE_A_LR.csv\", \"a\") as f:\n",
    "    #         f.write(\"%.2E,%.6f,%s,%.4f,%.4f,%s,%d,%d\\n\" % (weight,a,'active',\n",
    "    #             lasso.score(x_train, active_train), lasso.score(x_test, active_test), 'lasso', \n",
    "    #             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Trip Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.0706 \t Test R: -0.2020 \t Nonzero coef: 64\n",
      "Parameter: 1.00e-04 Train R2: 0.0706 \t Test R: -0.2016 \t Nonzero coef: 64\n",
      "Parameter: 6.00e-03 Train R2: 0.0702 \t Test R: -0.1798 \t Nonzero coef: 62\n",
      "Parameter: 7.00e-03 Train R2: 0.0701 \t Test R: -0.1762 \t Nonzero coef: 62\n",
      "Parameter: 8.00e-03 Train R2: 0.0699 \t Test R: -0.1729 \t Nonzero coef: 58\n",
      "Parameter: 1.00e-02 Train R2: 0.0696 \t Test R: -0.1664 \t Nonzero coef: 56\n",
      "Parameter: 1.10e-02 Train R2: 0.0694 \t Test R: -0.1632 \t Nonzero coef: 55\n",
      "Parameter: 1.20e-02 Train R2: 0.0692 \t Test R: -0.1601 \t Nonzero coef: 55\n",
      "Parameter: 1.30e-02 Train R2: 0.0690 \t Test R: -0.1571 \t Nonzero coef: 54\n",
      "Parameter: 1.40e-02 Train R2: 0.0687 \t Test R: -0.1541 \t Nonzero coef: 53\n",
      "Parameter: 1.50e-02 Train R2: 0.0685 \t Test R: -0.1512 \t Nonzero coef: 52\n",
      "Parameter: 2.00e-02 Train R2: 0.0670 \t Test R: -0.1382 \t Nonzero coef: 50\n",
      "Parameter: 5.00e-02 Train R2: 0.0547 \t Test R: -0.0708 \t Nonzero coef: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-aff3c5ecbb93>:3: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(x_train, trpgen_train)\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+05, tolerance: 3.630e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "for a in (1e-3)*np.array([0,0.1,6,7,8,10,11,12,13,14,15,20,50]):\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(x_train, trpgen_train)\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f \\t Nonzero coef: %d\" % (a, lasso.score(x_train, trpgen_train), \n",
    "                                                                                  lasso.score(x_test, trpgen_test), \n",
    "                                                                                  np.sum(lasso.coef_ != 0)))\n",
    "#     with open(out_dir+\"BA_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%.6f,%.4f,%.4f,%s,%d,%d\\n\" % (a, \n",
    "#             lasso.score(x_train, trpgen_train), lasso.score(x_test, trpgen_test), 'lasso', \n",
    "#             np.sum(lasso.coef_ != 0), len(lasso.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0.00e+00 Train R2: 0.0706 \t Test R: -0.2020\n",
      "Parameter: 1.00e+00 Train R2: 0.0705 \t Test R: -0.1890\n",
      "Parameter: 1.00e+01 Train R2: 0.0664 \t Test R: -0.1155\n",
      "Parameter: 2.00e+01 Train R2: 0.0603 \t Test R: -0.0760\n",
      "Parameter: 3.00e+01 Train R2: 0.0549 \t Test R: -0.0538\n",
      "Parameter: 4.00e+01 Train R2: 0.0503 \t Test R: -0.0401\n",
      "Parameter: 5.00e+01 Train R2: 0.0465 \t Test R: -0.0309\n",
      "Parameter: 6.00e+01 Train R2: 0.0432 \t Test R: -0.0244\n",
      "Parameter: 7.00e+01 Train R2: 0.0404 \t Test R: -0.0198\n",
      "Parameter: 8.00e+01 Train R2: 0.0379 \t Test R: -0.0163\n",
      "Parameter: 1.00e+02 Train R2: 0.0339 \t Test R: -0.0117\n",
      "Parameter: 2.00e+02 Train R2: 0.0225 \t Test R: -0.0044\n",
      "Parameter: 5.00e+02 Train R2: 0.0119 \t Test R: -0.0034\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "\n",
    "for a in (1e+1)*np.array([0,0.1,1,2,3,4,5,6,7,8,10,20,50]):\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(x_train, trpgen_train)\n",
    "#     with open(out_dir+sampling+\"_\"+model_code+\"_regression_\"+variable_names[-1]+\".csv\", \"a\") as f:\n",
    "#         f.write(\"%s,%s,%s,%.5f,%.4f,%.4f,%s,%s,%d,%d\\n\" % (model_run_date, model_type, variable_names[-1], a, \n",
    "#             ridge.score(x_train, trpgen_train), ridge.score(x_test, trpgen_test), 'ridge', zoomlevel,\n",
    "#             np.sum(ridge.coef_ != 0), len(ridge.coef_)))\n",
    "    print(\"Parameter: %.2e Train R2: %.4f \\t Test R: %.4f\" % (a, ridge.score(x_train, trpgen_train), \n",
    "                                                              ridge.score(x_test, trpgen_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MNL for Mode Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader and model definition\n",
    "\n",
    "trainset = SurveyDataset(torch.tensor(x_train,  dtype=torch.float), torch.tensor(y_train, dtype=torch.float))\n",
    "trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "\n",
    "testset = SurveyDataset(torch.tensor(x_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.float))\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "kldivloss = nn.KLDivLoss(reduction='sum')\n",
    "mseloss = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_train = np.sum(np.power(y_train - np.mean(y_train, axis=0), 2), axis=0)\n",
    "sst_test = np.sum(np.power(y_test - np.mean(y_test, axis=0), 2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mnl_torch(lr_list, wd_list):\n",
    "    \n",
    "    for (lr, wd) in itertools.product(lr_list, wd_list):\n",
    "        \n",
    "        print(f\"[lr: {lr:.4f}, wd: {wd:3.2e}]\")\n",
    "\n",
    "        # model setup\n",
    "        model = mnl.MNL(n_alts=4, n_features=x_train.shape[-1])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "#         print(optimizer)\n",
    "        # model training\n",
    "\n",
    "        converged = 0\n",
    "        ref1 = 0\n",
    "        ref2 = 0\n",
    "\n",
    "        for epoch in range(5000):\n",
    "\n",
    "            kl_ = 0\n",
    "            mse_ = 0\n",
    "            mse1_ = 0\n",
    "            mse2_ = 0\n",
    "            mse3_ = 0\n",
    "            mse4_ = 0\n",
    "\n",
    "            for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                util = model(x_batch)\n",
    "                probs = torch.log(nn.functional.softmax(util, dim=1))\n",
    "                kl = kldivloss(probs, y_batch)\n",
    "        #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                kl_ += kl.item()\n",
    "\n",
    "                mse = mseloss(torch.exp(probs), y_batch)\n",
    "        #         mse = mseloss(util, y_batch)\n",
    "                mse_ += mse.sum().item()\n",
    "                mse1_ += mse[:,0].sum().item()\n",
    "                mse2_ += mse[:,1].sum().item()\n",
    "                mse3_ += mse[:,2].sum().item()\n",
    "                mse4_ += mse[:,3].sum().item()\n",
    "                mse = mse.sum()\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                kl.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_kl = kl_/len(trainset)\n",
    "            train_mse = np.sqrt(mse_/len(trainset))\n",
    "            train_mse1 = np.sqrt(mse1_/len(trainset))\n",
    "            train_mse2 = np.sqrt(mse2_/len(trainset))\n",
    "            train_mse3 = np.sqrt(mse3_/len(trainset))\n",
    "            train_mse4 = np.sqrt(mse4_/len(trainset))\n",
    "\n",
    "            train_r1 = 1-mse1_/sst_train[0]\n",
    "            train_r2 = 1-mse2_/sst_train[1]\n",
    "            train_r3 = 1-mse3_/sst_train[2]\n",
    "            train_r4 = 1-mse4_/sst_train[3]\n",
    "\n",
    "            loss_ = train_kl\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "\n",
    "                kl_ = 0\n",
    "                mse_ = 0 \n",
    "                mse1_ = 0\n",
    "                mse2_ = 0\n",
    "                mse3_ = 0\n",
    "                mse4_ = 0\n",
    "\n",
    "                for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "                    \n",
    "                    util = model(x_batch)\n",
    "                    probs = torch.log(nn.functional.softmax(util,dim=1))\n",
    "                    kl = kldivloss(probs, y_batch)\n",
    "            #         kl = kldivloss(torch.log(util), y_batch)\n",
    "                    kl_ += kl.item()\n",
    "\n",
    "                    mse = mseloss(torch.exp(probs), y_batch)\n",
    "            #         mse = mseloss(util, y_batch)\n",
    "                    mse_ += mse.sum().item()\n",
    "                    mse1_ += mse[:,0].sum().item()\n",
    "                    mse2_ += mse[:,1].sum().item()\n",
    "                    mse3_ += mse[:,2].sum().item()\n",
    "                    mse4_ += mse[:,3].sum().item()\n",
    "\n",
    "                test_kl = kl_/len(testset)\n",
    "                test_mse = np.sqrt(mse_/len(testset))\n",
    "                test_mse1 = np.sqrt(mse1_/len(testset))\n",
    "                test_mse2 = np.sqrt(mse2_/len(testset))\n",
    "                test_mse3 = np.sqrt(mse3_/len(testset))\n",
    "                test_mse4 = np.sqrt(mse4_/len(testset))\n",
    "\n",
    "                r1 = r2_score(y_batch.numpy()[:,0],torch.exp(probs).detach().numpy()[:,0])\n",
    "                r2 = r2_score(y_batch.numpy()[:,1],torch.exp(probs).detach().numpy()[:,1])\n",
    "                r3 = r2_score(y_batch.numpy()[:,2],torch.exp(probs).detach().numpy()[:,2])\n",
    "                r4 = r2_score(y_batch.numpy()[:,3],torch.exp(probs).detach().numpy()[:,3])\n",
    "\n",
    "                if epoch >= 40:\n",
    "                    if (np.abs(loss_ - ref1)/ref1<0.001) & (np.abs(loss_ - ref2)/ref2<0.001):\n",
    "                        converged = 1\n",
    "                        print(\"Early stopping at epoch\", epoch)\n",
    "                        break\n",
    "                    if (ref1 < loss_) & (ref1 < ref2):\n",
    "                        print(\"Diverging. stop.\")\n",
    "                        break\n",
    "                    if loss_ < best:\n",
    "                        best = loss_\n",
    "                        best_epoch = epoch\n",
    "                        output = (best_epoch, train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                else:\n",
    "                    best = loss_\n",
    "                    best_epoch = epoch\n",
    "                    output = (best_epoch, train_kl, train_mse, train_mse1, train_mse2, train_mse3, train_mse4,\n",
    "                                  test_kl, test_mse, test_mse1, test_mse2, test_mse3, test_mse4,\n",
    "                                  train_r1, train_r2, train_r3, train_r4, r1, r2, r3, r4)\n",
    "                ref2 = ref1\n",
    "                ref1 = loss_\n",
    "\n",
    "            if epoch % 300 == 0:\n",
    "\n",
    "                print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} RMSE {train_mse:.3f}\")\n",
    "                   # {train_mse1:.3f} {train_mse2:.3f} {train_mse3:.3f} {train_mse4:.3f}\")\n",
    "                print(f\"\\t\\t\\t\\t\\t\\t Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "                print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} RMSE {np.sqrt(mse_/len(testset)):.3f}\")\n",
    "                   #     {np.sqrt(mse1_/len(testset)):.3f} {np.sqrt(mse2_/len(testset)):.3f} {np.sqrt(mse3_/len(testset)):.3f} {np.sqrt(mse4_/len(testset)):.3f}\")\n",
    "                print(f\"\\t\\t\\t\\t\\t\\t Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "                print(f\"[epoch: {epoch:>3d}] Train KL loss: {train_kl:.3f} Train R2 score: {train_r1:.3f} {train_r2:.3f} {train_r3:.3f} {train_r4:.3f} \")\n",
    "                print(f\"[epoch: {epoch:>3d}] Test KL loss: {kl_/len(testset):.3f} Test R2 score: {r1:.3f} {r2:.3f} {r3:.3f} {r4:.3f} \")\n",
    "\n",
    "        with open(out_dir+\"SAE_A_MNL.csv\", \"a\") as f:\n",
    "            f.write(\"%.1E,%.1E,%.1E,%d,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%.4f,%d\\n\" % \n",
    "                    ((weight,lr,wd)+output+(converged,)))\n",
    "\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Train KL loss: {output[1]:.3f} Train R2 score: {output[13]:.3f} {output[14]:.3f} {output[15]:.3f} {output[16]:.3f} \")\n",
    "        print(f\"[epoch: {best_epoch:>3d}] Test KL loss: {output[7]:.3f} Test R2 score: {output[17]:.3f} {output[18]:.3f} {output[19]:.3f} {output[20]:.3f} \")\n",
    "        print()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr: 0.0001, wd: 1.00e-01]\n",
      "[epoch:   0] Train KL loss: 0.782 RMSE 0.657\n",
      "\t\t\t\t\t\t Train R2 score: -1.691 -4.592 -6.467 -1.708 \n",
      "[epoch:   0] Test KL loss: 0.279 RMSE 0.346\n",
      "\t\t\t\t\t\t Test R2 score: -0.140 -0.483 -2.953 -0.106 \n",
      "[epoch:   0] Train KL loss: 0.782 Train R2 score: -1.691 -4.592 -6.467 -1.708 \n",
      "[epoch:   0] Test KL loss: 0.279 Test R2 score: -0.140 -0.483 -2.953 -0.106 \n",
      "[epoch: 300] Train KL loss: 0.150 RMSE 0.225\n",
      "\t\t\t\t\t\t Train R2 score: 0.420 0.528 0.004 0.437 \n",
      "[epoch: 300] Test KL loss: 0.125 RMSE 0.203\n",
      "\t\t\t\t\t\t Test R2 score: 0.479 0.578 -0.073 0.412 \n",
      "[epoch: 300] Train KL loss: 0.150 Train R2 score: 0.420 0.528 0.004 0.437 \n",
      "[epoch: 300] Test KL loss: 0.125 Test R2 score: 0.479 0.578 -0.073 0.412 \n",
      "[epoch: 600] Train KL loss: 0.141 RMSE 0.214\n",
      "\t\t\t\t\t\t Train R2 score: 0.466 0.582 0.010 0.487 \n",
      "[epoch: 600] Test KL loss: 0.116 RMSE 0.192\n",
      "\t\t\t\t\t\t Test R2 score: 0.532 0.633 -0.103 0.448 \n",
      "[epoch: 600] Train KL loss: 0.141 Train R2 score: 0.466 0.582 0.010 0.487 \n",
      "[epoch: 600] Test KL loss: 0.116 Test R2 score: 0.532 0.633 -0.103 0.448 \n",
      "Early stopping at epoch 665\n",
      "[epoch: 660] Train KL loss: 0.140 Train R2 score: 0.470 0.587 0.011 0.493 \n",
      "[epoch: 660] Test KL loss: 0.115 Test R2 score: 0.536 0.639 -0.106 0.454 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[1e-3]);\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[1e-2]);\n",
    "\n",
    "    model = mnl_torch(lr_list=[1e-4], wd_list=[1e-1]);\n",
    "#     model = mnl_torch(lr_list=[1e-5], wd_list=[1e+0]);\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[0.1,1,10,50,100,1000]);\n",
    "#     model = mnl_torch(lr_list=[1e-5], wd_list=[1e+1]);\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[50]);\n",
    "\n",
    "#     mnl_torch(lr_list=[1e-4], wd_list=[1e+2]);\n",
    "\n",
    "#     mnl_torch(lr_list=[5e-5], wd_list=[1e+3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), out_dir+\"sae_a_D_1_220829.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qingyi",
   "language": "python",
   "name": "qingyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
