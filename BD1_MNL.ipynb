{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc2bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from setup import *\n",
    "from dataloader import SurveyDataset\n",
    "import mnl\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c2f0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = '1571'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cedeaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.read_csv(data_dir+\"trips.csv\")\n",
    "n_alts = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9133c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.713060\n",
      "1    0.132001\n",
      "4    0.111893\n",
      "3    0.043046\n",
      "Name: mode, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(tp['mode'].value_counts()/len(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "521995a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp['morning'] = (tp['dep_hour'] > 6) & (tp['dep_hour'] < 10)\n",
    "tp['afternoon'] = (tp['dep_hour'] > 15) & (tp['dep_hour'] < 19)\n",
    "tp['morning'] = tp['morning'].astype(int)\n",
    "tp['afternoon'] = tp['afternoon'].astype(int)\n",
    "\n",
    "def normalize_features(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = df[c]/df[c].max()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9301b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60edc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_filter = pd.read_csv(data_dir+\"census_tracts_filtered-\"+data_version+\".csv\")\n",
    "unique_ct = ct_filter['geoid'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44e1aaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0aa0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_filter = []\n",
    "for t1, t2 in zip(tp['tract_1'], tp['tract_2']):\n",
    "    if sum(unique_ct == t1) == 1 and sum(unique_ct == t2) == 1:\n",
    "        trip_filter.append(True)\n",
    "    else:\n",
    "        trip_filter.append(False)\n",
    "trip_filter = np.array(trip_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0cbadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tp[['const','morning','afternoon','companion', 'distance', \n",
    "         'from_home', 'to_home', 'purp_work', 'purp_school', 'purp_errand', 'purp_recreation', \n",
    "         'ontime_important', '12_18yrs', '18_25yrs', '25_55yrs', '55+yrs', \n",
    "         'disability', 'educ_col', 'educ_grad', \n",
    "         'race_white', 'race_black', 'race_asian', \n",
    "         'male', 'female', \n",
    "         'emply_park', 'emply_transit', 'emply_veh', 'emply_wfh', 'emply_flex', 'emply_hours', \n",
    "         'license', 'person_trips', 'person_transit', 'person_freq_transit', \n",
    "         'hh_inc_0_30', 'hh_inc_30_60', 'hh_inc_60_100', 'hh_inc_100_150', 'hh_inc_150', \n",
    "         'avg_pr_veh', 'home_own', 'home_house', 'home_condo']].to_numpy()[trip_filter]\n",
    "\n",
    "y = tp['mode'].astype(int).to_numpy()[trip_filter] - 1\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91ef1e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79929, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "267ed279",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SurveyDataset(torch.tensor(x_train, dtype=torch.float), torch.tensor(y_train, dtype=torch.long))\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "testset = SurveyDataset(torch.tensor(x_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.long))\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b4c4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = mnl.MNL(n_alts=n_alts, n_features=x.shape[-1])\n",
    "# model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e3d0826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   0] Train loss: 0.5883 accuracy: 0.806\n",
      "[epoch:   0] Test loss: 0.4850 accuracy: 0.835\n",
      "[epoch:   1] Train loss: 0.4651 accuracy: 0.841\n",
      "[epoch:   1] Test loss: 0.4669 accuracy: 0.841\n",
      "[epoch:   2] Train loss: 0.4650 accuracy: 0.843\n",
      "[epoch:   2] Test loss: 0.4731 accuracy: 0.844\n",
      "[epoch:   3] Train loss: 0.4661 accuracy: 0.842\n",
      "[epoch:   3] Test loss: 0.4756 accuracy: 0.841\n",
      "[epoch:   4] Train loss: 0.4695 accuracy: 0.841\n",
      "[epoch:   4] Test loss: 0.4679 accuracy: 0.840\n",
      "[epoch:   5] Train loss: 0.4677 accuracy: 0.843\n",
      "[epoch:   5] Test loss: 0.4633 accuracy: 0.841\n",
      "[epoch:   6] Train loss: 0.4672 accuracy: 0.842\n",
      "[epoch:   6] Test loss: 0.4711 accuracy: 0.843\n",
      "[epoch:   7] Train loss: 0.4696 accuracy: 0.843\n",
      "[epoch:   7] Test loss: 0.4846 accuracy: 0.839\n",
      "[epoch:   8] Train loss: 0.4689 accuracy: 0.841\n",
      "[epoch:   8] Test loss: 0.4669 accuracy: 0.841\n",
      "[epoch:   9] Train loss: 0.4689 accuracy: 0.842\n",
      "[epoch:   9] Test loss: 0.4729 accuracy: 0.835\n",
      "[epoch:  10] Train loss: 0.4676 accuracy: 0.843\n",
      "[epoch:  10] Test loss: 0.4615 accuracy: 0.844\n",
      "[epoch:  11] Train loss: 0.4705 accuracy: 0.841\n",
      "[epoch:  11] Test loss: 0.4785 accuracy: 0.836\n",
      "[epoch:  12] Train loss: 0.4693 accuracy: 0.842\n",
      "[epoch:  12] Test loss: 0.4617 accuracy: 0.842\n",
      "[epoch:  13] Train loss: 0.4720 accuracy: 0.841\n",
      "[epoch:  13] Test loss: 0.4670 accuracy: 0.841\n",
      "[epoch:  14] Train loss: 0.4708 accuracy: 0.840\n",
      "[epoch:  14] Test loss: 0.4626 accuracy: 0.845\n",
      "[epoch:  15] Train loss: 0.4704 accuracy: 0.841\n",
      "[epoch:  15] Test loss: 0.4810 accuracy: 0.832\n",
      "[epoch:  16] Train loss: 0.4680 accuracy: 0.842\n",
      "[epoch:  16] Test loss: 0.4629 accuracy: 0.840\n",
      "[epoch:  17] Train loss: 0.4685 accuracy: 0.843\n",
      "[epoch:  17] Test loss: 0.4724 accuracy: 0.841\n",
      "[epoch:  18] Train loss: 0.4719 accuracy: 0.841\n",
      "[epoch:  18] Test loss: 0.4678 accuracy: 0.842\n",
      "[epoch:  19] Train loss: 0.4698 accuracy: 0.842\n",
      "[epoch:  19] Test loss: 0.4771 accuracy: 0.839\n",
      "[epoch:  20] Train loss: 0.4671 accuracy: 0.842\n",
      "[epoch:  20] Test loss: 0.4626 accuracy: 0.841\n",
      "[epoch:  21] Train loss: 0.4670 accuracy: 0.842\n",
      "[epoch:  21] Test loss: 0.4583 accuracy: 0.845\n",
      "[epoch:  22] Train loss: 0.4681 accuracy: 0.841\n",
      "[epoch:  22] Test loss: 0.4729 accuracy: 0.840\n",
      "[epoch:  23] Train loss: 0.4686 accuracy: 0.842\n",
      "[epoch:  23] Test loss: 0.4825 accuracy: 0.836\n",
      "[epoch:  24] Train loss: 0.4668 accuracy: 0.842\n",
      "[epoch:  24] Test loss: 0.4610 accuracy: 0.845\n",
      "[epoch:  25] Train loss: 0.4674 accuracy: 0.842\n",
      "[epoch:  25] Test loss: 0.4889 accuracy: 0.832\n",
      "[epoch:  26] Train loss: 0.4730 accuracy: 0.840\n",
      "[epoch:  26] Test loss: 0.4830 accuracy: 0.833\n",
      "[epoch:  27] Train loss: 0.4709 accuracy: 0.841\n",
      "[epoch:  27] Test loss: 0.4742 accuracy: 0.843\n",
      "[epoch:  28] Train loss: 0.4707 accuracy: 0.841\n",
      "[epoch:  28] Test loss: 0.4646 accuracy: 0.839\n",
      "[epoch:  29] Train loss: 0.4669 accuracy: 0.842\n",
      "[epoch:  29] Test loss: 0.4619 accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    loss_ = 0\n",
    "    correct = 0\n",
    "    for batch, (x_batch, y_batch) in enumerate(trainloader):\n",
    "        # Compute prediction and loss\n",
    "        util = model(x_batch)\n",
    "        loss = loss_fn(util, y_batch)\n",
    "        loss_ += loss.item()*len(y_batch)\n",
    "        \n",
    "        pred = torch.argmax(util, dim=1)\n",
    "        correct += torch.sum(pred == y_batch)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    if batch % 1 == 0:\n",
    "        print(f\"[epoch: {epoch:>3d}] Train loss: {loss_/len(trainset):.4f} accuracy: {correct/len(trainset):.3f}\")\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    loss_ = 0\n",
    "    for batch, (x_batch, y_batch) in enumerate(testloader):\n",
    "        util = model(x_batch)\n",
    "        loss = loss_fn(util, y_batch)\n",
    "        loss_ += loss.item()*len(y_batch)\n",
    "        pred = torch.argmax(util, dim=1)\n",
    "        correct += torch.sum(pred == y_batch)\n",
    "        \n",
    "    print(f\"[epoch: {epoch:>3d}] Test loss: {loss_/len(testset):.4f} accuracy: {correct/len(testset):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b058333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
