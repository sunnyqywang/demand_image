{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "from setup import out_dir, data_dir, image_dir, model_dir\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn\n",
    "import torchvision.utils\n",
    "import torchvision.transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    is_tensorboard_available = True\n",
    "except Exception:\n",
    "    is_tensorboard_available = False\n",
    "\n",
    "from dataloader import image_loader, load_demo\n",
    "from autoencoder import Autoencoder\n",
    "from M1_util_train_test import load_model, train, test, AverageMeter\n",
    "from util_model import my_loss\n",
    "from exp_version import get_hp_from_version_code\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='[%(asctime)s %(name)s %(levelname)s] - %(message)s',\n",
    "    datefmt='%Y/%m/%d %H:%M:%S',\n",
    "    level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomlevel = 'zoom13'\n",
    "output_dim = 3\n",
    "model_run_date = \"2207\"\n",
    "sampling='stratified'\n",
    "normalization = 'minmax'\n",
    "data_version = '1571'\n",
    "variable_names = ['tot_population','pct25_34yrs','pct35_50yrs','pctover65yrs',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pct_col_grad','avg_tt_to_work','inc_per_capita']\n",
    "model_save_variable_names = ['totpop','pct25-34','pct35-50','pctsenior',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pctcolgrad','avg_tt_to_work','inc']\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_cs, demo_np = load_demo(data_dir, norm=normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 'F'\n",
    "v2 = 1 \n",
    "weight, lr, wd = get_hp_from_version_code(v1,v2)\n",
    "\n",
    "if weight > 100:\n",
    "    weightt = 1/weight\n",
    "    weight = 1\n",
    "\n",
    "else:\n",
    "    weightt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'weight':weight,\n",
    "        'weightt':weightt,\n",
    "        'image_size': 224, \n",
    "        'depth': -1,\n",
    "       'base_channels':64,\n",
    "       'output_dim':output_dim,\n",
    "       'num_demo_vars':len(variable_names),\n",
    "       'demo_norm': normalization,\n",
    "       'cardinality':1,\n",
    "       'epochs':200,\n",
    "       'batch_size':16,\n",
    "       'base_lr':lr,\n",
    "       'weight_decay':wd,\n",
    "       'momentum': 0.9,\n",
    "       'nesterov': True,\n",
    "       'milestones': '[50,100]',\n",
    "       'lr_decay':0.1,\n",
    "       'seed': 1234,\n",
    "       'outdir':out_dir,\n",
    "       'num_workers':8,\n",
    "       'tensorboard':False,\n",
    "       'save':True}\n",
    "\n",
    "model_config = OrderedDict([\n",
    "    ('arch', 'resnext'),\n",
    "    ('depth', args['depth']),\n",
    "    ('base_channels', args['base_channels']),\n",
    "    ('cardinality', args['cardinality']),\n",
    "    ('input_shape', (1, 3, 32, 32)),\n",
    "    ('output_dim', args['output_dim']),\n",
    "    ('num_demo_vars', args['num_demo_vars'])\n",
    "])\n",
    "\n",
    "optim_config = OrderedDict([\n",
    "    ('epochs', args['epochs']),\n",
    "    ('batch_size', args['batch_size']),\n",
    "    ('base_lr', args['base_lr']),\n",
    "    ('weight_decay', args['weight_decay']),\n",
    "    ('momentum', args['momentum']),\n",
    "    ('nesterov', args['nesterov']),\n",
    "    ('milestones', json.loads(args['milestones'])),\n",
    "    ('lr_decay', args['lr_decay']),\n",
    "])\n",
    "\n",
    "data_config = OrderedDict([\n",
    "    ('dataset', 'CIFAR10'),\n",
    "    ('image_size', args['image_size']),\n",
    "    ('demo_norm', args['demo_norm'])\n",
    "])\n",
    "\n",
    "run_config = OrderedDict([\n",
    "    ('weight', args['weight']),\n",
    "    ('weightt', args['weightt']),\n",
    "    ('seed', args['seed']),\n",
    "    ('outdir', args['outdir']),\n",
    "    ('save', args['save']),\n",
    "    ('num_workers', args['num_workers']),\n",
    "    ('tensorboard', args['tensorboard']),\n",
    "])\n",
    "\n",
    "config = OrderedDict([\n",
    "    ('model_config', model_config),\n",
    "    ('optim_config', optim_config),\n",
    "    ('data_config', data_config),\n",
    "    ('run_config', run_config),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse command line arguments\n",
    "#config = parse_args()\n",
    "#logger.info(json.dumps(config, indent=2))\n",
    "\n",
    "model_name = datetime.now().strftime(\"%m%d-%H%M\")\n",
    "\n",
    "run_config = config['run_config']\n",
    "optim_config = config['optim_config']\n",
    "\n",
    "# TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(model_name) if run_config['tensorboard'] else None\n",
    "\n",
    "# set random seed\n",
    "seed = run_config['seed']\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# create output directory\n",
    "outdir = run_config['outdir']\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# save config as json file in output directory\n",
    "outpath = os.path.join(outdir, 'config.json')\n",
    "with open(outpath, 'w') as fout:\n",
    "    json.dump(config, fout, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14139 images in dataset\n",
      "1571 images in dataset\n"
     ]
    }
   ],
   "source": [
    "# data loaders\n",
    "# train_loader, test_loader = get_loader(optim_config['batch_size'], run_config['num_workers'])\n",
    "train_loader, test_loader = image_loader(image_dir+zoomlevel+\"/\", data_dir, optim_config['batch_size'], \n",
    "                                         run_config['num_workers'], \n",
    "                                         data_config['image_size'], \n",
    "                                         data_version=data_version, sampling=sampling, \n",
    "                                         recalculate_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.MSELoss(reduction='mean')\n",
    "criterion = my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "config['model_config']['input_shape'] = (1,3,data_config['image_size'],data_config['image_size'])\n",
    "\n",
    "encoder = load_model(config['model_config']['arch'], 'Encoder', config['model_config'])\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "config['model_config']['input_shape'] = [1,2048,config['model_config']['output_dim'],config['model_config']['output_dim']]\n",
    "\n",
    "config['model_config']['conv_shape'] = [data_config['image_size']//32,data_config['image_size']//32]\n",
    "config['model_config']['output_channels'] = 3\n",
    "\n",
    "decoder = load_model(config['model_config']['arch'], 'Decoder', config['model_config'])\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "config['encoder'] = encoder\n",
    "config['decoder'] = decoder\n",
    "model = load_model('autoencoder','Autoencoder', config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:23:07 __main__ INFO] - n_params: 31961862\n"
     ]
    }
   ],
   "source": [
    "n_params = sum([param.view(-1).size()[0] for param in encoder.parameters()]) +\\\n",
    "           sum([param.view(-1).size()[0] for param in decoder.parameters()])\n",
    "logger.info('n_params: {}'.format(n_params))\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=optim_config['base_lr'],\n",
    "    momentum=optim_config['momentum'],\n",
    "    weight_decay=optim_config['weight_decay'],\n",
    "    nesterov=optim_config['nesterov'])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=optim_config['milestones'],\n",
    "    gamma=optim_config['lr_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:25:23 __main__ INFO] - Epoch 0 Step 883/884 Train Loss 0.03733715\n",
      "[2022/07/24 00:25:28 __main__ INFO] - Epoch 0 Test Loss 0.04107460\n",
      "[2022/07/24 00:25:28 __main__ INFO] - Elapsed 5.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2764716889735315 0.03379813076117043\n",
      "5.713462040088615 0.033766770775264916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:28:37 __main__ INFO] - Epoch 1 Step 883/884 Train Loss 0.03519213\n",
      "[2022/07/24 00:28:42 __main__ INFO] - Epoch 1 Test Loss 0.03664240\n",
      "[2022/07/24 00:28:42 __main__ INFO] - Elapsed 5.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32395226427281 0.03331844539504131\n",
      "3.061000216259327 0.03329844256075737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:31:52 __main__ INFO] - Epoch 2 Step 883/884 Train Loss 0.03467630\n",
      "[2022/07/24 00:31:57 __main__ INFO] - Epoch 2 Test Loss 0.03522063\n",
      "[2022/07/24 00:31:57 __main__ INFO] - Elapsed 5.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.387338914399235 0.032833295434167076\n",
      "2.217796912539991 0.032849248864944024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:35:08 __main__ INFO] - Epoch 3 Step 883/884 Train Loss 0.03412001\n",
      "[2022/07/24 00:35:13 __main__ INFO] - Epoch 3 Test Loss 0.03619821\n",
      "[2022/07/24 00:35:13 __main__ INFO] - Elapsed 5.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0961357471974775 0.032102077410886436\n",
      "3.7422242435001656 0.03214626054507809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:38:24 __main__ INFO] - Epoch 4 Step 883/884 Train Loss 0.03362259\n",
      "[2022/07/24 00:38:29 __main__ INFO] - Epoch 4 Test Loss 0.03610151\n",
      "[2022/07/24 00:38:29 __main__ INFO] - Elapsed 5.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.432297008573288 0.03166921648887648\n",
      "4.1119587712632235 0.031704786552848536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:41:41 __main__ INFO] - Epoch 5 Step 883/884 Train Loss 0.03314229\n",
      "[2022/07/24 00:41:46 __main__ INFO] - Epoch 5 Test Loss 0.03453793\n",
      "[2022/07/24 00:41:46 __main__ INFO] - Elapsed 5.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.426516869127333 0.03111141080065744\n",
      "3.0721781758002793 0.031149847031952123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:44:57 __main__ INFO] - Epoch 6 Step 883/884 Train Loss 0.03262020\n",
      "[2022/07/24 00:45:03 __main__ INFO] - Epoch 6 Test Loss 0.03292370\n",
      "[2022/07/24 00:45:03 __main__ INFO] - Elapsed 5.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4050185364344405 0.030518676134507983\n",
      "2.200078445834447 0.030594847315551482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:48:14 __main__ INFO] - Epoch 7 Step 883/884 Train Loss 0.03211652\n",
      "[2022/07/24 00:48:19 __main__ INFO] - Epoch 7 Test Loss 0.03208848\n",
      "[2022/07/24 00:48:19 __main__ INFO] - Elapsed 5.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.032127785348801 0.030056348975953474\n",
      "1.8661041776221177 0.03015481447458581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:51:30 __main__ INFO] - Epoch 8 Step 883/884 Train Loss 0.03175178\n",
      "[2022/07/24 00:51:35 __main__ INFO] - Epoch 8 Test Loss 0.03469533\n",
      "[2022/07/24 00:51:35 __main__ INFO] - Elapsed 5.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.926444687636926 0.029768886305795293\n",
      "4.44673255086999 0.029879468102771575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:54:46 __main__ INFO] - Epoch 9 Step 883/884 Train Loss 0.03126040\n",
      "[2022/07/24 00:54:52 __main__ INFO] - Epoch 9 Test Loss 0.03217815\n",
      "[2022/07/24 00:54:52 __main__ INFO] - Elapsed 5.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.174867053042545 0.029003287118270472\n",
      "2.959516162388024 0.029135228240276763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 00:58:03 __main__ INFO] - Epoch 10 Step 883/884 Train Loss 0.03096859\n",
      "[2022/07/24 00:58:08 __main__ INFO] - Epoch 10 Test Loss 0.03102370\n",
      "[2022/07/24 00:58:08 __main__ INFO] - Elapsed 5.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.377662019772108 0.02864603416419453\n",
      "2.1523543757894554 0.028781019278679813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 01:01:20 __main__ INFO] - Epoch 11 Step 883/884 Train Loss 0.03060854\n",
      "[2022/07/24 01:01:25 __main__ INFO] - Epoch 11 Test Loss 0.03042867\n",
      "[2022/07/24 01:01:25 __main__ INFO] - Elapsed 5.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4107950420458555 0.0280178711828223\n",
      "2.2459799015789272 0.02825649956414049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 01:04:36 __main__ INFO] - Epoch 12 Step 883/884 Train Loss 0.03025205\n",
      "[2022/07/24 01:04:41 __main__ INFO] - Epoch 12 Test Loss 0.03288794\n",
      "[2022/07/24 01:04:41 __main__ INFO] - Elapsed 5.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.215494593414511 0.027672439995160916\n",
      "4.871627332179615 0.027895666511168725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 01:07:52 __main__ INFO] - Epoch 13 Step 883/884 Train Loss 0.02980989\n",
      "[2022/07/24 01:07:57 __main__ INFO] - Epoch 13 Test Loss 0.02963756\n",
      "[2022/07/24 01:07:57 __main__ INFO] - Elapsed 5.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5745061038407 0.027063050587410886\n",
      "2.29651515181512 0.02719161818425493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 01:11:08 __main__ INFO] - Epoch 14 Step 883/884 Train Loss 0.02904766\n",
      "[2022/07/24 01:11:13 __main__ INFO] - Epoch 14 Test Loss 0.02850855\n",
      "[2022/07/24 01:11:13 __main__ INFO] - Elapsed 5.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.689830011770575 0.025818724790390664\n",
      "2.466260993950302 0.026013973643517308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/07/24 01:14:24 __main__ INFO] - Epoch 15 Step 883/884 Train Loss 0.02825085\n",
      "[2022/07/24 01:14:29 __main__ INFO] - Epoch 15 Test Loss 0.02715802\n",
      "[2022/07/24 01:14:29 __main__ INFO] - Elapsed 5.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.600903816582821 0.024557119997253046\n",
      "2.476600513489279 0.02458006312039343\n"
     ]
    }
   ],
   "source": [
    "# Test with Adam Optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=optim_config['base_lr'],\n",
    "#                              weight_decay=optim_config['weight_decay'])\n",
    "\n",
    "# run test before start training\n",
    "# test_outputs = test(0, model, criterion, test_loader, run_config, writer, device)\n",
    "\n",
    "ref1 = 0\n",
    "ref2 = 0\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "train_flag = True\n",
    "\n",
    "run_config['scheduler'] = scheduler\n",
    "    \n",
    "for epoch in range(args['epochs']):\n",
    "\n",
    "    loss_ = train(epoch, model, optimizer, criterion, train_loader, (demo_cs,demo_np), run_config,\n",
    "         writer, device, logger=logger)\n",
    "    train_loss_list.append(loss_)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    test_loss_ = test(epoch, model, criterion, test_loader, (demo_cs,demo_np), run_config,\n",
    "                    writer, device, logger, return_output=False)\n",
    "    test_loss_list.append(test_loss_)\n",
    "    \n",
    "    model.eval()\n",
    "    loss_meter_1 = AverageMeter()\n",
    "    loss_meter_2 = AverageMeter()\n",
    "\n",
    "    for step, (image_list, data) in enumerate(test_loader):\n",
    "\n",
    "        census_index = [demo_cs.index(i[i.rfind('/')+1:i.rfind('_')]) for i in image_list]\n",
    "        census_data = demo_np[census_index]\n",
    "\n",
    "        census_data = torch.tensor(census_data).to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        out_image, out_demo = model(data)\n",
    "\n",
    "        loss1, loss2 = criterion(out_image, out_demo, data, census_data, return_components=True)\n",
    "\n",
    "        num = data.size(0)\n",
    "\n",
    "        loss_meter_1.update(loss1.item(), num)\n",
    "        loss_meter_2.update(loss2.item(), num)\n",
    "\n",
    "#         if step % 10 == 0:\n",
    "#             print(step, end='\\t')\n",
    "\n",
    "    best_test_1 = loss_meter_1.avg\n",
    "    best_test_2 = loss_meter_2.avg\n",
    "    print(best_test_1, best_test_2)         \n",
    "\n",
    "    loss_meter_1 = AverageMeter()\n",
    "    loss_meter_2 = AverageMeter() \n",
    "    \n",
    "    for step, (image_list, data) in enumerate(train_loader):\n",
    "\n",
    "        census_index = [demo_cs.index(i[i.rfind('/')+1:i.rfind('_')]) for i in image_list]\n",
    "        census_data = demo_np[census_index]\n",
    "\n",
    "        census_data = torch.tensor(census_data).to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        out_image, out_demo = model(data)\n",
    "\n",
    "        loss1, loss2 = criterion(out_image, out_demo, data, census_data, return_components=True)\n",
    "\n",
    "        num = data.size(0)\n",
    "\n",
    "        loss_meter_1.update(loss1.item(), num)\n",
    "        loss_meter_2.update(loss2.item(), num)\n",
    "\n",
    "#         if step % 10 == 0:\n",
    "#             print(step, end='\\t')\n",
    "\n",
    "    best_1 = loss_meter_1.avg\n",
    "    best_2 = loss_meter_2.avg\n",
    "    print(best_1, best_2)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        if epoch > 50:\n",
    "            if (np.abs(loss_ - ref1)/ref1<0.0001) & (np.abs(loss_ - ref2)/ref2<0.0001):\n",
    "                print(\"Early stopping at epoch\", epoch)\n",
    "                break\n",
    "            if (ref1 < loss_) & (ref1 < ref2):\n",
    "                print(\"Diverging. stop.\")\n",
    "                train_flag = False\n",
    "                break\n",
    "            if loss_ < best:\n",
    "                best = loss_\n",
    "                best_epoch = epoch\n",
    "        else:\n",
    "            best = loss_\n",
    "            best_epoch = epoch\n",
    "\n",
    "        ref2 = ref1\n",
    "        ref1 = loss_\n",
    "\n",
    "        if (config['run_config']['save']) & (best_epoch==epoch):\n",
    "            torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'config': config},\n",
    "                model_dir+\"SAE_\"+zoomlevel+\"_\"+str(model_config['output_dim']**2*2048)+\"_\"+str(v1)+\"_\"+str(v2)+\"_\"+\n",
    "                model_run_date+\"_\"+str(epoch)+\".pt\")\n",
    "\n",
    "            \n",
    "if config['run_config']['save']:\n",
    "    files = glob.glob(model_dir+\"SAE_\"+zoomlevel+\"_\"+str(model_config['output_dim']**2*2048)+\"_\"+\n",
    "                              str(v1)+\"_\"+str(v2)+\"_\"+model_run_date+\"_*.pt\")\n",
    "\n",
    "    for f in files:\n",
    "        e = int(f.split(\"_\")[-1].split(\".\")[0])\n",
    "        if e != best_epoch:\n",
    "            os.remove(f)\n",
    "\n",
    "        \n",
    "if run_config['tensorboard']:\n",
    "    outpath = os.path.join(outdir, 'all_scalars.json')\n",
    "    writer.export_scalars_to_json(outpath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "ax.plot(train_loss_list, color='cornflowerblue', label='Train')\n",
    "ax.plot(test_loss_list, color='sandybrown', label='Test')\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_ylim([0, 1.1*np.max(train_loss_list+test_loss_list)])\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig(out_dir+\"training_plots/SAE_\"+model_run_date+\".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t120\t130\t140\t150\t160\t170\t180\t190\t0.40756353766276227 0.010623590972356966\n",
      "0\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t120\t130\t140\t150\t160\t170\t180\t190\t200\t210\t220\t230\t240\t250\t260\t270\t280\t290\t300\t310\t320\t330\t340\t350\t360\t370\t380\t390\t400\t410\t420\t430\t440\t450\t460\t470\t480\t490\t500\t510\t520\t530\t540\t550\t560\t570\t580\t590\t600\t610\t620\t630\t640\t650\t660\t670\t680\t690\t700\t710\t720\t730\t740\t750\t760\t770\t780\t790\t800\t810\t820\t830\t840\t850\t860\t870\t880\t890\t900\t910\t920\t930\t940\t950\t960\t970\t980\t990\t1000\t1010\t1020\t1030\t1040\t1050\t1060\t1070\t1080\t1090\t1100\t1110\t1120\t1130\t1140\t1150\t1160\t1170\t1180\t1190\t1200\t1210\t1220\t1230\t1240\t1250\t1260\t1270\t1280\t1290\t1300\t1310\t1320\t1330\t1340\t1350\t1360\t1370\t1380\t1390\t1400\t1410\t1420\t1430\t1440\t1450\t1460\t1470\t1480\t1490\t1500\t1510\t"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "loss_meter_1 = AverageMeter()\n",
    "loss_meter_2 = AverageMeter()\n",
    "\n",
    "for step, (image_list, data) in enumerate(test_loader):\n",
    "\n",
    "    census_index = [demo_cs.index(i[i.rfind('/')+1:i.rfind('_')]) for i in image_list]\n",
    "    census_data = demo_np[census_index]\n",
    "\n",
    "    census_data = torch.tensor(census_data).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    out_image, out_demo = model(data)\n",
    "\n",
    "    loss1, loss2 = criterion(out_image, out_demo, data, census_data, return_components=True)\n",
    "\n",
    "    num = data.size(0)\n",
    "\n",
    "    loss_meter_1.update(loss1.item(), num)\n",
    "    loss_meter_2.update(loss2.item(), num)\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(step, end='\\t')\n",
    "\n",
    "best_test_1 = loss_meter_1.avg\n",
    "best_test_2 = loss_meter_2.avg\n",
    "print(best_test_1, best_test_2)         \n",
    "\n",
    "loss_meter_1 = AverageMeter()\n",
    "loss_meter_2 = AverageMeter()                                                              \n",
    "for step, (image_list, data) in enumerate(train_loader):\n",
    "\n",
    "    census_index = [demo_cs.index(i[i.rfind('/')+1:i.rfind('_')]) for i in image_list]\n",
    "    census_data = demo_np[census_index]\n",
    "\n",
    "    census_data = torch.tensor(census_data).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    out_image, out_demo = model(data)\n",
    "\n",
    "    loss1, loss2 = criterion(out_image, out_demo, data, census_data, return_components=True)\n",
    "\n",
    "    num = data.size(0)\n",
    "\n",
    "    loss_meter_1.update(loss1.item(), num)\n",
    "    loss_meter_2.update(loss2.item(), num)\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(step, end='\\t')\n",
    "\n",
    "best_1 = loss_meter_1.avg\n",
    "best_2 = loss_meter_2.avg\n",
    "print(best_1, best_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_dir+\"SAE_train.csv\", \"a\") as f:\n",
    "    f.write(\"%s,%s,%d,%s,%s,%d,%.4f,%.4f,%.4f,%.4f,%d\\n\" % (model_run_date, zoomlevel, model_config['output_dim']**2*2048, \n",
    "            sampling, normalization, best_epoch, best_1, best_2, best_test_1, best_test_2, train_flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse Normalization\n",
    "\n",
    "# CIFAR\n",
    "# inv_normalize = torchvision.transforms.Normalize(\n",
    "#     mean=[-0.4914/0.2470, -0.4822/0.2435, -0.4465/0.2616],\n",
    "#     std=[1/0.2470, 1/0.2435, 1/0.2616]\n",
    "# )\n",
    "\n",
    "\n",
    "# Satellite image\n",
    "inv_normalize = torchvision.transforms.Normalize(\n",
    "    mean=[-0.3733/0.2173, -0.3991/0.2055, -0.3711/0.2143],\n",
    "    std=[1/0.2173, 1/0.2055, 1/0.2143]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for step, (_,data) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    test_output = model(data)\n",
    "    test_output_orig = inv_normalize(test_output)\n",
    "    data_orig = inv_normalize(data)\n",
    "    if step == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(data[plot_image, :, :, :].cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_output[plot_image, :, :, :].cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(test_output[:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(test_output[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(test_output[:,2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(data[:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(data[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(data[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).detach().cpu().numpy()[:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).detach().cpu().numpy()[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).detach().cpu().numpy()[:,2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.power((test_output - data).cpu().detach().numpy(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((test_output - data).detach().cpu().numpy()[:,2,:,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((test_output - data).detach().cpu().numpy()[:,1,:,:].flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((test_output - data).detach().cpu().numpy()[:,0,:,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_output_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0));\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.detach().numpy()[:,0,:,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qingyi",
   "language": "python",
   "name": "qingyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
