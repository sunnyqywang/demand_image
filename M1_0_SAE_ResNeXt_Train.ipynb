{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/02/02 00:50:57 matplotlib.backends DEBUG] - backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/\")\n",
    "from setup import out_dir, data_dir, image_dir, model_dir\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn\n",
    "import torchvision.utils\n",
    "import torchvision.transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    is_tensorboard_available = True\n",
    "except Exception:\n",
    "    is_tensorboard_available = False\n",
    "\n",
    "from dataloader import get_loader, image_loader, load_demo\n",
    "from autoencoder import Autoencoder\n",
    "from M1_util_train_test import load_model, train, test, AverageMeter\n",
    "from util_model import my_loss\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='[%(asctime)s %(name)s %(levelname)s] - %(message)s',\n",
    "    datefmt='%Y/%m/%d %H:%M:%S',\n",
    "    level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomlevel = 'zoom13'\n",
    "output_dim = 1\n",
    "model_run_date = \"22013101\"\n",
    "sampling='stratified'\n",
    "normalization = 'minmax'\n",
    "variable_names = ['tot_population','pct25_34yrs','pct35_50yrs','pctover65yrs',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pct_col_grad','avg_tt_to_work','inc_per_capita']\n",
    "model_save_variable_names = ['totpop','pct25-34','pct35-50','pctsenior',\n",
    "         'pctwhite_alone','pct_nonwhite','pctblack_alone',\n",
    "         'pctcolgrad','avg_tt_to_work','inc']\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/02/01 16:01:53 numexpr.utils INFO] - Note: NumExpr detected 20 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2022/02/01 16:01:53 numexpr.utils INFO] - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "demo_cs, demo_np = load_demo(data_dir, norm=normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'image_size': 224, \n",
    "        'depth': -1,\n",
    "       'base_channels':64,\n",
    "       'output_dim':output_dim,\n",
    "       'num_demo_vars':len(variable_names),\n",
    "       'demo_norm': normalization,\n",
    "       'cardinality':1,\n",
    "       'epochs':200,\n",
    "       'batch_size':16,\n",
    "       'base_lr':0.005,\n",
    "       'weight_decay':0.0005,\n",
    "       'momentum': 0.9,\n",
    "       'nesterov': True,\n",
    "       'milestones': '[50,100]',\n",
    "       'lr_decay':0.1,\n",
    "       'seed': 1234,\n",
    "       'outdir':out_dir,\n",
    "       'num_workers':8,\n",
    "       'tensorboard':False,\n",
    "       'save':True}\n",
    "\n",
    "model_config = OrderedDict([\n",
    "    ('arch', 'resnext'),\n",
    "    ('depth', args['depth']),\n",
    "    ('base_channels', args['base_channels']),\n",
    "    ('cardinality', args['cardinality']),\n",
    "    ('input_shape', (1, 3, 32, 32)),\n",
    "    ('output_dim', args['output_dim']),\n",
    "    ('num_demo_vars', args['num_demo_vars'])\n",
    "])\n",
    "\n",
    "optim_config = OrderedDict([\n",
    "    ('epochs', args['epochs']),\n",
    "    ('batch_size', args['batch_size']),\n",
    "    ('base_lr', args['base_lr']),\n",
    "    ('weight_decay', args['weight_decay']),\n",
    "    ('momentum', args['momentum']),\n",
    "    ('nesterov', args['nesterov']),\n",
    "    ('milestones', json.loads(args['milestones'])),\n",
    "    ('lr_decay', args['lr_decay']),\n",
    "])\n",
    "\n",
    "data_config = OrderedDict([\n",
    "    ('dataset', 'CIFAR10'),\n",
    "    ('image_size', args['image_size']),\n",
    "    ('demo_norm', args['demo_norm'])\n",
    "])\n",
    "\n",
    "run_config = OrderedDict([\n",
    "    ('seed', args['seed']),\n",
    "    ('outdir', args['outdir']),\n",
    "    ('save', args['save']),\n",
    "    ('num_workers', args['num_workers']),\n",
    "    ('tensorboard', args['tensorboard']),\n",
    "])\n",
    "\n",
    "config = OrderedDict([\n",
    "    ('model_config', model_config),\n",
    "    ('optim_config', optim_config),\n",
    "    ('data_config', data_config),\n",
    "    ('run_config', run_config),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse command line arguments\n",
    "#config = parse_args()\n",
    "#logger.info(json.dumps(config, indent=2))\n",
    "\n",
    "model_name = datetime.now().strftime(\"%m%d-%H%M\")\n",
    "\n",
    "run_config = config['run_config']\n",
    "optim_config = config['optim_config']\n",
    "\n",
    "# TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(model_name) if run_config['tensorboard'] else None\n",
    "\n",
    "# set random seed\n",
    "seed = run_config['seed']\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# create output directory\n",
    "outdir = run_config['outdir']\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# save config as json file in output directory\n",
    "outpath = os.path.join(outdir, 'config.json')\n",
    "with open(outpath, 'w') as fout:\n",
    "    json.dump(config, fout, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data loaders\n",
    "# train_loader, test_loader = get_loader(optim_config['batch_size'], run_config['num_workers'])\n",
    "train_loader, test_loader = image_loader(image_dir+zoomlevel+\"/\", data_dir, optim_config['batch_size'], \n",
    "                                         run_config['num_workers'], \n",
    "                                         data_config['image_size'], sampling=sampling, \n",
    "                                         recalculate_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.MSELoss(reduction='mean')\n",
    "criterion = my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/02/01 16:02:43 __main__ INFO] - n_params: 31961862\n",
      "[2022/02/01 16:04:08 __main__ INFO] - Epoch 0 Step 603/604 Train Loss 0.85085648\n",
      "[2022/02/01 16:04:13 __main__ INFO] - Epoch 0 Test Loss 0.75235411\n",
      "[2022/02/01 16:04:13 __main__ INFO] - Elapsed 4.45\n",
      "[2022/02/01 16:05:38 __main__ INFO] - Epoch 1 Step 603/604 Train Loss 0.76819638\n",
      "[2022/02/01 16:05:42 __main__ INFO] - Epoch 1 Test Loss 0.71209569\n",
      "[2022/02/01 16:05:42 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:07:08 __main__ INFO] - Epoch 2 Step 603/604 Train Loss 0.74185187\n",
      "[2022/02/01 16:07:12 __main__ INFO] - Epoch 2 Test Loss 0.69355645\n",
      "[2022/02/01 16:07:12 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 16:08:37 __main__ INFO] - Epoch 3 Step 603/604 Train Loss 0.72086907\n",
      "[2022/02/01 16:08:41 __main__ INFO] - Epoch 3 Test Loss 0.68010988\n",
      "[2022/02/01 16:08:41 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 16:10:07 __main__ INFO] - Epoch 4 Step 603/604 Train Loss 0.71043354\n",
      "[2022/02/01 16:10:11 __main__ INFO] - Epoch 4 Test Loss 0.66393446\n",
      "[2022/02/01 16:10:11 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 16:11:36 __main__ INFO] - Epoch 5 Step 603/604 Train Loss 0.69702632\n",
      "[2022/02/01 16:11:40 __main__ INFO] - Epoch 5 Test Loss 0.65701518\n",
      "[2022/02/01 16:11:40 __main__ INFO] - Elapsed 4.07\n",
      "[2022/02/01 16:13:06 __main__ INFO] - Epoch 6 Step 603/604 Train Loss 0.68566116\n",
      "[2022/02/01 16:13:10 __main__ INFO] - Epoch 6 Test Loss 0.65252158\n",
      "[2022/02/01 16:13:10 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 16:14:35 __main__ INFO] - Epoch 7 Step 603/604 Train Loss 0.67019485\n",
      "[2022/02/01 16:14:39 __main__ INFO] - Epoch 7 Test Loss 0.64848282\n",
      "[2022/02/01 16:14:39 __main__ INFO] - Elapsed 4.05\n",
      "[2022/02/01 16:16:05 __main__ INFO] - Epoch 8 Step 603/604 Train Loss 0.66165862\n",
      "[2022/02/01 16:16:09 __main__ INFO] - Epoch 8 Test Loss 0.64455021\n",
      "[2022/02/01 16:16:09 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 16:17:34 __main__ INFO] - Epoch 9 Step 603/604 Train Loss 0.64811050\n",
      "[2022/02/01 16:17:38 __main__ INFO] - Epoch 9 Test Loss 0.74051228\n",
      "[2022/02/01 16:17:38 __main__ INFO] - Elapsed 4.07\n",
      "[2022/02/01 16:19:04 __main__ INFO] - Epoch 10 Step 603/604 Train Loss 0.64063047\n",
      "[2022/02/01 16:19:08 __main__ INFO] - Epoch 10 Test Loss 0.64124845\n",
      "[2022/02/01 16:19:08 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:20:34 __main__ INFO] - Epoch 11 Step 603/604 Train Loss 0.62975175\n",
      "[2022/02/01 16:20:38 __main__ INFO] - Epoch 11 Test Loss 0.64372039\n",
      "[2022/02/01 16:20:38 __main__ INFO] - Elapsed 4.05\n",
      "[2022/02/01 16:22:03 __main__ INFO] - Epoch 12 Step 603/604 Train Loss 0.62175322\n",
      "[2022/02/01 16:22:07 __main__ INFO] - Epoch 12 Test Loss 0.63218168\n",
      "[2022/02/01 16:22:07 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 16:23:33 __main__ INFO] - Epoch 13 Step 603/604 Train Loss 0.60978861\n",
      "[2022/02/01 16:23:37 __main__ INFO] - Epoch 13 Test Loss 0.66451523\n",
      "[2022/02/01 16:23:37 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 16:25:02 __main__ INFO] - Epoch 14 Step 603/604 Train Loss 0.60552647\n",
      "[2022/02/01 16:25:06 __main__ INFO] - Epoch 14 Test Loss 0.63049208\n",
      "[2022/02/01 16:25:06 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 16:26:32 __main__ INFO] - Epoch 15 Step 603/604 Train Loss 0.59196728\n",
      "[2022/02/01 16:26:36 __main__ INFO] - Epoch 15 Test Loss 0.60908759\n",
      "[2022/02/01 16:26:36 __main__ INFO] - Elapsed 4.15\n",
      "[2022/02/01 16:28:01 __main__ INFO] - Epoch 16 Step 603/604 Train Loss 0.58478797\n",
      "[2022/02/01 16:28:06 __main__ INFO] - Epoch 16 Test Loss 0.59306258\n",
      "[2022/02/01 16:28:06 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 16:29:31 __main__ INFO] - Epoch 17 Step 603/604 Train Loss 0.58047626\n",
      "[2022/02/01 16:29:35 __main__ INFO] - Epoch 17 Test Loss 0.60184396\n",
      "[2022/02/01 16:29:35 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 16:31:00 __main__ INFO] - Epoch 18 Step 603/604 Train Loss 0.57093896\n",
      "[2022/02/01 16:31:05 __main__ INFO] - Epoch 18 Test Loss 0.61278833\n",
      "[2022/02/01 16:31:05 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:32:30 __main__ INFO] - Epoch 19 Step 603/604 Train Loss 0.56436631\n",
      "[2022/02/01 16:32:34 __main__ INFO] - Epoch 19 Test Loss 0.57847850\n",
      "[2022/02/01 16:32:34 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 16:33:59 __main__ INFO] - Epoch 20 Step 603/604 Train Loss 0.55771342\n",
      "[2022/02/01 16:34:04 __main__ INFO] - Epoch 20 Test Loss 0.65327738\n",
      "[2022/02/01 16:34:04 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:35:29 __main__ INFO] - Epoch 21 Step 603/604 Train Loss 0.54833507\n",
      "[2022/02/01 16:35:33 __main__ INFO] - Epoch 21 Test Loss 0.58367164\n",
      "[2022/02/01 16:35:33 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:36:59 __main__ INFO] - Epoch 22 Step 603/604 Train Loss 0.54077383\n",
      "[2022/02/01 16:37:03 __main__ INFO] - Epoch 22 Test Loss 0.57436704\n",
      "[2022/02/01 16:37:03 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 16:38:28 __main__ INFO] - Epoch 23 Step 603/604 Train Loss 0.53313692\n",
      "[2022/02/01 16:38:32 __main__ INFO] - Epoch 23 Test Loss 0.57518518\n",
      "[2022/02/01 16:38:32 __main__ INFO] - Elapsed 4.14\n",
      "[2022/02/01 16:39:58 __main__ INFO] - Epoch 24 Step 603/604 Train Loss 0.52968121\n",
      "[2022/02/01 16:40:02 __main__ INFO] - Epoch 24 Test Loss 0.58009364\n",
      "[2022/02/01 16:40:02 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:41:27 __main__ INFO] - Epoch 25 Step 603/604 Train Loss 0.52028609\n",
      "[2022/02/01 16:41:32 __main__ INFO] - Epoch 25 Test Loss 0.57809203\n",
      "[2022/02/01 16:41:32 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 16:42:57 __main__ INFO] - Epoch 26 Step 603/604 Train Loss 0.51493312\n",
      "[2022/02/01 16:43:01 __main__ INFO] - Epoch 26 Test Loss 0.57071096\n",
      "[2022/02/01 16:43:02 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 16:44:27 __main__ INFO] - Epoch 27 Step 603/604 Train Loss 0.51323754\n",
      "[2022/02/01 16:44:31 __main__ INFO] - Epoch 27 Test Loss 0.56752129\n",
      "[2022/02/01 16:44:31 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:45:56 __main__ INFO] - Epoch 28 Step 603/604 Train Loss 0.50765286\n",
      "[2022/02/01 16:46:01 __main__ INFO] - Epoch 28 Test Loss 0.56889799\n",
      "[2022/02/01 16:46:01 __main__ INFO] - Elapsed 4.15\n",
      "[2022/02/01 16:47:26 __main__ INFO] - Epoch 29 Step 603/604 Train Loss 0.50215024\n",
      "[2022/02/01 16:47:30 __main__ INFO] - Epoch 29 Test Loss 0.55408588\n",
      "[2022/02/01 16:47:30 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 16:48:55 __main__ INFO] - Epoch 30 Step 603/604 Train Loss 0.49874121\n",
      "[2022/02/01 16:48:59 __main__ INFO] - Epoch 30 Test Loss 0.55322592\n",
      "[2022/02/01 16:48:59 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 16:50:25 __main__ INFO] - Epoch 31 Step 603/604 Train Loss 0.49331383\n",
      "[2022/02/01 16:50:29 __main__ INFO] - Epoch 31 Test Loss 0.55517042\n",
      "[2022/02/01 16:50:29 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 16:51:55 __main__ INFO] - Epoch 32 Step 603/604 Train Loss 0.48867037\n",
      "[2022/02/01 16:51:59 __main__ INFO] - Epoch 32 Test Loss 0.56747190\n",
      "[2022/02/01 16:51:59 __main__ INFO] - Elapsed 4.14\n",
      "[2022/02/01 16:53:24 __main__ INFO] - Epoch 33 Step 603/604 Train Loss 0.48255354\n",
      "[2022/02/01 16:53:28 __main__ INFO] - Epoch 33 Test Loss 0.57027155\n",
      "[2022/02/01 16:53:28 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 16:54:54 __main__ INFO] - Epoch 34 Step 603/604 Train Loss 0.47673984\n",
      "[2022/02/01 16:54:58 __main__ INFO] - Epoch 34 Test Loss 0.55005785\n",
      "[2022/02/01 16:54:58 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 16:56:23 __main__ INFO] - Epoch 35 Step 603/604 Train Loss 0.47163167\n",
      "[2022/02/01 16:56:28 __main__ INFO] - Epoch 35 Test Loss 0.54260482\n",
      "[2022/02/01 16:56:28 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 16:57:53 __main__ INFO] - Epoch 36 Step 603/604 Train Loss 0.46979364\n",
      "[2022/02/01 16:57:57 __main__ INFO] - Epoch 36 Test Loss 0.54943680\n",
      "[2022/02/01 16:57:57 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 16:59:23 __main__ INFO] - Epoch 37 Step 603/604 Train Loss 0.46613724\n",
      "[2022/02/01 16:59:27 __main__ INFO] - Epoch 37 Test Loss 0.56104357\n",
      "[2022/02/01 16:59:27 __main__ INFO] - Elapsed 4.07\n",
      "[2022/02/01 17:00:52 __main__ INFO] - Epoch 38 Step 603/604 Train Loss 0.46339471\n",
      "[2022/02/01 17:00:56 __main__ INFO] - Epoch 38 Test Loss 0.54985630\n",
      "[2022/02/01 17:00:56 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 17:02:22 __main__ INFO] - Epoch 39 Step 603/604 Train Loss 0.45806620\n",
      "[2022/02/01 17:02:26 __main__ INFO] - Epoch 39 Test Loss 0.53572195\n",
      "[2022/02/01 17:02:26 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:03:51 __main__ INFO] - Epoch 40 Step 603/604 Train Loss 0.45271786\n",
      "[2022/02/01 17:03:55 __main__ INFO] - Epoch 40 Test Loss 0.54099423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/02/01 17:03:55 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 17:05:21 __main__ INFO] - Epoch 41 Step 603/604 Train Loss 0.45228433\n",
      "[2022/02/01 17:05:25 __main__ INFO] - Epoch 41 Test Loss 0.54598538\n",
      "[2022/02/01 17:05:25 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 17:06:51 __main__ INFO] - Epoch 42 Step 603/604 Train Loss 0.44457460\n",
      "[2022/02/01 17:06:55 __main__ INFO] - Epoch 42 Test Loss 0.55876570\n",
      "[2022/02/01 17:06:55 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 17:08:20 __main__ INFO] - Epoch 43 Step 603/604 Train Loss 0.44322673\n",
      "[2022/02/01 17:08:24 __main__ INFO] - Epoch 43 Test Loss 0.54128374\n",
      "[2022/02/01 17:08:24 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:09:50 __main__ INFO] - Epoch 44 Step 603/604 Train Loss 0.43888614\n",
      "[2022/02/01 17:09:54 __main__ INFO] - Epoch 44 Test Loss 0.55531756\n",
      "[2022/02/01 17:09:54 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 17:11:19 __main__ INFO] - Epoch 45 Step 603/604 Train Loss 0.43842999\n",
      "[2022/02/01 17:11:23 __main__ INFO] - Epoch 45 Test Loss 0.53414555\n",
      "[2022/02/01 17:11:23 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 17:12:49 __main__ INFO] - Epoch 46 Step 603/604 Train Loss 0.43450316\n",
      "[2022/02/01 17:12:53 __main__ INFO] - Epoch 46 Test Loss 0.53760817\n",
      "[2022/02/01 17:12:53 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 17:14:19 __main__ INFO] - Epoch 47 Step 603/604 Train Loss 0.43085540\n",
      "[2022/02/01 17:14:23 __main__ INFO] - Epoch 47 Test Loss 0.53289905\n",
      "[2022/02/01 17:14:23 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:15:48 __main__ INFO] - Epoch 48 Step 603/604 Train Loss 0.42935380\n",
      "[2022/02/01 17:15:52 __main__ INFO] - Epoch 48 Test Loss 0.53652503\n",
      "[2022/02/01 17:15:52 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:17:18 __main__ INFO] - Epoch 49 Step 603/604 Train Loss 0.42852540\n",
      "[2022/02/01 17:17:22 __main__ INFO] - Epoch 49 Test Loss 0.53493340\n",
      "[2022/02/01 17:17:22 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 17:18:47 __main__ INFO] - Epoch 50 Step 603/604 Train Loss 0.42413370\n",
      "[2022/02/01 17:18:51 __main__ INFO] - Epoch 50 Test Loss 0.52914304\n",
      "[2022/02/01 17:18:51 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:20:17 __main__ INFO] - Epoch 51 Step 603/604 Train Loss 0.42299736\n",
      "[2022/02/01 17:20:21 __main__ INFO] - Epoch 51 Test Loss 0.53957603\n",
      "[2022/02/01 17:20:21 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:21:47 __main__ INFO] - Epoch 52 Step 603/604 Train Loss 0.42114320\n",
      "[2022/02/01 17:21:51 __main__ INFO] - Epoch 52 Test Loss 0.53048541\n",
      "[2022/02/01 17:21:51 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:23:16 __main__ INFO] - Epoch 53 Step 603/604 Train Loss 0.41948987\n",
      "[2022/02/01 17:23:20 __main__ INFO] - Epoch 53 Test Loss 0.53862051\n",
      "[2022/02/01 17:23:20 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 17:24:46 __main__ INFO] - Epoch 54 Step 603/604 Train Loss 0.41534623\n",
      "[2022/02/01 17:24:50 __main__ INFO] - Epoch 54 Test Loss 0.52979920\n",
      "[2022/02/01 17:24:50 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:26:15 __main__ INFO] - Epoch 55 Step 603/604 Train Loss 0.41300533\n",
      "[2022/02/01 17:26:20 __main__ INFO] - Epoch 55 Test Loss 0.53000057\n",
      "[2022/02/01 17:26:20 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 17:27:45 __main__ INFO] - Epoch 56 Step 603/604 Train Loss 0.41145769\n",
      "[2022/02/01 17:27:49 __main__ INFO] - Epoch 56 Test Loss 0.52498986\n",
      "[2022/02/01 17:27:49 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 17:29:15 __main__ INFO] - Epoch 57 Step 603/604 Train Loss 0.40927324\n",
      "[2022/02/01 17:29:19 __main__ INFO] - Epoch 57 Test Loss 0.52142764\n",
      "[2022/02/01 17:29:19 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 17:30:44 __main__ INFO] - Epoch 58 Step 603/604 Train Loss 0.40664940\n",
      "[2022/02/01 17:30:48 __main__ INFO] - Epoch 58 Test Loss 0.52276353\n",
      "[2022/02/01 17:30:48 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:32:14 __main__ INFO] - Epoch 59 Step 603/604 Train Loss 0.40350649\n",
      "[2022/02/01 17:32:18 __main__ INFO] - Epoch 59 Test Loss 0.52750361\n",
      "[2022/02/01 17:32:18 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:33:43 __main__ INFO] - Epoch 60 Step 603/604 Train Loss 0.40118332\n",
      "[2022/02/01 17:33:47 __main__ INFO] - Epoch 60 Test Loss 0.52272738\n",
      "[2022/02/01 17:33:47 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 17:35:13 __main__ INFO] - Epoch 61 Step 603/604 Train Loss 0.39975331\n",
      "[2022/02/01 17:35:17 __main__ INFO] - Epoch 61 Test Loss 0.51817957\n",
      "[2022/02/01 17:35:17 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:36:43 __main__ INFO] - Epoch 62 Step 603/604 Train Loss 0.40062063\n",
      "[2022/02/01 17:36:47 __main__ INFO] - Epoch 62 Test Loss 0.53416295\n",
      "[2022/02/01 17:36:47 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:38:12 __main__ INFO] - Epoch 63 Step 603/604 Train Loss 0.39706521\n",
      "[2022/02/01 17:38:16 __main__ INFO] - Epoch 63 Test Loss 0.52230484\n",
      "[2022/02/01 17:38:16 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:39:42 __main__ INFO] - Epoch 64 Step 603/604 Train Loss 0.39507107\n",
      "[2022/02/01 17:39:46 __main__ INFO] - Epoch 64 Test Loss 0.51410398\n",
      "[2022/02/01 17:39:46 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:41:11 __main__ INFO] - Epoch 65 Step 603/604 Train Loss 0.39379010\n",
      "[2022/02/01 17:41:15 __main__ INFO] - Epoch 65 Test Loss 0.52063932\n",
      "[2022/02/01 17:41:15 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:42:41 __main__ INFO] - Epoch 66 Step 603/604 Train Loss 0.38971792\n",
      "[2022/02/01 17:42:45 __main__ INFO] - Epoch 66 Test Loss 0.52268676\n",
      "[2022/02/01 17:42:45 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 17:44:11 __main__ INFO] - Epoch 67 Step 603/604 Train Loss 0.39005951\n",
      "[2022/02/01 17:44:15 __main__ INFO] - Epoch 67 Test Loss 0.51498717\n",
      "[2022/02/01 17:44:15 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 17:45:40 __main__ INFO] - Epoch 68 Step 603/604 Train Loss 0.38776724\n",
      "[2022/02/01 17:45:44 __main__ INFO] - Epoch 68 Test Loss 0.52086745\n",
      "[2022/02/01 17:45:44 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 17:47:10 __main__ INFO] - Epoch 69 Step 603/604 Train Loss 0.38447254\n",
      "[2022/02/01 17:47:14 __main__ INFO] - Epoch 69 Test Loss 0.51471683\n",
      "[2022/02/01 17:47:14 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 17:48:39 __main__ INFO] - Epoch 70 Step 603/604 Train Loss 0.38445141\n",
      "[2022/02/01 17:48:43 __main__ INFO] - Epoch 70 Test Loss 0.51657854\n",
      "[2022/02/01 17:48:43 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 17:50:09 __main__ INFO] - Epoch 71 Step 603/604 Train Loss 0.38258015\n",
      "[2022/02/01 17:50:13 __main__ INFO] - Epoch 71 Test Loss 0.51377841\n",
      "[2022/02/01 17:50:13 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 17:51:39 __main__ INFO] - Epoch 72 Step 603/604 Train Loss 0.38260492\n",
      "[2022/02/01 17:51:43 __main__ INFO] - Epoch 72 Test Loss 0.50835083\n",
      "[2022/02/01 17:51:43 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 17:53:08 __main__ INFO] - Epoch 73 Step 603/604 Train Loss 0.37897531\n",
      "[2022/02/01 17:53:12 __main__ INFO] - Epoch 73 Test Loss 0.51084253\n",
      "[2022/02/01 17:53:12 __main__ INFO] - Elapsed 4.14\n",
      "[2022/02/01 17:54:38 __main__ INFO] - Epoch 74 Step 603/604 Train Loss 0.37675192\n",
      "[2022/02/01 17:54:42 __main__ INFO] - Epoch 74 Test Loss 0.50799831\n",
      "[2022/02/01 17:54:42 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:56:07 __main__ INFO] - Epoch 75 Step 603/604 Train Loss 0.37461144\n",
      "[2022/02/01 17:56:11 __main__ INFO] - Epoch 75 Test Loss 0.51005805\n",
      "[2022/02/01 17:56:11 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 17:57:37 __main__ INFO] - Epoch 76 Step 603/604 Train Loss 0.37366505\n",
      "[2022/02/01 17:57:41 __main__ INFO] - Epoch 76 Test Loss 0.50865308\n",
      "[2022/02/01 17:57:41 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 17:59:07 __main__ INFO] - Epoch 77 Step 603/604 Train Loss 0.37297819\n",
      "[2022/02/01 17:59:11 __main__ INFO] - Epoch 77 Test Loss 0.51056197\n",
      "[2022/02/01 17:59:11 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 18:00:36 __main__ INFO] - Epoch 78 Step 603/604 Train Loss 0.36916068\n",
      "[2022/02/01 18:00:40 __main__ INFO] - Epoch 78 Test Loss 0.52890042\n",
      "[2022/02/01 18:00:40 __main__ INFO] - Elapsed 4.14\n",
      "[2022/02/01 18:02:06 __main__ INFO] - Epoch 79 Step 603/604 Train Loss 0.36902485\n",
      "[2022/02/01 18:02:10 __main__ INFO] - Epoch 79 Test Loss 0.51042782\n",
      "[2022/02/01 18:02:10 __main__ INFO] - Elapsed 4.07\n",
      "[2022/02/01 18:03:35 __main__ INFO] - Epoch 80 Step 603/604 Train Loss 0.36710314\n",
      "[2022/02/01 18:03:39 __main__ INFO] - Epoch 80 Test Loss 0.50701498\n",
      "[2022/02/01 18:03:39 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 18:05:05 __main__ INFO] - Epoch 81 Step 603/604 Train Loss 0.36786132\n",
      "[2022/02/01 18:05:09 __main__ INFO] - Epoch 81 Test Loss 0.50627377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/02/01 18:05:09 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 18:06:35 __main__ INFO] - Epoch 82 Step 603/604 Train Loss 0.36675891\n",
      "[2022/02/01 18:06:39 __main__ INFO] - Epoch 82 Test Loss 0.50107226\n",
      "[2022/02/01 18:06:39 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:08:04 __main__ INFO] - Epoch 83 Step 603/604 Train Loss 0.36521679\n",
      "[2022/02/01 18:08:08 __main__ INFO] - Epoch 83 Test Loss 0.51445395\n",
      "[2022/02/01 18:08:08 __main__ INFO] - Elapsed 4.07\n",
      "[2022/02/01 18:09:34 __main__ INFO] - Epoch 84 Step 603/604 Train Loss 0.36300899\n",
      "[2022/02/01 18:09:38 __main__ INFO] - Epoch 84 Test Loss 0.50478182\n",
      "[2022/02/01 18:09:38 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:11:03 __main__ INFO] - Epoch 85 Step 603/604 Train Loss 0.36105962\n",
      "[2022/02/01 18:11:07 __main__ INFO] - Epoch 85 Test Loss 0.49882293\n",
      "[2022/02/01 18:11:07 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 18:12:33 __main__ INFO] - Epoch 86 Step 603/604 Train Loss 0.36135683\n",
      "[2022/02/01 18:12:37 __main__ INFO] - Epoch 86 Test Loss 0.49814488\n",
      "[2022/02/01 18:12:37 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 18:14:03 __main__ INFO] - Epoch 87 Step 603/604 Train Loss 0.35945894\n",
      "[2022/02/01 18:14:07 __main__ INFO] - Epoch 87 Test Loss 0.50475990\n",
      "[2022/02/01 18:14:07 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:15:32 __main__ INFO] - Epoch 88 Step 603/604 Train Loss 0.36020681\n",
      "[2022/02/01 18:15:36 __main__ INFO] - Epoch 88 Test Loss 0.51874506\n",
      "[2022/02/01 18:15:36 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 18:17:02 __main__ INFO] - Epoch 89 Step 603/604 Train Loss 0.35837956\n",
      "[2022/02/01 18:17:06 __main__ INFO] - Epoch 89 Test Loss 0.50039604\n",
      "[2022/02/01 18:17:06 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 18:18:31 __main__ INFO] - Epoch 90 Step 603/604 Train Loss 0.35471633\n",
      "[2022/02/01 18:18:35 __main__ INFO] - Epoch 90 Test Loss 0.49400217\n",
      "[2022/02/01 18:18:35 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:20:01 __main__ INFO] - Epoch 91 Step 603/604 Train Loss 0.35341295\n",
      "[2022/02/01 18:20:05 __main__ INFO] - Epoch 91 Test Loss 0.49572496\n",
      "[2022/02/01 18:20:05 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:21:31 __main__ INFO] - Epoch 92 Step 603/604 Train Loss 0.35151390\n",
      "[2022/02/01 18:21:35 __main__ INFO] - Epoch 92 Test Loss 0.49931899\n",
      "[2022/02/01 18:21:35 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:23:00 __main__ INFO] - Epoch 93 Step 603/604 Train Loss 0.35148527\n",
      "[2022/02/01 18:23:04 __main__ INFO] - Epoch 93 Test Loss 0.51271508\n",
      "[2022/02/01 18:23:04 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:24:30 __main__ INFO] - Epoch 94 Step 603/604 Train Loss 0.34850321\n",
      "[2022/02/01 18:24:34 __main__ INFO] - Epoch 94 Test Loss 0.49139482\n",
      "[2022/02/01 18:24:34 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:25:59 __main__ INFO] - Epoch 95 Step 603/604 Train Loss 0.34535859\n",
      "[2022/02/01 18:26:03 __main__ INFO] - Epoch 95 Test Loss 0.50027072\n",
      "[2022/02/01 18:26:03 __main__ INFO] - Elapsed 4.14\n",
      "[2022/02/01 18:27:29 __main__ INFO] - Epoch 96 Step 603/604 Train Loss 0.34735863\n",
      "[2022/02/01 18:27:33 __main__ INFO] - Epoch 96 Test Loss 0.49723345\n",
      "[2022/02/01 18:27:33 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:28:59 __main__ INFO] - Epoch 97 Step 603/604 Train Loss 0.34587564\n",
      "[2022/02/01 18:29:03 __main__ INFO] - Epoch 97 Test Loss 0.49336396\n",
      "[2022/02/01 18:29:03 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:30:28 __main__ INFO] - Epoch 98 Step 603/604 Train Loss 0.34582695\n",
      "[2022/02/01 18:30:32 __main__ INFO] - Epoch 98 Test Loss 0.51036143\n",
      "[2022/02/01 18:30:32 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 18:31:58 __main__ INFO] - Epoch 99 Step 603/604 Train Loss 0.34592794\n",
      "[2022/02/01 18:32:02 __main__ INFO] - Epoch 99 Test Loss 0.49143463\n",
      "[2022/02/01 18:32:02 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 18:33:27 __main__ INFO] - Epoch 100 Step 603/604 Train Loss 0.34484336\n",
      "[2022/02/01 18:33:32 __main__ INFO] - Epoch 100 Test Loss 0.49596873\n",
      "[2022/02/01 18:33:32 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 18:34:57 __main__ INFO] - Epoch 101 Step 603/604 Train Loss 0.34094759\n",
      "[2022/02/01 18:35:01 __main__ INFO] - Epoch 101 Test Loss 0.49785404\n",
      "[2022/02/01 18:35:01 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:36:27 __main__ INFO] - Epoch 102 Step 603/604 Train Loss 0.33941531\n",
      "[2022/02/01 18:36:31 __main__ INFO] - Epoch 102 Test Loss 0.49592394\n",
      "[2022/02/01 18:36:31 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:37:57 __main__ INFO] - Epoch 103 Step 603/604 Train Loss 0.34019044\n",
      "[2022/02/01 18:38:01 __main__ INFO] - Epoch 103 Test Loss 0.49615605\n",
      "[2022/02/01 18:38:01 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:39:26 __main__ INFO] - Epoch 104 Step 603/604 Train Loss 0.33987476\n",
      "[2022/02/01 18:39:30 __main__ INFO] - Epoch 104 Test Loss 0.48997993\n",
      "[2022/02/01 18:39:30 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 18:40:55 __main__ INFO] - Epoch 105 Step 603/604 Train Loss 0.33766415\n",
      "[2022/02/01 18:41:00 __main__ INFO] - Epoch 105 Test Loss 0.48716287\n",
      "[2022/02/01 18:41:00 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:42:25 __main__ INFO] - Epoch 106 Step 603/604 Train Loss 0.33458817\n",
      "[2022/02/01 18:42:29 __main__ INFO] - Epoch 106 Test Loss 0.50184663\n",
      "[2022/02/01 18:42:29 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:43:55 __main__ INFO] - Epoch 107 Step 603/604 Train Loss 0.33511979\n",
      "[2022/02/01 18:43:59 __main__ INFO] - Epoch 107 Test Loss 0.48677506\n",
      "[2022/02/01 18:43:59 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 18:45:24 __main__ INFO] - Epoch 108 Step 603/604 Train Loss 0.33596657\n",
      "[2022/02/01 18:45:29 __main__ INFO] - Epoch 108 Test Loss 0.48737537\n",
      "[2022/02/01 18:45:29 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 18:46:54 __main__ INFO] - Epoch 109 Step 603/604 Train Loss 0.33339005\n",
      "[2022/02/01 18:46:58 __main__ INFO] - Epoch 109 Test Loss 0.49317412\n",
      "[2022/02/01 18:46:58 __main__ INFO] - Elapsed 4.07\n",
      "[2022/02/01 18:48:23 __main__ INFO] - Epoch 110 Step 603/604 Train Loss 0.33016791\n",
      "[2022/02/01 18:48:28 __main__ INFO] - Epoch 110 Test Loss 0.49101296\n",
      "[2022/02/01 18:48:28 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 18:49:53 __main__ INFO] - Epoch 111 Step 603/604 Train Loss 0.33198703\n",
      "[2022/02/01 18:49:58 __main__ INFO] - Epoch 111 Test Loss 0.48927818\n",
      "[2022/02/01 18:49:58 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 18:51:23 __main__ INFO] - Epoch 112 Step 603/604 Train Loss 0.33026263\n",
      "[2022/02/01 18:51:27 __main__ INFO] - Epoch 112 Test Loss 0.48163631\n",
      "[2022/02/01 18:51:27 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 18:52:52 __main__ INFO] - Epoch 113 Step 603/604 Train Loss 0.33045914\n",
      "[2022/02/01 18:52:56 __main__ INFO] - Epoch 113 Test Loss 0.49689129\n",
      "[2022/02/01 18:52:56 __main__ INFO] - Elapsed 4.14\n",
      "[2022/02/01 18:54:22 __main__ INFO] - Epoch 114 Step 603/604 Train Loss 0.32866534\n",
      "[2022/02/01 18:54:26 __main__ INFO] - Epoch 114 Test Loss 0.48647514\n",
      "[2022/02/01 18:54:26 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:55:51 __main__ INFO] - Epoch 115 Step 603/604 Train Loss 0.32860300\n",
      "[2022/02/01 18:55:55 __main__ INFO] - Epoch 115 Test Loss 0.48525415\n",
      "[2022/02/01 18:55:55 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:57:21 __main__ INFO] - Epoch 116 Step 603/604 Train Loss 0.32712147\n",
      "[2022/02/01 18:57:25 __main__ INFO] - Epoch 116 Test Loss 0.48562279\n",
      "[2022/02/01 18:57:25 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 18:58:51 __main__ INFO] - Epoch 117 Step 603/604 Train Loss 0.32651527\n",
      "[2022/02/01 18:58:55 __main__ INFO] - Epoch 117 Test Loss 0.48955777\n",
      "[2022/02/01 18:58:55 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:00:20 __main__ INFO] - Epoch 118 Step 603/604 Train Loss 0.32557185\n",
      "[2022/02/01 19:00:24 __main__ INFO] - Epoch 118 Test Loss 0.49276303\n",
      "[2022/02/01 19:00:24 __main__ INFO] - Elapsed 4.15\n",
      "[2022/02/01 19:01:50 __main__ INFO] - Epoch 119 Step 603/604 Train Loss 0.32092876\n",
      "[2022/02/01 19:01:54 __main__ INFO] - Epoch 119 Test Loss 0.47779064\n",
      "[2022/02/01 19:01:54 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 19:03:19 __main__ INFO] - Epoch 120 Step 603/604 Train Loss 0.32180514\n",
      "[2022/02/01 19:03:24 __main__ INFO] - Epoch 120 Test Loss 0.48085910\n",
      "[2022/02/01 19:03:24 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:04:49 __main__ INFO] - Epoch 121 Step 603/604 Train Loss 0.31958702\n",
      "[2022/02/01 19:04:53 __main__ INFO] - Epoch 121 Test Loss 0.47793957\n",
      "[2022/02/01 19:04:53 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 19:06:19 __main__ INFO] - Epoch 122 Step 603/604 Train Loss 0.31925106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022/02/01 19:06:23 __main__ INFO] - Epoch 122 Test Loss 0.48479881\n",
      "[2022/02/01 19:06:23 __main__ INFO] - Elapsed 4.07\n",
      "[2022/02/01 19:07:48 __main__ INFO] - Epoch 123 Step 603/604 Train Loss 0.31728988\n",
      "[2022/02/01 19:07:52 __main__ INFO] - Epoch 123 Test Loss 0.50357324\n",
      "[2022/02/01 19:07:52 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 19:09:18 __main__ INFO] - Epoch 124 Step 603/604 Train Loss 0.31880784\n",
      "[2022/02/01 19:09:22 __main__ INFO] - Epoch 124 Test Loss 0.47958803\n",
      "[2022/02/01 19:09:22 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 19:10:47 __main__ INFO] - Epoch 125 Step 603/604 Train Loss 0.31661012\n",
      "[2022/02/01 19:10:52 __main__ INFO] - Epoch 125 Test Loss 0.47441961\n",
      "[2022/02/01 19:10:52 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:12:17 __main__ INFO] - Epoch 126 Step 603/604 Train Loss 0.31552783\n",
      "[2022/02/01 19:12:21 __main__ INFO] - Epoch 126 Test Loss 0.47763879\n",
      "[2022/02/01 19:12:21 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 19:13:47 __main__ INFO] - Epoch 127 Step 603/604 Train Loss 0.31323477\n",
      "[2022/02/01 19:13:51 __main__ INFO] - Epoch 127 Test Loss 0.48572323\n",
      "[2022/02/01 19:13:51 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:15:16 __main__ INFO] - Epoch 128 Step 603/604 Train Loss 0.31391836\n",
      "[2022/02/01 19:15:20 __main__ INFO] - Epoch 128 Test Loss 0.47923114\n",
      "[2022/02/01 19:15:20 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 19:16:46 __main__ INFO] - Epoch 129 Step 603/604 Train Loss 0.31392165\n",
      "[2022/02/01 19:16:50 __main__ INFO] - Epoch 129 Test Loss 0.48023978\n",
      "[2022/02/01 19:16:50 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:18:15 __main__ INFO] - Epoch 130 Step 603/604 Train Loss 0.31384963\n",
      "[2022/02/01 19:18:20 __main__ INFO] - Epoch 130 Test Loss 0.47660071\n",
      "[2022/02/01 19:18:20 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:19:45 __main__ INFO] - Epoch 131 Step 603/604 Train Loss 0.31225704\n",
      "[2022/02/01 19:19:50 __main__ INFO] - Epoch 131 Test Loss 0.47082911\n",
      "[2022/02/01 19:19:50 __main__ INFO] - Elapsed 4.14\n",
      "[2022/02/01 19:21:15 __main__ INFO] - Epoch 132 Step 603/604 Train Loss 0.31467686\n",
      "[2022/02/01 19:21:19 __main__ INFO] - Epoch 132 Test Loss 0.47908261\n",
      "[2022/02/01 19:21:19 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:22:44 __main__ INFO] - Epoch 133 Step 603/604 Train Loss 0.31479816\n",
      "[2022/02/01 19:22:49 __main__ INFO] - Epoch 133 Test Loss 0.47557957\n",
      "[2022/02/01 19:22:49 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 19:24:14 __main__ INFO] - Epoch 134 Step 603/604 Train Loss 0.31103416\n",
      "[2022/02/01 19:24:18 __main__ INFO] - Epoch 134 Test Loss 0.47568670\n",
      "[2022/02/01 19:24:18 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:25:43 __main__ INFO] - Epoch 135 Step 603/604 Train Loss 0.30976205\n",
      "[2022/02/01 19:25:48 __main__ INFO] - Epoch 135 Test Loss 0.47120722\n",
      "[2022/02/01 19:25:48 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 19:27:13 __main__ INFO] - Epoch 136 Step 603/604 Train Loss 0.30779623\n",
      "[2022/02/01 19:27:18 __main__ INFO] - Epoch 136 Test Loss 0.48436945\n",
      "[2022/02/01 19:27:18 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 19:28:43 __main__ INFO] - Epoch 137 Step 603/604 Train Loss 0.30869830\n",
      "[2022/02/01 19:28:47 __main__ INFO] - Epoch 137 Test Loss 0.47912067\n",
      "[2022/02/01 19:28:47 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 19:30:13 __main__ INFO] - Epoch 138 Step 603/604 Train Loss 0.30732238\n",
      "[2022/02/01 19:30:17 __main__ INFO] - Epoch 138 Test Loss 0.46158252\n",
      "[2022/02/01 19:30:17 __main__ INFO] - Elapsed 4.12\n",
      "[2022/02/01 19:31:42 __main__ INFO] - Epoch 139 Step 603/604 Train Loss 0.30615892\n",
      "[2022/02/01 19:31:46 __main__ INFO] - Epoch 139 Test Loss 0.46229871\n",
      "[2022/02/01 19:31:46 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:33:12 __main__ INFO] - Epoch 140 Step 603/604 Train Loss 0.30489363\n",
      "[2022/02/01 19:33:16 __main__ INFO] - Epoch 140 Test Loss 0.46887023\n",
      "[2022/02/01 19:33:16 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 19:34:41 __main__ INFO] - Epoch 141 Step 603/604 Train Loss 0.30420775\n",
      "[2022/02/01 19:34:46 __main__ INFO] - Epoch 141 Test Loss 0.47436516\n",
      "[2022/02/01 19:34:46 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 19:36:11 __main__ INFO] - Epoch 142 Step 603/604 Train Loss 0.30256357\n",
      "[2022/02/01 19:36:15 __main__ INFO] - Epoch 142 Test Loss 0.46130528\n",
      "[2022/02/01 19:36:15 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 19:37:40 __main__ INFO] - Epoch 143 Step 603/604 Train Loss 0.30177595\n",
      "[2022/02/01 19:37:45 __main__ INFO] - Epoch 143 Test Loss 0.46876295\n",
      "[2022/02/01 19:37:45 __main__ INFO] - Elapsed 4.09\n",
      "[2022/02/01 19:39:10 __main__ INFO] - Epoch 144 Step 603/604 Train Loss 0.30130637\n",
      "[2022/02/01 19:39:14 __main__ INFO] - Epoch 144 Test Loss 0.45680377\n",
      "[2022/02/01 19:39:14 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 19:40:40 __main__ INFO] - Epoch 145 Step 603/604 Train Loss 0.29872622\n",
      "[2022/02/01 19:40:44 __main__ INFO] - Epoch 145 Test Loss 0.46224157\n",
      "[2022/02/01 19:40:44 __main__ INFO] - Elapsed 4.11\n",
      "[2022/02/01 19:42:09 __main__ INFO] - Epoch 146 Step 603/604 Train Loss 0.35589658\n",
      "[2022/02/01 19:42:14 __main__ INFO] - Epoch 146 Test Loss 0.63846451\n",
      "[2022/02/01 19:42:14 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:43:39 __main__ INFO] - Epoch 147 Step 603/604 Train Loss 0.45289927\n",
      "[2022/02/01 19:43:43 __main__ INFO] - Epoch 147 Test Loss 0.50029881\n",
      "[2022/02/01 19:43:43 __main__ INFO] - Elapsed 4.10\n",
      "[2022/02/01 19:45:08 __main__ INFO] - Epoch 148 Step 603/604 Train Loss 0.39573168\n",
      "[2022/02/01 19:45:13 __main__ INFO] - Epoch 148 Test Loss 0.49009578\n",
      "[2022/02/01 19:45:13 __main__ INFO] - Elapsed 4.13\n",
      "[2022/02/01 19:46:38 __main__ INFO] - Epoch 149 Step 603/604 Train Loss 0.34644602\n",
      "[2022/02/01 19:46:42 __main__ INFO] - Epoch 149 Test Loss 0.46220931\n",
      "[2022/02/01 19:46:42 __main__ INFO] - Elapsed 4.08\n",
      "[2022/02/01 19:48:08 __main__ INFO] - Epoch 150 Step 603/604 Train Loss 0.31376744\n",
      "[2022/02/01 19:48:12 __main__ INFO] - Epoch 150 Test Loss 0.43936857\n",
      "[2022/02/01 19:48:12 __main__ INFO] - Elapsed 4.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diverging. stop.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "config['model_config']['input_shape'] = (1,3,data_config['image_size'],data_config['image_size'])\n",
    "\n",
    "encoder = load_model(config['model_config']['arch'], 'Encoder', config['model_config'])\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "config['model_config']['input_shape'] = [1,2048,config['model_config']['output_dim'],config['model_config']['output_dim']]\n",
    "\n",
    "config['model_config']['conv_shape'] = [data_config['image_size']//32,data_config['image_size']//32]\n",
    "config['model_config']['output_channels'] = 3\n",
    "\n",
    "decoder = load_model(config['model_config']['arch'], 'Decoder', config['model_config'])\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "config['encoder'] = encoder\n",
    "config['decoder'] = decoder\n",
    "model = load_model('autoencoder','Autoencoder', config)\n",
    "model = model.to(device)\n",
    "\n",
    "n_params = sum([param.view(-1).size()[0] for param in encoder.parameters()]) +\\\n",
    "           sum([param.view(-1).size()[0] for param in decoder.parameters()])\n",
    "logger.info('n_params: {}'.format(n_params))\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=optim_config['base_lr'],\n",
    "    momentum=optim_config['momentum'],\n",
    "    weight_decay=optim_config['weight_decay'],\n",
    "    nesterov=optim_config['nesterov'])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=optim_config['milestones'],\n",
    "    gamma=optim_config['lr_decay'])\n",
    "\n",
    "# Test with Adam Optimizer (easier to setup, experiment with SGD later)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=optim_config['base_lr'],\n",
    "#                              weight_decay=optim_config['weight_decay'])\n",
    "\n",
    "# run test before start training\n",
    "# test_outputs = test(0, model, criterion, test_loader, run_config, writer, device)\n",
    "\n",
    "ref1 = 0\n",
    "ref2 = 0\n",
    "\n",
    "for epoch in range(optim_config['epochs']):\n",
    "\n",
    "    loss_ = train(epoch, model, optimizer, criterion, train_loader, (demo_cs,demo_np), run_config,\n",
    "         writer, device, logger=logger)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    test(epoch, model, criterion, test_loader, (demo_cs,demo_np), run_config,\n",
    "                    writer, device, logger, return_output=False)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        if epoch > 50:\n",
    "            if (np.abs(loss_ - ref1)/ref1<ref1*0.01) & (np.abs(loss_ - ref2)/ref2<ref2*0.01):\n",
    "                print(\"Early stopping at epoch\", epoch)\n",
    "                break\n",
    "            if (ref1 < loss_) & (ref1 < ref2):\n",
    "                print(\"Diverging. stop.\")\n",
    "                break\n",
    "            if loss_ < best:\n",
    "                best = loss_\n",
    "                best_epoch = epoch\n",
    "        else:\n",
    "            best = loss_\n",
    "            best_epoch = epoch\n",
    "\n",
    "        ref2 = ref1\n",
    "        ref1 = loss_\n",
    "\n",
    "        if (config['run_config']['save']) & (best_epoch==epoch):\n",
    "            torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()},\n",
    "                model_dir+\"SAE_\"+zoomlevel+\"_\"+str(model_config['output_dim']**2*2048)+\"_\"+\n",
    "                model_run_date+\"_\"+str(epoch)+\".pt\")\n",
    "\n",
    "            \n",
    "if config['run_config']['save']:\n",
    "    files = glob.glob(model_dir+\"SAE_\"+zoomlevel+\"_\"+str(model_config['output_dim']**2*2048)+\"_\"+\n",
    "                              model_run_date+\"_*.pt\")\n",
    "\n",
    "    for f in files:\n",
    "        e = int(f.split(\"_\")[-1].split(\".\")[0])\n",
    "        if e != best_epoch:\n",
    "            os.remove(f)\n",
    "\n",
    "        \n",
    "if run_config['tensorboard']:\n",
    "    outpath = os.path.join(outdir, 'all_scalars.json')\n",
    "    writer.export_scalars_to_json(outpath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_meter_1 = AverageMeter()\n",
    "loss_meter_2 = AverageMeter()\n",
    "\n",
    "for step, (image_list, data) in enumerate(test_loader):\n",
    "\n",
    "    census_index = [demo_cs.index(i[i.rfind('/')+1:i.rfind('_')]) for i in image_list]\n",
    "    census_data = demo_np[census_index]\n",
    "\n",
    "    census_data = torch.tensor(census_data).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    out_image, out_demo = model(data)\n",
    "\n",
    "    loss1, loss2 = criterion(out_image, out_demo, data, census_data, return_components=True)\n",
    "\n",
    "    num = data.size(0)\n",
    "\n",
    "    loss_meter_1.update(loss1.item(), num)\n",
    "    loss_meter_2.update(loss2.item(), num)\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(step, end='\\t')\n",
    "\n",
    "best_test_1 = loss_meter_1.avg\n",
    "best_test_2 = loss_meter_2.avg\n",
    "print(best_test_1, best_test_2)         \n",
    "\n",
    "loss_meter_1 = AverageMeter()\n",
    "loss_meter_2 = AverageMeter()                                                              \n",
    "for step, (image_list, data) in enumerate(train_loader):\n",
    "\n",
    "    census_index = [demo_cs.index(i[i.rfind('/')+1:i.rfind('_')]) for i in image_list]\n",
    "    census_data = demo_np[census_index]\n",
    "\n",
    "    census_data = torch.tensor(census_data).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    out_image, out_demo = model(data)\n",
    "\n",
    "    loss1, loss2 = criterion(out_image, out_demo, data, census_data, return_components=True)\n",
    "\n",
    "    num = data.size(0)\n",
    "\n",
    "    loss_meter_1.update(loss1.item(), num)\n",
    "    loss_meter_2.update(loss2.item(), num)\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(step, end='\\t')\n",
    "\n",
    "best_1 = loss_meter_1.avg\n",
    "best_2 = loss_meter_2.avg\n",
    "print(best_1, best_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t10\t20\t30\t40\t50\t60\t70\t0.29800634201653975 0.014136222738354649\n",
      "0\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t120\t130\t140\t150\t160\t170\t180\t190\t200\t210\t220\t230\t240\t250\t260\t270\t280\t290\t300\t310\t320\t330\t340\t350\t360\t370\t380\t390\t400\t410\t420\t430\t440\t450\t460\t470\t480\t490\t500\t510\t520\t530\t540\t550\t560\t570\t580\t590\t600\t0.27115582356488466 0.001241747316502718\n"
     ]
    }
   ],
   "source": [
    "with open(out_dir+\"SAE_train.csv\", \"a\") as f:\n",
    "    f.write(\"%s,%s,%d,%s,%s,%d,%.4f,%.4f,%.4f,%.4f\\n\" % (model_run_date, zoomlevel, model_config['output_dim']**2*2048, \n",
    "            sampling, normalization, best_epoch, best_1, best_2, best_test_1, best_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse Normalization\n",
    "\n",
    "# CIFAR\n",
    "# inv_normalize = torchvision.transforms.Normalize(\n",
    "#     mean=[-0.4914/0.2470, -0.4822/0.2435, -0.4465/0.2616],\n",
    "#     std=[1/0.2470, 1/0.2435, 1/0.2616]\n",
    "# )\n",
    "\n",
    "\n",
    "# Satellite image\n",
    "inv_normalize = torchvision.transforms.Normalize(\n",
    "    mean=[-0.3733/0.2173, -0.3991/0.2055, -0.3711/0.2143],\n",
    "    std=[1/0.2173, 1/0.2055, 1/0.2143]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for step, (_,data) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    test_output = model(data)\n",
    "    test_output_orig = inv_normalize(test_output)\n",
    "    data_orig = inv_normalize(data)\n",
    "    if step == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(data[plot_image, :, :, :].cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_output[plot_image, :, :, :].cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(test_output[:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(test_output[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(test_output[:,2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(data[:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(data[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(data[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).detach().cpu().numpy()[:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).detach().cpu().numpy()[:,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).detach().cpu().numpy()[:,2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((test_output - data).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.power((test_output - data).cpu().detach().numpy(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((test_output - data).detach().cpu().numpy()[:,2,:,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((test_output - data).detach().cpu().numpy()[:,1,:,:].flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((test_output - data).detach().cpu().numpy()[:,0,:,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_output_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_orig[plot_image,:,:,:].cpu().detach().permute(1, 2, 0));\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.detach().numpy()[:,0,:,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
